{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa994ae-ee9b-4e46-afc3-06c3ab38feec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run a second experiment using the DQN algorithm\n",
    " \n",
    "- Allowed algorithm names can be found [here](https://docs.ray.io/en/master/rllib-algorithms.html)\n",
    "- To visualize both experiments together, use the same results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ceed762-e676-480c-814f-0c99b2d5c979",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.90',\n",
       " 'raylet_ip_address': '192.168.0.90',\n",
       " 'redis_address': '192.168.0.90:45176',\n",
       " 'object_store_address': '/tmp/ray/session_2022-01-03_14-50-24_397488_15747/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-01-03_14-50-24_397488_15747/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-01-03_14-50-24_397488_15747',\n",
       " 'metrics_export_port': 55350,\n",
       " 'node_id': '7d7646911b7d1ba9cf53f1d64288da37ecc46ee23b4b4e1007b1601b'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1961d539-2395-44c0-9bcd-d4586a229024",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:08:00,791\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:08:00,791\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:08:00,791\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:08:01,264\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:08:01,907\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:02 (running for 00:00:04.43)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:08:02,984\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:03 (running for 00:00:05.44)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-08-05\n",
      "  done: false\n",
      "  episode_len_mean: 20.367346938775512\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 58.0\n",
      "  episode_reward_mean: 20.367346938775512\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 49\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 0.3911696970462799\n",
      "          mean_q: 0.041637029498815536\n",
      "          mean_td_error: -0.5128652453422546\n",
      "          min_q: -0.2418372631072998\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.5890849232673645\n",
      "        - 0.23067933320999146\n",
      "        - -0.5255952477455139\n",
      "        - -0.05037719011306763\n",
      "        - -0.7710492610931396\n",
      "        - -0.3488236367702484\n",
      "        - -0.2024255096912384\n",
      "        - -0.5791395306587219\n",
      "        - 0.3961222469806671\n",
      "        - -0.6977411508560181\n",
      "        - -0.9870268106460571\n",
      "        - 0.012053310871124268\n",
      "        - -0.2003699541091919\n",
      "        - -0.33617186546325684\n",
      "        - -0.9678444862365723\n",
      "        - -0.1971186250448227\n",
      "        - 0.2519112527370453\n",
      "        - -0.7281347513198853\n",
      "        - -0.2713219225406647\n",
      "        - -1.1093685626983643\n",
      "        - -0.4430624544620514\n",
      "        - -1.0217796564102173\n",
      "        - -0.9700666666030884\n",
      "        - -0.917778730392456\n",
      "        - -0.21779510378837585\n",
      "        - -1.0193047523498535\n",
      "        - -1.0919713973999023\n",
      "        - -0.9852990508079529\n",
      "        - -0.5910701155662537\n",
      "        - -0.7369399070739746\n",
      "        - 0.004025280475616455\n",
      "        - -0.7498182654380798\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.2\n",
      "    ram_util_percent: 16.0\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11640042810887843\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11980926597511375\n",
      "    mean_inference_ms: 1.7419480658196782\n",
      "    mean_raw_obs_processing_ms: 0.27011991380811573\n",
      "  time_since_restore: 2.7677857875823975\n",
      "  time_this_iter_s: 2.7677857875823975\n",
      "  time_total_s: 2.7677857875823975\n",
      "  timers:\n",
      "    learn_throughput: 256.07\n",
      "    learn_time_ms: 124.966\n",
      "    load_throughput: 207126.123\n",
      "    load_time_ms: 0.154\n",
      "  timestamp: 1641218885\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:09 (running for 00:00:11.24)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.76779</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 20.3673</td><td style=\"text-align: right;\">                  58</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">           20.3673</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m WARNING:tensorflow:From /home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py:216: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 2000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-08-11\n",
      "  done: false\n",
      "  episode_len_mean: 20.02020202020202\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 60.0\n",
      "  episode_reward_mean: 20.02020202020202\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 99\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 9.35\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 11.0\n",
      "    episode_reward_mean: 9.35\n",
      "    episode_reward_min: 8.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 8\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 10\n",
      "      - 8\n",
      "      - 9\n",
      "      - 9\n",
      "      - 8\n",
      "      - 10\n",
      "      - 9\n",
      "      - 10\n",
      "      - 9\n",
      "      - 10\n",
      "      - 10\n",
      "      - 9\n",
      "      - 11\n",
      "      - 10\n",
      "      - 8\n",
      "      - 9\n",
      "      episode_reward:\n",
      "      - 8.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 8.0\n",
      "      - 9.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 10.0\n",
      "      - 9.0\n",
      "      - 10.0\n",
      "      - 9.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 9.0\n",
      "      - 11.0\n",
      "      - 10.0\n",
      "      - 8.0\n",
      "      - 9.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1046556107541348\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.10892558605112927\n",
      "      mean_inference_ms: 1.693800408789452\n",
      "      mean_raw_obs_processing_ms: 0.18698357521219452\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 1504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 2.514159917831421\n",
      "          mean_q: 2.230184555053711\n",
      "          mean_td_error: 0.07897074520587921\n",
      "          min_q: 1.8830230236053467\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.18781232833862305\n",
      "        - -0.2756679058074951\n",
      "        - 0.16083002090454102\n",
      "        - -0.4665360450744629\n",
      "        - -0.3421316146850586\n",
      "        - 0.002455472946166992\n",
      "        - 0.896084189414978\n",
      "        - 0.9184384346008301\n",
      "        - 1.1141507625579834\n",
      "        - -0.12884926795959473\n",
      "        - -0.15034723281860352\n",
      "        - -0.04249382019042969\n",
      "        - 0.8830230236053467\n",
      "        - 0.04435539245605469\n",
      "        - -0.09320902824401855\n",
      "        - 0.015410423278808594\n",
      "        - 0.0583796501159668\n",
      "        - 0.0560758113861084\n",
      "        - -0.09055495262145996\n",
      "        - -0.43039989471435547\n",
      "        - -0.018213510513305664\n",
      "        - -0.27148985862731934\n",
      "        - 1.2920591831207275\n",
      "        - -0.0018126964569091797\n",
      "        - -0.14759206771850586\n",
      "        - 0.013441085815429688\n",
      "        - 0.03544878959655762\n",
      "        - 0.10930585861206055\n",
      "        - -0.02685236930847168\n",
      "        - -0.0908811092376709\n",
      "        - -0.3237888813018799\n",
      "        - 0.01623845100402832\n",
      "    num_agent_steps_sampled: 2000\n",
      "    num_agent_steps_trained: 8032\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 8032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.425\n",
      "    ram_util_percent: 16.0\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11513522776357053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11855960911340922\n",
      "    mean_inference_ms: 1.7119777760175443\n",
      "    mean_raw_obs_processing_ms: 0.2671627120679446\n",
      "  time_since_restore: 8.354723930358887\n",
      "  time_this_iter_s: 5.586938142776489\n",
      "  time_total_s: 8.354723930358887\n",
      "  timers:\n",
      "    learn_throughput: 7427.696\n",
      "    learn_time_ms: 4.308\n",
      "    load_throughput: 86346.969\n",
      "    load_time_ms: 0.371\n",
      "  timestamp: 1641218891\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 2\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:15 (running for 00:00:16.88)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.35472</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\"> 20.0202</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">           20.0202</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 3000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-08-16\n",
      "  done: false\n",
      "  episode_len_mean: 23.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 127.0\n",
      "  episode_reward_mean: 23.08\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 134\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 4.86088228225708\n",
      "          mean_q: 3.499209403991699\n",
      "          mean_td_error: -0.05915272980928421\n",
      "          min_q: 1.7995824813842773\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.26461076736450195\n",
      "        - -0.10272741317749023\n",
      "        - 0.07503437995910645\n",
      "        - 0.16277313232421875\n",
      "        - -0.0785682201385498\n",
      "        - -0.055812835693359375\n",
      "        - -0.5530948638916016\n",
      "        - -0.4178478717803955\n",
      "        - 2.3343684673309326\n",
      "        - 0.15241432189941406\n",
      "        - -0.2696208953857422\n",
      "        - 1.1146376132965088\n",
      "        - -1.0989830493927002\n",
      "        - -0.3754889965057373\n",
      "        - 0.7995824813842773\n",
      "        - 1.4455316066741943\n",
      "        - -0.10074853897094727\n",
      "        - -0.10954952239990234\n",
      "        - -0.5493893623352051\n",
      "        - -0.2404179573059082\n",
      "        - -0.272585391998291\n",
      "        - -0.8428418636322021\n",
      "        - 0.0717310905456543\n",
      "        - -0.056397438049316406\n",
      "        - -0.38777971267700195\n",
      "        - 0.218583345413208\n",
      "        - -0.23251008987426758\n",
      "        - -0.5233621597290039\n",
      "        - -0.9204776287078857\n",
      "        - -1.1855785846710205\n",
      "        - -0.15247559547424316\n",
      "        - -0.005896568298339844\n",
      "    num_agent_steps_sampled: 3000\n",
      "    num_agent_steps_trained: 16032\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.95\n",
      "    ram_util_percent: 16.0625\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11402496505479501\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11726376776354024\n",
      "    mean_inference_ms: 1.6834904519825624\n",
      "    mean_raw_obs_processing_ms: 0.2638534488153074\n",
      "  time_since_restore: 13.333685874938965\n",
      "  time_this_iter_s: 4.978961944580078\n",
      "  time_total_s: 13.333685874938965\n",
      "  timers:\n",
      "    learn_throughput: 7638.767\n",
      "    learn_time_ms: 4.189\n",
      "    load_throughput: 88161.934\n",
      "    load_time_ms: 0.363\n",
      "  timestamp: 1641218896\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:20 (running for 00:00:21.90)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         13.3337</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">   23.08</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             23.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:25 (running for 00:00:26.91)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         13.3337</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">   23.08</td><td style=\"text-align: right;\">                 127</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             23.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-08-27\n",
      "  done: false\n",
      "  episode_len_mean: 28.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 138.0\n",
      "  episode_reward_mean: 28.21\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 155\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 153.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 299.0\n",
      "    episode_reward_mean: 153.5\n",
      "    episode_reward_min: 100.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 219\n",
      "      - 119\n",
      "      - 133\n",
      "      - 131\n",
      "      - 120\n",
      "      - 104\n",
      "      - 130\n",
      "      - 177\n",
      "      - 299\n",
      "      - 100\n",
      "      - 146\n",
      "      - 166\n",
      "      - 126\n",
      "      - 147\n",
      "      - 237\n",
      "      - 110\n",
      "      - 109\n",
      "      - 134\n",
      "      - 178\n",
      "      - 185\n",
      "      episode_reward:\n",
      "      - 219.0\n",
      "      - 119.0\n",
      "      - 133.0\n",
      "      - 131.0\n",
      "      - 120.0\n",
      "      - 104.0\n",
      "      - 130.0\n",
      "      - 177.0\n",
      "      - 299.0\n",
      "      - 100.0\n",
      "      - 146.0\n",
      "      - 166.0\n",
      "      - 126.0\n",
      "      - 147.0\n",
      "      - 237.0\n",
      "      - 110.0\n",
      "      - 109.0\n",
      "      - 134.0\n",
      "      - 178.0\n",
      "      - 185.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1186859102758474\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11955806270854612\n",
      "      mean_inference_ms: 1.6820386847957942\n",
      "      mean_raw_obs_processing_ms: 0.1326653033842552\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 3520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 6.534749984741211\n",
      "          mean_q: 5.418067932128906\n",
      "          mean_td_error: 0.5147452354431152\n",
      "          min_q: 1.3255572319030762\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.9998326301574707\n",
      "        - 0.10646343231201172\n",
      "        - -0.07345438003540039\n",
      "        - 4.283924579620361\n",
      "        - 0.1525106430053711\n",
      "        - -0.007653236389160156\n",
      "        - 3.4534902572631836\n",
      "        - 1.9727697372436523\n",
      "        - 0.13828563690185547\n",
      "        - 0.32555723190307617\n",
      "        - 0.051480770111083984\n",
      "        - -0.061342716217041016\n",
      "        - -0.4585895538330078\n",
      "        - 0.04352855682373047\n",
      "        - 0.1491403579711914\n",
      "        - 0.05449390411376953\n",
      "        - 2.753871440887451\n",
      "        - 7.82012939453125e-05\n",
      "        - -0.010278701782226562\n",
      "        - 0.19605779647827148\n",
      "        - -0.7135958671569824\n",
      "        - -0.8860087394714355\n",
      "        - 4.283924579620361\n",
      "        - -0.16692876815795898\n",
      "        - -0.25298118591308594\n",
      "        - 2.3376035690307617\n",
      "        - 0.07854270935058594\n",
      "        - 0.08031320571899414\n",
      "        - -0.46519041061401367\n",
      "        - -0.09212303161621094\n",
      "        - 0.23779058456420898\n",
      "        - -0.04000139236450195\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 24032\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 24032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 6\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.15625\n",
      "    ram_util_percent: 16.1\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11366360038162714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11680386069156241\n",
      "    mean_inference_ms: 1.6706514231211758\n",
      "    mean_raw_obs_processing_ms: 0.2615974279761394\n",
      "  time_since_restore: 24.78354811668396\n",
      "  time_this_iter_s: 11.449862241744995\n",
      "  time_total_s: 24.78354811668396\n",
      "  timers:\n",
      "    learn_throughput: 10294.586\n",
      "    learn_time_ms: 3.108\n",
      "    load_throughput: 144227.088\n",
      "    load_time_ms: 0.222\n",
      "  timestamp: 1641218907\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 4\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:30 (running for 00:00:32.41)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         24.7835</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">   28.21</td><td style=\"text-align: right;\">                 138</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             28.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 5000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-08-33\n",
      "  done: false\n",
      "  episode_len_mean: 34.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 138.0\n",
      "  episode_reward_mean: 34.67\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 172\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 8.740397453308105\n",
      "          mean_q: 6.80490779876709\n",
      "          mean_td_error: 0.40044325590133667\n",
      "          min_q: 1.4429242610931396\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.11870193481445312\n",
      "        - 2.621483325958252\n",
      "        - -0.1448535919189453\n",
      "        - 0.2188577651977539\n",
      "        - -0.24352073669433594\n",
      "        - 0.193939208984375\n",
      "        - -0.010473251342773438\n",
      "        - -0.35398149490356445\n",
      "        - 0.06342458724975586\n",
      "        - -0.10345745086669922\n",
      "        - 0.45604658126831055\n",
      "        - -0.4976043701171875\n",
      "        - 0.5107684135437012\n",
      "        - -0.2915215492248535\n",
      "        - -0.348970890045166\n",
      "        - -0.5397672653198242\n",
      "        - 6.133608341217041\n",
      "        - 0.15007781982421875\n",
      "        - -1.4821586608886719\n",
      "        - 0.06818675994873047\n",
      "        - -0.31850671768188477\n",
      "        - 0.4437837600708008\n",
      "        - 0.21761178970336914\n",
      "        - 0.0007977485656738281\n",
      "        - 6.5286664962768555\n",
      "        - 1.545100212097168\n",
      "        - -0.13572359085083008\n",
      "        - -1.035494089126587\n",
      "        - -0.0194854736328125\n",
      "        - -0.3092660903930664\n",
      "        - -0.5803427696228027\n",
      "        - -0.04174327850341797\n",
      "    num_agent_steps_sampled: 5000\n",
      "    num_agent_steps_trained: 32032\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.257142857142856\n",
      "    ram_util_percent: 16.099999999999998\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11367994792833262\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11670464167713518\n",
      "    mean_inference_ms: 1.6668396183924927\n",
      "    mean_raw_obs_processing_ms: 0.25996939896604787\n",
      "  time_since_restore: 29.867689609527588\n",
      "  time_this_iter_s: 5.084141492843628\n",
      "  time_total_s: 29.867689609527588\n",
      "  timers:\n",
      "    learn_throughput: 7764.938\n",
      "    learn_time_ms: 4.121\n",
      "    load_throughput: 96887.12\n",
      "    load_time_ms: 0.33\n",
      "  timestamp: 1641218913\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:36 (running for 00:00:37.53)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         29.8677</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">   34.67</td><td style=\"text-align: right;\">                 138</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             34.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:41 (running for 00:00:42.54)<br>Memory usage on this node: 9.9/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         29.8677</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">   34.67</td><td style=\"text-align: right;\">                 138</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             34.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 6000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 41.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 145.0\n",
      "  episode_reward_mean: 41.31\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 184\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 199.8\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 249.0\n",
      "    episode_reward_mean: 199.8\n",
      "    episode_reward_min: 175.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 234\n",
      "      - 231\n",
      "      - 196\n",
      "      - 177\n",
      "      - 190\n",
      "      - 194\n",
      "      - 187\n",
      "      - 175\n",
      "      - 190\n",
      "      - 200\n",
      "      - 192\n",
      "      - 195\n",
      "      - 219\n",
      "      - 198\n",
      "      - 196\n",
      "      - 201\n",
      "      - 194\n",
      "      - 249\n",
      "      - 195\n",
      "      - 183\n",
      "      episode_reward:\n",
      "      - 234.0\n",
      "      - 231.0\n",
      "      - 196.0\n",
      "      - 177.0\n",
      "      - 190.0\n",
      "      - 194.0\n",
      "      - 187.0\n",
      "      - 175.0\n",
      "      - 190.0\n",
      "      - 200.0\n",
      "      - 192.0\n",
      "      - 195.0\n",
      "      - 219.0\n",
      "      - 198.0\n",
      "      - 196.0\n",
      "      - 201.0\n",
      "      - 194.0\n",
      "      - 249.0\n",
      "      - 195.0\n",
      "      - 183.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1167804701189578\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.1179058097563797\n",
      "      mean_inference_ms: 1.6536815192109795\n",
      "      mean_raw_obs_processing_ms: 0.12830097812708327\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 5536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 10.878185272216797\n",
      "          mean_q: 9.080738067626953\n",
      "          mean_td_error: 0.4209386706352234\n",
      "          min_q: 4.554231643676758\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.0639810562133789\n",
      "        - 0.019783973693847656\n",
      "        - -0.0692586898803711\n",
      "        - -0.12792491912841797\n",
      "        - 0.006934165954589844\n",
      "        - -0.07122421264648438\n",
      "        - 0.10240840911865234\n",
      "        - -0.03995704650878906\n",
      "        - 0.21029186248779297\n",
      "        - -0.017627716064453125\n",
      "        - 0.16891098022460938\n",
      "        - 0.011109352111816406\n",
      "        - 0.10609912872314453\n",
      "        - 0.2256326675415039\n",
      "        - -0.27745819091796875\n",
      "        - 5.709773063659668\n",
      "        - 0.08576774597167969\n",
      "        - 1.1379060745239258\n",
      "        - -0.045187950134277344\n",
      "        - 5.024407386779785\n",
      "        - 1.652073860168457\n",
      "        - 0.3215646743774414\n",
      "        - -0.3173208236694336\n",
      "        - 0.386322021484375\n",
      "        - 0.19136905670166016\n",
      "        - -0.24306201934814453\n",
      "        - 0.1904125213623047\n",
      "        - 0.04382610321044922\n",
      "        - -0.3503885269165039\n",
      "        - -0.054843902587890625\n",
      "        - -0.3822669982910156\n",
      "        - -0.06405353546142578\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 40032\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 40032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 10\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.442105263157895\n",
      "    ram_util_percent: 15.926315789473685\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11361504892088377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11652713180317927\n",
      "    mean_inference_ms: 1.662889679570716\n",
      "    mean_raw_obs_processing_ms: 0.25835643142671544\n",
      "  time_since_restore: 42.816484212875366\n",
      "  time_this_iter_s: 12.948794603347778\n",
      "  time_total_s: 42.816484212875366\n",
      "  timers:\n",
      "    learn_throughput: 7281.422\n",
      "    learn_time_ms: 4.395\n",
      "    load_throughput: 85109.529\n",
      "    load_time_ms: 0.376\n",
      "  timestamp: 1641218926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 6\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:47 (running for 00:00:48.54)<br>Memory usage on this node: 9.9/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         42.8165</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">   41.31</td><td style=\"text-align: right;\">                 145</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             41.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:52 (running for 00:00:54.37)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         47.6198</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">   50.64</td><td style=\"text-align: right;\">                 226</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             50.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:08:57 (running for 00:00:59.38)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         47.6198</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">   50.64</td><td style=\"text-align: right;\">                 226</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             50.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:02 (running for 00:01:04.39)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         47.6198</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">   50.64</td><td style=\"text-align: right;\">                 226</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             50.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-04\n",
      "  done: false\n",
      "  episode_len_mean: 59.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 311.0\n",
      "  episode_reward_mean: 59.33\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 197\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 193.65\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 241.0\n",
      "    episode_reward_mean: 193.65\n",
      "    episode_reward_min: 162.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 215\n",
      "      - 241\n",
      "      - 226\n",
      "      - 182\n",
      "      - 198\n",
      "      - 172\n",
      "      - 181\n",
      "      - 183\n",
      "      - 195\n",
      "      - 172\n",
      "      - 186\n",
      "      - 162\n",
      "      - 186\n",
      "      - 205\n",
      "      - 211\n",
      "      - 178\n",
      "      - 162\n",
      "      - 216\n",
      "      - 181\n",
      "      - 221\n",
      "      episode_reward:\n",
      "      - 215.0\n",
      "      - 241.0\n",
      "      - 226.0\n",
      "      - 182.0\n",
      "      - 198.0\n",
      "      - 172.0\n",
      "      - 181.0\n",
      "      - 183.0\n",
      "      - 195.0\n",
      "      - 172.0\n",
      "      - 186.0\n",
      "      - 162.0\n",
      "      - 186.0\n",
      "      - 205.0\n",
      "      - 211.0\n",
      "      - 178.0\n",
      "      - 162.0\n",
      "      - 216.0\n",
      "      - 181.0\n",
      "      - 221.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11811753944362006\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11926958521732137\n",
      "      mean_inference_ms: 1.6691957060470302\n",
      "      mean_raw_obs_processing_ms: 0.12863049816118904\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 7552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 14.575490951538086\n",
      "          mean_q: 11.130128860473633\n",
      "          mean_td_error: -0.13501089811325073\n",
      "          min_q: -0.4421851634979248\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.5174322128295898\n",
      "        - -0.5001373291015625\n",
      "        - -0.1054525375366211\n",
      "        - 0.13282394409179688\n",
      "        - 0.22350502014160156\n",
      "        - -0.49451446533203125\n",
      "        - -1.6662635803222656\n",
      "        - -0.27294921875\n",
      "        - -0.08576393127441406\n",
      "        - 0.3596857786178589\n",
      "        - -0.07895851135253906\n",
      "        - -0.06581497192382812\n",
      "        - 0.02515888214111328\n",
      "        - -0.023664474487304688\n",
      "        - 0.5021677017211914\n",
      "        - 0.2794218063354492\n",
      "        - 0.10778951644897461\n",
      "        - -0.7406511306762695\n",
      "        - -0.44159984588623047\n",
      "        - 1.8690524101257324\n",
      "        - 0.1636495590209961\n",
      "        - -0.4661140441894531\n",
      "        - -0.6204910278320312\n",
      "        - 0.07419490814208984\n",
      "        - -0.05285358428955078\n",
      "        - -1.071868896484375\n",
      "        - 0.06682395935058594\n",
      "        - 0.28336238861083984\n",
      "        - -0.1755828857421875\n",
      "        - -0.31156349182128906\n",
      "        - -0.8731155395507812\n",
      "        - 0.15680694580078125\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 56032\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 56032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 14\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.147368421052633\n",
      "    ram_util_percent: 16.2578947368421\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1134805461746398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11626168324162521\n",
      "    mean_inference_ms: 1.657448501307174\n",
      "    mean_raw_obs_processing_ms: 0.2561271287753638\n",
      "  time_since_restore: 60.997008085250854\n",
      "  time_this_iter_s: 13.377197742462158\n",
      "  time_total_s: 60.997008085250854\n",
      "  timers:\n",
      "    learn_throughput: 7689.71\n",
      "    learn_time_ms: 4.161\n",
      "    load_throughput: 92049.741\n",
      "    load_time_ms: 0.348\n",
      "  timestamp: 1641218944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 8\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:08 (running for 00:01:09.80)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">          60.997</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">   59.33</td><td style=\"text-align: right;\">                 311</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             59.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:13 (running for 00:01:14.80)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         65.9662</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">   68.72</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             68.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 10000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-18\n",
      "  done: false\n",
      "  episode_len_mean: 77.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 77.88\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 209\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 95.1\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 106.0\n",
      "    episode_reward_mean: 95.1\n",
      "    episode_reward_min: 83.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 84\n",
      "      - 98\n",
      "      - 99\n",
      "      - 106\n",
      "      - 97\n",
      "      - 93\n",
      "      - 105\n",
      "      - 100\n",
      "      - 97\n",
      "      - 85\n",
      "      - 95\n",
      "      - 88\n",
      "      - 88\n",
      "      - 98\n",
      "      - 102\n",
      "      - 83\n",
      "      - 87\n",
      "      - 99\n",
      "      - 96\n",
      "      - 102\n",
      "      episode_reward:\n",
      "      - 84.0\n",
      "      - 98.0\n",
      "      - 99.0\n",
      "      - 106.0\n",
      "      - 97.0\n",
      "      - 93.0\n",
      "      - 105.0\n",
      "      - 100.0\n",
      "      - 97.0\n",
      "      - 85.0\n",
      "      - 95.0\n",
      "      - 88.0\n",
      "      - 88.0\n",
      "      - 98.0\n",
      "      - 102.0\n",
      "      - 83.0\n",
      "      - 87.0\n",
      "      - 99.0\n",
      "      - 96.0\n",
      "      - 102.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11734093623549621\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11856045943648208\n",
      "      mean_inference_ms: 1.6608241880028782\n",
      "      mean_raw_obs_processing_ms: 0.12831814556808405\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 9568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 19.48189353942871\n",
      "          mean_q: 16.359642028808594\n",
      "          mean_td_error: -0.09228956699371338\n",
      "          min_q: -2.8178157806396484\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2529315948486328\n",
      "        - 0.2273082733154297\n",
      "        - -0.4298286437988281\n",
      "        - -3.8178157806396484\n",
      "        - 0.0500030517578125\n",
      "        - 0.3003559112548828\n",
      "        - -0.042647361755371094\n",
      "        - -0.08844947814941406\n",
      "        - -0.04349517822265625\n",
      "        - 0.20913219451904297\n",
      "        - 0.08996009826660156\n",
      "        - -0.03141975402832031\n",
      "        - 0.20268821716308594\n",
      "        - -0.4491863250732422\n",
      "        - 0.34317588806152344\n",
      "        - 0.28946971893310547\n",
      "        - 0.010343551635742188\n",
      "        - 0.1481952667236328\n",
      "        - 0.4626655578613281\n",
      "        - -0.3141937255859375\n",
      "        - 0.3614654541015625\n",
      "        - 0.0545654296875\n",
      "        - 0.012376785278320312\n",
      "        - -1.1904563903808594\n",
      "        - 0.5069160461425781\n",
      "        - 0.3154773712158203\n",
      "        - 0.06189155578613281\n",
      "        - 0.01198577880859375\n",
      "        - -1.1341676712036133\n",
      "        - 0.2260284423828125\n",
      "        - -0.07317352294921875\n",
      "        - 0.5246315002441406\n",
      "    num_agent_steps_sampled: 10000\n",
      "    num_agent_steps_trained: 72032\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 72032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 18\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.525000000000002\n",
      "    ram_util_percent: 16.35\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11346984196150914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11618149254452667\n",
      "    mean_inference_ms: 1.6550378026206694\n",
      "    mean_raw_obs_processing_ms: 0.2541341131314765\n",
      "  time_since_restore: 74.78481936454773\n",
      "  time_this_iter_s: 8.818644046783447\n",
      "  time_total_s: 74.78481936454773\n",
      "  timers:\n",
      "    learn_throughput: 8156.455\n",
      "    learn_time_ms: 3.923\n",
      "    load_throughput: 94128.43\n",
      "    load_time_ms: 0.34\n",
      "  timestamp: 1641218958\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 10\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:19 (running for 00:01:20.66)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         74.7848</td><td style=\"text-align: right;\">10000</td><td style=\"text-align: right;\">   77.88</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             77.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 11000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-23\n",
      "  done: false\n",
      "  episode_len_mean: 85.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 85.44\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 215\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 10576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 20.73247718811035\n",
      "          mean_q: 15.959794044494629\n",
      "          mean_td_error: 0.104680135846138\n",
      "          min_q: 3.324559211730957\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.21673965454101562\n",
      "        - 0.33270835876464844\n",
      "        - 0.1572856903076172\n",
      "        - 0.13574790954589844\n",
      "        - -0.006580352783203125\n",
      "        - -0.22403812408447266\n",
      "        - -0.2396259307861328\n",
      "        - 1.3418083190917969\n",
      "        - -0.17129135131835938\n",
      "        - 0.7427520751953125\n",
      "        - 0.032009124755859375\n",
      "        - -0.06004047393798828\n",
      "        - -0.13209247589111328\n",
      "        - 2.324559211730957\n",
      "        - -0.7771964073181152\n",
      "        - -0.8060359954833984\n",
      "        - -1.4361181259155273\n",
      "        - -1.335580825805664\n",
      "        - -0.31120872497558594\n",
      "        - -0.1622447967529297\n",
      "        - -0.8163795471191406\n",
      "        - 0.04857826232910156\n",
      "        - 5.431305885314941\n",
      "        - -0.07343864440917969\n",
      "        - 0.07293319702148438\n",
      "        - -0.28621864318847656\n",
      "        - 0.2102203369140625\n",
      "        - -0.36487388610839844\n",
      "        - -0.2053070068359375\n",
      "        - -0.11962318420410156\n",
      "        - -0.3164234161376953\n",
      "        - 0.14743423461914062\n",
      "    num_agent_steps_sampled: 11000\n",
      "    num_agent_steps_trained: 80032\n",
      "    num_steps_sampled: 11000\n",
      "    num_steps_trained: 80032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 20\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.35\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11344770923458132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11612264695626756\n",
      "    mean_inference_ms: 1.6537504954185607\n",
      "    mean_raw_obs_processing_ms: 0.2530470274098497\n",
      "  time_since_restore: 79.82064008712769\n",
      "  time_this_iter_s: 5.035820722579956\n",
      "  time_total_s: 79.82064008712769\n",
      "  timers:\n",
      "    learn_throughput: 6978.694\n",
      "    learn_time_ms: 4.585\n",
      "    load_throughput: 66928.158\n",
      "    load_time_ms: 0.478\n",
      "  timestamp: 1641218963\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 11000\n",
      "  training_iteration: 11\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:24 (running for 00:01:25.74)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         79.8206</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">   85.44</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             85.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:29 (running for 00:01:30.75)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         79.8206</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">   85.44</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             85.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-33\n",
      "  done: false\n",
      "  episode_len_mean: 91.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 91.89\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 225\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 101.8\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 109.0\n",
      "    episode_reward_mean: 101.8\n",
      "    episode_reward_min: 93.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 108\n",
      "      - 100\n",
      "      - 100\n",
      "      - 103\n",
      "      - 107\n",
      "      - 98\n",
      "      - 95\n",
      "      - 102\n",
      "      - 100\n",
      "      - 97\n",
      "      - 109\n",
      "      - 106\n",
      "      - 101\n",
      "      - 99\n",
      "      - 93\n",
      "      - 108\n",
      "      - 108\n",
      "      - 104\n",
      "      - 102\n",
      "      - 96\n",
      "      episode_reward:\n",
      "      - 108.0\n",
      "      - 100.0\n",
      "      - 100.0\n",
      "      - 103.0\n",
      "      - 107.0\n",
      "      - 98.0\n",
      "      - 95.0\n",
      "      - 102.0\n",
      "      - 100.0\n",
      "      - 97.0\n",
      "      - 109.0\n",
      "      - 106.0\n",
      "      - 101.0\n",
      "      - 99.0\n",
      "      - 93.0\n",
      "      - 108.0\n",
      "      - 108.0\n",
      "      - 104.0\n",
      "      - 102.0\n",
      "      - 96.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1187307590113658\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11995323781273985\n",
      "      mean_inference_ms: 1.6779140582561012\n",
      "      mean_raw_obs_processing_ms: 0.12998577767418656\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 11584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 22.40367889404297\n",
      "          mean_q: 16.941547393798828\n",
      "          mean_td_error: 0.48959288001060486\n",
      "          min_q: -2.46256685256958\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2777214050292969\n",
      "        - -0.28739166259765625\n",
      "        - 3.7238688468933105\n",
      "        - 0.0034189224243164062\n",
      "        - 15.844717025756836\n",
      "        - -0.03951835632324219\n",
      "        - -0.08091163635253906\n",
      "        - 0.3953533172607422\n",
      "        - 0.13576126098632812\n",
      "        - -0.22700881958007812\n",
      "        - -0.40878868103027344\n",
      "        - -0.3488616943359375\n",
      "        - -0.6256866455078125\n",
      "        - -0.30614662170410156\n",
      "        - 0.03852653503417969\n",
      "        - 0.0051898956298828125\n",
      "        - -2.315790891647339\n",
      "        - 0.14886856079101562\n",
      "        - 0.13751602172851562\n",
      "        - -0.0402679443359375\n",
      "        - -0.40167808532714844\n",
      "        - 4.42734956741333\n",
      "        - 0.04106903076171875\n",
      "        - 1.8114700317382812\n",
      "        - -0.33321571350097656\n",
      "        - 0.3508472442626953\n",
      "        - -2.117359161376953\n",
      "        - -3.46256685256958\n",
      "        - -0.6323394775390625\n",
      "        - 0.22065162658691406\n",
      "        - 0.008939743041992188\n",
      "        - -0.276763916015625\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 88032\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 88032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 22\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.435714285714287\n",
      "    ram_util_percent: 16.371428571428574\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11348741312215554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11610993139108627\n",
      "    mean_inference_ms: 1.6525601226725057\n",
      "    mean_raw_obs_processing_ms: 0.25134543844113727\n",
      "  time_since_restore: 89.66401410102844\n",
      "  time_this_iter_s: 9.843374013900757\n",
      "  time_total_s: 89.66401410102844\n",
      "  timers:\n",
      "    learn_throughput: 7818.721\n",
      "    learn_time_ms: 4.093\n",
      "    load_throughput: 99923.859\n",
      "    load_time_ms: 0.32\n",
      "  timestamp: 1641218973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 12\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:35 (running for 00:01:36.64)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">          89.664</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">   91.89</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             91.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 13000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-38\n",
      "  done: false\n",
      "  episode_len_mean: 99.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 99.87\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 235\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 12592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 24.240392684936523\n",
      "          mean_q: 19.68633270263672\n",
      "          mean_td_error: 0.3112889528274536\n",
      "          min_q: 5.095141410827637\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.23892593383789062\n",
      "        - 0.025983810424804688\n",
      "        - 0.6449623107910156\n",
      "        - 0.11353397369384766\n",
      "        - 2.1205034255981445\n",
      "        - -1.0432987213134766\n",
      "        - -1.2102956771850586\n",
      "        - -0.2023468017578125\n",
      "        - -0.3027324676513672\n",
      "        - 0.31522178649902344\n",
      "        - -0.24595069885253906\n",
      "        - -0.2998695373535156\n",
      "        - -0.12215232849121094\n",
      "        - -0.621314525604248\n",
      "        - -0.011388778686523438\n",
      "        - 0.34641265869140625\n",
      "        - -0.3746166229248047\n",
      "        - 0.10138893127441406\n",
      "        - -0.39354705810546875\n",
      "        - -0.29114723205566406\n",
      "        - -1.3162002563476562\n",
      "        - 0.1303558349609375\n",
      "        - -3.8617916107177734\n",
      "        - 0.48000144958496094\n",
      "        - -0.5608272552490234\n",
      "        - -0.27550697326660156\n",
      "        - 17.939815521240234\n",
      "        - -0.4431018829345703\n",
      "        - -0.8091678619384766\n",
      "        - -0.02062511444091797\n",
      "        - 0.15697860717773438\n",
      "        - -0.24695587158203125\n",
      "    num_agent_steps_sampled: 13000\n",
      "    num_agent_steps_trained: 96032\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 96032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 24\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.457142857142856\n",
      "    ram_util_percent: 16.37142857142857\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11354710040208278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11611511223256009\n",
      "    mean_inference_ms: 1.6517357242562622\n",
      "    mean_raw_obs_processing_ms: 0.24967641547566002\n",
      "  time_since_restore: 94.88970446586609\n",
      "  time_this_iter_s: 5.2256903648376465\n",
      "  time_total_s: 94.88970446586609\n",
      "  timers:\n",
      "    learn_throughput: 8500.55\n",
      "    learn_time_ms: 3.764\n",
      "    load_throughput: 108091.913\n",
      "    load_time_ms: 0.296\n",
      "  timestamp: 1641218978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 13\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:40 (running for 00:01:41.91)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         94.8897</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">   99.87</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             99.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:45 (running for 00:01:46.92)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         94.8897</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">   99.87</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             99.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 14000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-48\n",
      "  done: false\n",
      "  episode_len_mean: 107.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 107.6\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 242\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 109.95\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 196.0\n",
      "    episode_reward_mean: 109.95\n",
      "    episode_reward_min: 91.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 116\n",
      "      - 115\n",
      "      - 103\n",
      "      - 99\n",
      "      - 125\n",
      "      - 196\n",
      "      - 96\n",
      "      - 98\n",
      "      - 98\n",
      "      - 93\n",
      "      - 120\n",
      "      - 94\n",
      "      - 101\n",
      "      - 135\n",
      "      - 97\n",
      "      - 99\n",
      "      - 112\n",
      "      - 91\n",
      "      - 102\n",
      "      - 109\n",
      "      episode_reward:\n",
      "      - 116.0\n",
      "      - 115.0\n",
      "      - 103.0\n",
      "      - 99.0\n",
      "      - 125.0\n",
      "      - 196.0\n",
      "      - 96.0\n",
      "      - 98.0\n",
      "      - 98.0\n",
      "      - 93.0\n",
      "      - 120.0\n",
      "      - 94.0\n",
      "      - 101.0\n",
      "      - 135.0\n",
      "      - 97.0\n",
      "      - 99.0\n",
      "      - 112.0\n",
      "      - 91.0\n",
      "      - 102.0\n",
      "      - 109.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1179098502920114\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11917486082524258\n",
      "      mean_inference_ms: 1.6669574244581404\n",
      "      mean_raw_obs_processing_ms: 0.1293876112556988\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 13600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 26.26418685913086\n",
      "          mean_q: 21.061586380004883\n",
      "          mean_td_error: 0.15317578613758087\n",
      "          min_q: 3.407654285430908\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.40535449981689453\n",
      "        - 0.17749977111816406\n",
      "        - -0.7800426483154297\n",
      "        - -0.21042823791503906\n",
      "        - -0.07359886169433594\n",
      "        - 0.22554969787597656\n",
      "        - 0.3222541809082031\n",
      "        - -0.11042976379394531\n",
      "        - -0.7884941101074219\n",
      "        - 0.5958061218261719\n",
      "        - 0.25000762939453125\n",
      "        - 0.4404430389404297\n",
      "        - -0.4420967102050781\n",
      "        - -0.7465000152587891\n",
      "        - -0.38036155700683594\n",
      "        - -0.2673206329345703\n",
      "        - 0.4493446350097656\n",
      "        - -0.8597793579101562\n",
      "        - -0.03254127502441406\n",
      "        - -0.1771526336669922\n",
      "        - 0.5605182647705078\n",
      "        - -0.3366851806640625\n",
      "        - -0.684417724609375\n",
      "        - 0.04153251647949219\n",
      "        - 0.7668380737304688\n",
      "        - 0.10199928283691406\n",
      "        - -0.38373565673828125\n",
      "        - 0.29770660400390625\n",
      "        - 8.667604446411133\n",
      "        - -0.4631624221801758\n",
      "        - -0.3447532653808594\n",
      "        - -1.319333553314209\n",
      "    num_agent_steps_sampled: 14000\n",
      "    num_agent_steps_trained: 104032\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 104032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 26\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.999999999999996\n",
      "    ram_util_percent: 16.392857142857146\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11355805316307847\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11608249343408979\n",
      "    mean_inference_ms: 1.6511233782953576\n",
      "    mean_raw_obs_processing_ms: 0.24869814272686874\n",
      "  time_since_restore: 104.43654942512512\n",
      "  time_this_iter_s: 9.546844959259033\n",
      "  time_total_s: 104.43654942512512\n",
      "  timers:\n",
      "    learn_throughput: 7752.022\n",
      "    learn_time_ms: 4.128\n",
      "    load_throughput: 84387.129\n",
      "    load_time_ms: 0.379\n",
      "  timestamp: 1641218988\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 14\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:51 (running for 00:01:52.50)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         104.437</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">   107.6</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             107.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 112.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 112.94\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 249\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 14608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 27.312744140625\n",
      "          mean_q: 20.481395721435547\n",
      "          mean_td_error: 0.5793314576148987\n",
      "          min_q: 0.16581737995147705\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.1632080078125\n",
      "        - 0.13450050354003906\n",
      "        - -0.11109352111816406\n",
      "        - -0.2098560333251953\n",
      "        - 0.2555694580078125\n",
      "        - -0.3261547088623047\n",
      "        - -2.3005599975585938\n",
      "        - 0.3816852569580078\n",
      "        - -0.03713226318359375\n",
      "        - 0.4027519226074219\n",
      "        - 2.079847574234009\n",
      "        - -0.09207725524902344\n",
      "        - 0.08263778686523438\n",
      "        - -0.5587825775146484\n",
      "        - 0.10915756225585938\n",
      "        - 0.28760719299316406\n",
      "        - -0.4195518493652344\n",
      "        - 0.1558074951171875\n",
      "        - -1.6057891845703125\n",
      "        - 0.1269702911376953\n",
      "        - 0.2701873779296875\n",
      "        - 1.4666657447814941\n",
      "        - 3.0031309127807617\n",
      "        - -0.4893608093261719\n",
      "        - 5.613243103027344\n",
      "        - -0.1409168243408203\n",
      "        - 1.8033380508422852\n",
      "        - 9.44024658203125\n",
      "        - -0.16814613342285156\n",
      "        - -0.1018829345703125\n",
      "        - -0.834182620048523\n",
      "        - 0.15753936767578125\n",
      "    num_agent_steps_sampled: 15000\n",
      "    num_agent_steps_trained: 112032\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 112032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 28\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.214285714285715\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11356735209726959\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11604264733194658\n",
      "    mean_inference_ms: 1.6504422495854991\n",
      "    mean_raw_obs_processing_ms: 0.24769054408535968\n",
      "  time_since_restore: 109.54273080825806\n",
      "  time_this_iter_s: 5.106181383132935\n",
      "  time_total_s: 109.54273080825806\n",
      "  timers:\n",
      "    learn_throughput: 8503.889\n",
      "    learn_time_ms: 3.763\n",
      "    load_throughput: 116619.8\n",
      "    load_time_ms: 0.274\n",
      "  timestamp: 1641218993\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 15\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:09:56 (running for 00:01:57.63)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         109.543</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">  112.94</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            112.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:01 (running for 00:02:02.64)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         109.543</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">  112.94</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            112.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 119.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 119.07\n",
      "  episode_reward_min: 18.0\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 257\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 137.2\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 146.0\n",
      "    episode_reward_mean: 137.2\n",
      "    episode_reward_min: 130.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 145\n",
      "      - 136\n",
      "      - 133\n",
      "      - 134\n",
      "      - 140\n",
      "      - 139\n",
      "      - 131\n",
      "      - 141\n",
      "      - 132\n",
      "      - 139\n",
      "      - 130\n",
      "      - 142\n",
      "      - 132\n",
      "      - 133\n",
      "      - 146\n",
      "      - 133\n",
      "      - 140\n",
      "      - 144\n",
      "      - 138\n",
      "      - 136\n",
      "      episode_reward:\n",
      "      - 145.0\n",
      "      - 136.0\n",
      "      - 133.0\n",
      "      - 134.0\n",
      "      - 140.0\n",
      "      - 139.0\n",
      "      - 131.0\n",
      "      - 141.0\n",
      "      - 132.0\n",
      "      - 139.0\n",
      "      - 130.0\n",
      "      - 142.0\n",
      "      - 132.0\n",
      "      - 133.0\n",
      "      - 146.0\n",
      "      - 133.0\n",
      "      - 140.0\n",
      "      - 144.0\n",
      "      - 138.0\n",
      "      - 136.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11775817503122654\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11892684075127884\n",
      "      mean_inference_ms: 1.6656177895205446\n",
      "      mean_raw_obs_processing_ms: 0.12918124671746906\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 15616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 29.903911590576172\n",
      "          mean_q: 21.725788116455078\n",
      "          mean_td_error: -0.19893550872802734\n",
      "          min_q: -2.38472056388855\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.502777099609375\n",
      "        - -0.16129493713378906\n",
      "        - 0.3398284912109375\n",
      "        - 0.4733924865722656\n",
      "        - -0.3128986358642578\n",
      "        - -0.29885101318359375\n",
      "        - -0.37928199768066406\n",
      "        - -0.37201881408691406\n",
      "        - 0.2767353057861328\n",
      "        - 0.03314781188964844\n",
      "        - -0.5391120910644531\n",
      "        - 0.4835472106933594\n",
      "        - -0.44112586975097656\n",
      "        - -0.4292449951171875\n",
      "        - 0.25076889991760254\n",
      "        - -0.5936717987060547\n",
      "        - -1.3292713165283203\n",
      "        - 2.176194429397583\n",
      "        - -0.00897979736328125\n",
      "        - -0.19918441772460938\n",
      "        - 0.02317047119140625\n",
      "        - -0.2341327667236328\n",
      "        - 1.2332229614257812\n",
      "        - -0.3501262664794922\n",
      "        - -0.41732215881347656\n",
      "        - -0.3740234375\n",
      "        - -0.28545188903808594\n",
      "        - -0.4151039123535156\n",
      "        - -3.38472056388855\n",
      "        - 0.04401588439941406\n",
      "        - 0.2896995544433594\n",
      "        - -0.9610652923583984\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 120032\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 120032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 30\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.81875\n",
      "    ram_util_percent: 16.4\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11360991199539085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1160335975908607\n",
      "    mean_inference_ms: 1.6501024982772174\n",
      "    mean_raw_obs_processing_ms: 0.24662252556150643\n",
      "  time_since_restore: 120.4366226196289\n",
      "  time_this_iter_s: 10.89389181137085\n",
      "  time_total_s: 120.4366226196289\n",
      "  timers:\n",
      "    learn_throughput: 7261.921\n",
      "    learn_time_ms: 4.407\n",
      "    load_throughput: 82799.339\n",
      "    load_time_ms: 0.386\n",
      "  timestamp: 1641219004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 16\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:07 (running for 00:02:08.59)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         120.437</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">  119.07</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">            119.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 17000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-09\n",
      "  done: false\n",
      "  episode_len_mean: 123.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 123.9\n",
      "  episode_reward_min: 18.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 264\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 16624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 30.771207809448242\n",
      "          mean_q: 26.14531898498535\n",
      "          mean_td_error: 1.2169363498687744\n",
      "          min_q: 3.239595413208008\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.2193737030029297\n",
      "        - 0.5315093994140625\n",
      "        - 0.03572654724121094\n",
      "        - 0.28644561767578125\n",
      "        - -0.05496025085449219\n",
      "        - -0.03824806213378906\n",
      "        - 11.688021659851074\n",
      "        - 0.2617073059082031\n",
      "        - 0.2195587158203125\n",
      "        - 0.1622638702392578\n",
      "        - 0.18636512756347656\n",
      "        - 1.1060352325439453\n",
      "        - 20.1116943359375\n",
      "        - 0.5257377624511719\n",
      "        - 0.3563957214355469\n",
      "        - -0.4975624084472656\n",
      "        - -0.11806678771972656\n",
      "        - -0.023626327514648438\n",
      "        - 0.17093849182128906\n",
      "        - -0.09170341491699219\n",
      "        - 0.053684234619140625\n",
      "        - 0.2601947784423828\n",
      "        - -0.08892822265625\n",
      "        - 0.4537506103515625\n",
      "        - -0.56402587890625\n",
      "        - -0.1821613311767578\n",
      "        - 2.239595413208008\n",
      "        - -0.016262054443359375\n",
      "        - 0.2150592803955078\n",
      "        - -0.33545494079589844\n",
      "        - 0.2841644287109375\n",
      "        - 0.5847396850585938\n",
      "    num_agent_steps_sampled: 17000\n",
      "    num_agent_steps_trained: 128032\n",
      "    num_steps_sampled: 17000\n",
      "    num_steps_trained: 128032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 32\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.0375\n",
      "    ram_util_percent: 16.2875\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1136780438005672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11607150113840853\n",
      "    mean_inference_ms: 1.6504005944180262\n",
      "    mean_raw_obs_processing_ms: 0.24588147936166588\n",
      "  time_since_restore: 125.84976840019226\n",
      "  time_this_iter_s: 5.4131457805633545\n",
      "  time_total_s: 125.84976840019226\n",
      "  timers:\n",
      "    learn_throughput: 7766.78\n",
      "    learn_time_ms: 4.12\n",
      "    load_throughput: 92176.175\n",
      "    load_time_ms: 0.347\n",
      "  timestamp: 1641219009\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 17000\n",
      "  training_iteration: 17\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:12 (running for 00:02:14.05)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          125.85</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">   123.9</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">             123.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:17 (running for 00:02:19.05)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          125.85</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">   123.9</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">             123.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:22 (running for 00:02:24.06)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          125.85</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">   123.9</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">             123.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 18000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-25\n",
      "  done: false\n",
      "  episode_len_mean: 130.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 130.77\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 270\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 274.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 430.0\n",
      "    episode_reward_mean: 274.0\n",
      "    episode_reward_min: 208.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 257\n",
      "      - 239\n",
      "      - 274\n",
      "      - 357\n",
      "      - 248\n",
      "      - 213\n",
      "      - 430\n",
      "      - 249\n",
      "      - 262\n",
      "      - 245\n",
      "      - 283\n",
      "      - 271\n",
      "      - 246\n",
      "      - 208\n",
      "      - 251\n",
      "      - 239\n",
      "      - 384\n",
      "      - 248\n",
      "      - 317\n",
      "      - 259\n",
      "      episode_reward:\n",
      "      - 257.0\n",
      "      - 239.0\n",
      "      - 274.0\n",
      "      - 357.0\n",
      "      - 248.0\n",
      "      - 213.0\n",
      "      - 430.0\n",
      "      - 249.0\n",
      "      - 262.0\n",
      "      - 245.0\n",
      "      - 283.0\n",
      "      - 271.0\n",
      "      - 246.0\n",
      "      - 208.0\n",
      "      - 251.0\n",
      "      - 239.0\n",
      "      - 384.0\n",
      "      - 248.0\n",
      "      - 317.0\n",
      "      - 259.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11722142039345107\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11837802364327817\n",
      "      mean_inference_ms: 1.6565088554515228\n",
      "      mean_raw_obs_processing_ms: 0.12810093310368711\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 17632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 32.12601089477539\n",
      "          mean_q: 26.078956604003906\n",
      "          mean_td_error: 0.944608747959137\n",
      "          min_q: 13.13309383392334\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.38324928283691406\n",
      "        - -0.1412677764892578\n",
      "        - -0.17278671264648438\n",
      "        - -0.19312095642089844\n",
      "        - 16.651103973388672\n",
      "        - 0.2075672149658203\n",
      "        - -0.7478237152099609\n",
      "        - -0.4300041198730469\n",
      "        - 0.22080421447753906\n",
      "        - 0.7809906005859375\n",
      "        - -1.2727127075195312\n",
      "        - 0.18468666076660156\n",
      "        - -0.025676727294921875\n",
      "        - 0.06199836730957031\n",
      "        - -0.29523277282714844\n",
      "        - -0.47135066986083984\n",
      "        - 1.1218223571777344\n",
      "        - -0.14364242553710938\n",
      "        - -0.07580184936523438\n",
      "        - 14.543622016906738\n",
      "        - -0.6408882141113281\n",
      "        - 0.4129161834716797\n",
      "        - -0.6130409240722656\n",
      "        - -0.5374050140380859\n",
      "        - 1.0144424438476562\n",
      "        - 0.25913429260253906\n",
      "        - 0.4410419464111328\n",
      "        - -0.1208953857421875\n",
      "        - -0.6963615417480469\n",
      "        - -0.06578254699707031\n",
      "        - 0.4574451446533203\n",
      "        - 0.1304492950439453\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 136032\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 136032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 34\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.327272727272728\n",
      "    ram_util_percent: 16.090909090909093\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11373720273248306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11610178735358755\n",
      "    mean_inference_ms: 1.650648008317694\n",
      "    mean_raw_obs_processing_ms: 0.24521860256472286\n",
      "  time_since_restore: 141.89914655685425\n",
      "  time_this_iter_s: 16.049378156661987\n",
      "  time_total_s: 141.89914655685425\n",
      "  timers:\n",
      "    learn_throughput: 8407.683\n",
      "    learn_time_ms: 3.806\n",
      "    load_throughput: 105442.476\n",
      "    load_time_ms: 0.303\n",
      "  timestamp: 1641219025\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 18\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:27 (running for 00:02:29.14)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         141.899</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">  130.77</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            130.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 19000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-31\n",
      "  done: false\n",
      "  episode_len_mean: 137.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 137.42\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 275\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 18640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 33.33149337768555\n",
      "          mean_q: 27.04502296447754\n",
      "          mean_td_error: 0.05205206573009491\n",
      "          min_q: 0.4137357473373413\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.11792564392089844\n",
      "        - -0.10587310791015625\n",
      "        - 0.1551055908203125\n",
      "        - 0.0334320068359375\n",
      "        - 0.19577598571777344\n",
      "        - -0.12938690185546875\n",
      "        - -0.05126190185546875\n",
      "        - -0.255950927734375\n",
      "        - -1.2046527862548828\n",
      "        - -0.30475425720214844\n",
      "        - -0.0616607666015625\n",
      "        - 0.1528949737548828\n",
      "        - 0.25950050354003906\n",
      "        - 0.29740333557128906\n",
      "        - -0.163787841796875\n",
      "        - 0.26825714111328125\n",
      "        - -0.5862642526626587\n",
      "        - 0.18203163146972656\n",
      "        - 0.005947113037109375\n",
      "        - -0.3083171844482422\n",
      "        - -0.4635581970214844\n",
      "        - 6.281455039978027\n",
      "        - -1.4072484970092773\n",
      "        - -0.8129940032958984\n",
      "        - -0.2812824249267578\n",
      "        - 0.009775161743164062\n",
      "        - -0.33889007568359375\n",
      "        - -0.12875938415527344\n",
      "        - -0.30694007873535156\n",
      "        - 0.27138519287109375\n",
      "        - 0.031452178955078125\n",
      "        - 0.5507583618164062\n",
      "    num_agent_steps_sampled: 19000\n",
      "    num_agent_steps_trained: 144032\n",
      "    num_steps_sampled: 19000\n",
      "    num_steps_trained: 144032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 36\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.6625\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11381157694774101\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11615914491331289\n",
      "    mean_inference_ms: 1.6512162217976785\n",
      "    mean_raw_obs_processing_ms: 0.24477911039717185\n",
      "  time_since_restore: 147.25918006896973\n",
      "  time_this_iter_s: 5.3600335121154785\n",
      "  time_total_s: 147.25918006896973\n",
      "  timers:\n",
      "    learn_throughput: 6996.993\n",
      "    learn_time_ms: 4.573\n",
      "    load_throughput: 79137.811\n",
      "    load_time_ms: 0.404\n",
      "  timestamp: 1641219031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 19000\n",
      "  training_iteration: 19\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:33 (running for 00:02:34.55)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         147.259</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">  137.42</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            137.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:38 (running for 00:02:39.56)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         147.259</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">  137.42</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            137.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 141.7\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 284\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 51.3\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 60.0\n",
      "    episode_reward_mean: 51.3\n",
      "    episode_reward_min: 39.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 42\n",
      "      - 39\n",
      "      - 51\n",
      "      - 57\n",
      "      - 47\n",
      "      - 60\n",
      "      - 51\n",
      "      - 60\n",
      "      - 47\n",
      "      - 50\n",
      "      - 51\n",
      "      - 60\n",
      "      - 51\n",
      "      - 59\n",
      "      - 53\n",
      "      - 46\n",
      "      - 44\n",
      "      - 48\n",
      "      - 55\n",
      "      - 55\n",
      "      episode_reward:\n",
      "      - 42.0\n",
      "      - 39.0\n",
      "      - 51.0\n",
      "      - 57.0\n",
      "      - 47.0\n",
      "      - 60.0\n",
      "      - 51.0\n",
      "      - 60.0\n",
      "      - 47.0\n",
      "      - 50.0\n",
      "      - 51.0\n",
      "      - 60.0\n",
      "      - 51.0\n",
      "      - 59.0\n",
      "      - 53.0\n",
      "      - 46.0\n",
      "      - 44.0\n",
      "      - 48.0\n",
      "      - 55.0\n",
      "      - 55.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11776341943797677\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11890942742672228\n",
      "      mean_inference_ms: 1.6642427106352151\n",
      "      mean_raw_obs_processing_ms: 0.12901263277644148\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 19648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 34.52042007446289\n",
      "          mean_q: 27.6785945892334\n",
      "          mean_td_error: 1.318054437637329\n",
      "          min_q: 0.6603965163230896\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -1.0543994903564453\n",
      "        - 21.166799545288086\n",
      "        - -0.0060272216796875\n",
      "        - 0.15493392944335938\n",
      "        - -0.042964935302734375\n",
      "        - -2.2149505615234375\n",
      "        - 0.1855335235595703\n",
      "        - -1.729043960571289\n",
      "        - 0.07731246948242188\n",
      "        - -0.21200180053710938\n",
      "        - 0.06028175354003906\n",
      "        - -0.3756256103515625\n",
      "        - 0.290069580078125\n",
      "        - -0.9111518859863281\n",
      "        - 1.9159393310546875\n",
      "        - 0.36749267578125\n",
      "        - 0.5521774291992188\n",
      "        - -0.072021484375\n",
      "        - 0.3569984436035156\n",
      "        - -0.15512657165527344\n",
      "        - -0.22026443481445312\n",
      "        - 0.4442901611328125\n",
      "        - 24.31413459777832\n",
      "        - -0.2349853515625\n",
      "        - 0.18031883239746094\n",
      "        - -0.3396034836769104\n",
      "        - 0.40625\n",
      "        - -0.36974334716796875\n",
      "        - -0.44551849365234375\n",
      "        - -0.03658103942871094\n",
      "        - -0.12049102783203125\n",
      "        - 0.2457122802734375\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 152032\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 152032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 38\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.9\n",
      "    ram_util_percent: 16.300000000000004\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11397783058322136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11630224202727402\n",
      "    mean_inference_ms: 1.6526926136078373\n",
      "    mean_raw_obs_processing_ms: 0.24413652930707225\n",
      "  time_since_restore: 154.85600686073303\n",
      "  time_this_iter_s: 7.596826791763306\n",
      "  time_total_s: 154.85600686073303\n",
      "  timers:\n",
      "    learn_throughput: 7781.324\n",
      "    learn_time_ms: 4.112\n",
      "    load_throughput: 95637.543\n",
      "    load_time_ms: 0.335\n",
      "  timestamp: 1641219038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 20\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:43 (running for 00:02:45.21)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         154.856</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">   141.7</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             141.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 21000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-43\n",
      "  done: false\n",
      "  episode_len_mean: 132.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 450.0\n",
      "  episode_reward_mean: 132.5\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 296\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 20656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 37.125335693359375\n",
      "          mean_q: 30.329360961914062\n",
      "          mean_td_error: 2.2366037368774414\n",
      "          min_q: 3.181696891784668\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.4066810607910156\n",
      "        - -0.050579071044921875\n",
      "        - -0.7206497192382812\n",
      "        - -0.214019775390625\n",
      "        - 0.18973541259765625\n",
      "        - 0.5616340637207031\n",
      "        - -2.3867034912109375\n",
      "        - -3.3155269622802734\n",
      "        - 20.807849884033203\n",
      "        - 0.07364273071289062\n",
      "        - -0.3014640808105469\n",
      "        - -0.448394775390625\n",
      "        - 0.6923446655273438\n",
      "        - -0.8865623474121094\n",
      "        - 0.3847179412841797\n",
      "        - 27.623214721679688\n",
      "        - 9.364432334899902\n",
      "        - 17.796825408935547\n",
      "        - 0.31519317626953125\n",
      "        - 0.06537246704101562\n",
      "        - 0.02785491943359375\n",
      "        - 0.756439208984375\n",
      "        - -0.2629661560058594\n",
      "        - -0.31781768798828125\n",
      "        - 0.62384033203125\n",
      "        - 0.4348182678222656\n",
      "        - 0.09776687622070312\n",
      "        - 0.0755157470703125\n",
      "        - 0.2367687225341797\n",
      "        - 0.25606536865234375\n",
      "        - 0.21258163452148438\n",
      "        - 0.2860679626464844\n",
      "    num_agent_steps_sampled: 21000\n",
      "    num_agent_steps_trained: 160032\n",
      "    num_steps_sampled: 21000\n",
      "    num_steps_trained: 160032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 40\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.5\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11424970222684476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11654914282947854\n",
      "    mean_inference_ms: 1.655595070909661\n",
      "    mean_raw_obs_processing_ms: 0.2436873151582079\n",
      "  time_since_restore: 159.95429158210754\n",
      "  time_this_iter_s: 5.098284721374512\n",
      "  time_total_s: 159.95429158210754\n",
      "  timers:\n",
      "    learn_throughput: 7779.25\n",
      "    learn_time_ms: 4.114\n",
      "    load_throughput: 86709.56\n",
      "    load_time_ms: 0.369\n",
      "  timestamp: 1641219043\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 21\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:48 (running for 00:02:50.34)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         159.954</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">   132.5</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             132.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:53 (running for 00:02:55.35)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         159.954</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">   132.5</td><td style=\"text-align: right;\">                 450</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             132.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 22000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-10-54\n",
      "  done: false\n",
      "  episode_len_mean: 124.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 124.49\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 304\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 151.25\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 166.0\n",
      "    episode_reward_mean: 151.25\n",
      "    episode_reward_min: 139.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 155\n",
      "      - 146\n",
      "      - 143\n",
      "      - 144\n",
      "      - 146\n",
      "      - 146\n",
      "      - 142\n",
      "      - 143\n",
      "      - 160\n",
      "      - 139\n",
      "      - 158\n",
      "      - 162\n",
      "      - 165\n",
      "      - 152\n",
      "      - 166\n",
      "      - 148\n",
      "      - 153\n",
      "      - 144\n",
      "      - 158\n",
      "      - 155\n",
      "      episode_reward:\n",
      "      - 155.0\n",
      "      - 146.0\n",
      "      - 143.0\n",
      "      - 144.0\n",
      "      - 146.0\n",
      "      - 146.0\n",
      "      - 142.0\n",
      "      - 143.0\n",
      "      - 160.0\n",
      "      - 139.0\n",
      "      - 158.0\n",
      "      - 162.0\n",
      "      - 165.0\n",
      "      - 152.0\n",
      "      - 166.0\n",
      "      - 148.0\n",
      "      - 153.0\n",
      "      - 144.0\n",
      "      - 158.0\n",
      "      - 155.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11725067192394552\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11838666110763722\n",
      "      mean_inference_ms: 1.6575165764125401\n",
      "      mean_raw_obs_processing_ms: 0.12838339659512227\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 21664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 38.354923248291016\n",
      "          mean_q: 32.05277633666992\n",
      "          mean_td_error: -0.09947963804006577\n",
      "          min_q: 2.5360138416290283\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.5014381408691406\n",
      "        - -0.33074188232421875\n",
      "        - 0.14171600341796875\n",
      "        - -0.5129508972167969\n",
      "        - -1.7555809020996094\n",
      "        - -0.00475311279296875\n",
      "        - -0.7062110900878906\n",
      "        - -0.5300140380859375\n",
      "        - -1.7179756164550781\n",
      "        - -0.6583175659179688\n",
      "        - 0.2051219940185547\n",
      "        - 0.6412086486816406\n",
      "        - -0.4235248565673828\n",
      "        - -0.09043121337890625\n",
      "        - -2.812358856201172\n",
      "        - -0.3325691223144531\n",
      "        - -0.3995628356933594\n",
      "        - -0.24088287353515625\n",
      "        - 3.997335433959961\n",
      "        - -0.9228782653808594\n",
      "        - 0.48114776611328125\n",
      "        - -1.1142845153808594\n",
      "        - 0.3433837890625\n",
      "        - 1.5360138416290283\n",
      "        - -0.11947250366210938\n",
      "        - 0.6426582336425781\n",
      "        - -0.5283164978027344\n",
      "        - 1.5466251373291016\n",
      "        - -0.332305908203125\n",
      "        - 1.0718402862548828\n",
      "        - -0.5662803649902344\n",
      "        - 0.8104515075683594\n",
      "    num_agent_steps_sampled: 22000\n",
      "    num_agent_steps_trained: 168032\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 168032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 42\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.543750000000003\n",
      "    ram_util_percent: 16.356250000000003\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11436409214996006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11664285861341823\n",
      "    mean_inference_ms: 1.6568338086082128\n",
      "    mean_raw_obs_processing_ms: 0.24348332896068492\n",
      "  time_since_restore: 170.7332365512848\n",
      "  time_this_iter_s: 10.778944969177246\n",
      "  time_total_s: 170.7332365512848\n",
      "  timers:\n",
      "    learn_throughput: 8423.724\n",
      "    learn_time_ms: 3.799\n",
      "    load_throughput: 116065.14\n",
      "    load_time_ms: 0.276\n",
      "  timestamp: 1641219054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 22\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:10:59 (running for 00:03:01.10)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         175.656</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">  128.09</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            128.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:04 (running for 00:03:06.12)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         175.656</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">  128.09</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            128.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:09 (running for 00:03:11.13)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         175.656</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">  128.09</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            128.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 126.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 126.95\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 317\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 148.15\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 166.0\n",
      "    episode_reward_mean: 148.15\n",
      "    episode_reward_min: 136.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 136\n",
      "      - 155\n",
      "      - 141\n",
      "      - 152\n",
      "      - 148\n",
      "      - 156\n",
      "      - 140\n",
      "      - 151\n",
      "      - 146\n",
      "      - 141\n",
      "      - 155\n",
      "      - 145\n",
      "      - 151\n",
      "      - 143\n",
      "      - 136\n",
      "      - 155\n",
      "      - 163\n",
      "      - 136\n",
      "      - 166\n",
      "      - 147\n",
      "      episode_reward:\n",
      "      - 136.0\n",
      "      - 155.0\n",
      "      - 141.0\n",
      "      - 152.0\n",
      "      - 148.0\n",
      "      - 156.0\n",
      "      - 140.0\n",
      "      - 151.0\n",
      "      - 146.0\n",
      "      - 141.0\n",
      "      - 155.0\n",
      "      - 145.0\n",
      "      - 151.0\n",
      "      - 143.0\n",
      "      - 136.0\n",
      "      - 155.0\n",
      "      - 163.0\n",
      "      - 136.0\n",
      "      - 166.0\n",
      "      - 147.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11743605595340392\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11852012620427912\n",
      "      mean_inference_ms: 1.6597606799659872\n",
      "      mean_raw_obs_processing_ms: 0.12851563917806383\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 23680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 40.671321868896484\n",
      "          mean_q: 33.718597412109375\n",
      "          mean_td_error: 1.319394588470459\n",
      "          min_q: 0.19858229160308838\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.5799369812011719\n",
      "        - -1.8321952819824219\n",
      "        - -0.0511322021484375\n",
      "        - -0.024265289306640625\n",
      "        - 19.43085479736328\n",
      "        - 0.16215133666992188\n",
      "        - -0.07135391235351562\n",
      "        - -0.14537811279296875\n",
      "        - -0.018375396728515625\n",
      "        - -0.30248260498046875\n",
      "        - 0.3309478759765625\n",
      "        - -0.06994247436523438\n",
      "        - -0.20069122314453125\n",
      "        - 0.35997772216796875\n",
      "        - 26.058334350585938\n",
      "        - -0.06293487548828125\n",
      "        - 0.23128700256347656\n",
      "        - 0.5850791931152344\n",
      "        - -0.8014177083969116\n",
      "        - -0.14577102661132812\n",
      "        - -0.27863311767578125\n",
      "        - -0.07069015502929688\n",
      "        - 0.11564826965332031\n",
      "        - 0.32888031005859375\n",
      "        - -0.25671958923339844\n",
      "        - -0.43378448486328125\n",
      "        - -0.038265228271484375\n",
      "        - 0.12965011596679688\n",
      "        - -0.03995513916015625\n",
      "        - 0.21020889282226562\n",
      "        - -0.12292861938476562\n",
      "        - -0.17554092407226562\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 184032\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 184032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 46\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.9875\n",
      "    ram_util_percent: 16.4\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11455874628595493\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11681397998571845\n",
      "    mean_inference_ms: 1.6590279043621265\n",
      "    mean_raw_obs_processing_ms: 0.24329266669672528\n",
      "  time_since_restore: 187.21074843406677\n",
      "  time_this_iter_s: 11.554478406906128\n",
      "  time_total_s: 187.21074843406677\n",
      "  timers:\n",
      "    learn_throughput: 8015.2\n",
      "    learn_time_ms: 3.992\n",
      "    load_throughput: 87284.729\n",
      "    load_time_ms: 0.367\n",
      "  timestamp: 1641219071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 24\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:15 (running for 00:03:16.72)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         187.211</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">  126.95</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            126.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 25000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-16\n",
      "  done: false\n",
      "  episode_len_mean: 131.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 131.64\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 323\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 24688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 41.432472229003906\n",
      "          mean_q: 33.00265121459961\n",
      "          mean_td_error: 1.6951930522918701\n",
      "          min_q: -3.809736490249634\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.003086090087890625\n",
      "        - 0.14130592346191406\n",
      "        - -0.20502853393554688\n",
      "        - 0.18911361694335938\n",
      "        - 0.6451454162597656\n",
      "        - -0.3700141906738281\n",
      "        - 0.5270557403564453\n",
      "        - -0.077392578125\n",
      "        - -0.1662139892578125\n",
      "        - 0.3441963195800781\n",
      "        - -0.392364501953125\n",
      "        - 0.2730064392089844\n",
      "        - 0.09854507446289062\n",
      "        - 22.27113914489746\n",
      "        - 0.02043914794921875\n",
      "        - -3.6961898803710938\n",
      "        - 0.1746978759765625\n",
      "        - 0.42093658447265625\n",
      "        - 0.5088691711425781\n",
      "        - -0.00447845458984375\n",
      "        - -0.15884017944335938\n",
      "        - 20.38479232788086\n",
      "        - -0.21910858154296875\n",
      "        - -4.809736251831055\n",
      "        - 0.5306854248046875\n",
      "        - -0.1938343048095703\n",
      "        - 0.5077362060546875\n",
      "        - 0.053516387939453125\n",
      "        - 0.2795867919921875\n",
      "        - 0.39508628845214844\n",
      "        - 16.155750274658203\n",
      "        - 0.6208629608154297\n",
      "    num_agent_steps_sampled: 25000\n",
      "    num_agent_steps_trained: 192032\n",
      "    num_steps_sampled: 25000\n",
      "    num_steps_trained: 192032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 48\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.1\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11462022723640558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11685865359460074\n",
      "    mean_inference_ms: 1.6596643737129175\n",
      "    mean_raw_obs_processing_ms: 0.24316701390623371\n",
      "  time_since_restore: 192.19334483146667\n",
      "  time_this_iter_s: 4.982596397399902\n",
      "  time_total_s: 192.19334483146667\n",
      "  timers:\n",
      "    learn_throughput: 7721.562\n",
      "    learn_time_ms: 4.144\n",
      "    load_throughput: 87001.833\n",
      "    load_time_ms: 0.368\n",
      "  timestamp: 1641219076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 25000\n",
      "  training_iteration: 25\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:20 (running for 00:03:21.73)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         192.193</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">  131.64</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            131.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:25 (running for 00:03:26.74)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         192.193</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">  131.64</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            131.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 26000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-25\n",
      "  done: false\n",
      "  episode_len_mean: 135.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 135.72\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 329\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 108.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 115.0\n",
      "    episode_reward_mean: 108.5\n",
      "    episode_reward_min: 105.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 107\n",
      "      - 105\n",
      "      - 110\n",
      "      - 106\n",
      "      - 108\n",
      "      - 110\n",
      "      - 107\n",
      "      - 109\n",
      "      - 113\n",
      "      - 105\n",
      "      - 109\n",
      "      - 112\n",
      "      - 106\n",
      "      - 106\n",
      "      - 113\n",
      "      - 107\n",
      "      - 106\n",
      "      - 107\n",
      "      - 109\n",
      "      - 115\n",
      "      episode_reward:\n",
      "      - 107.0\n",
      "      - 105.0\n",
      "      - 110.0\n",
      "      - 106.0\n",
      "      - 108.0\n",
      "      - 110.0\n",
      "      - 107.0\n",
      "      - 109.0\n",
      "      - 113.0\n",
      "      - 105.0\n",
      "      - 109.0\n",
      "      - 112.0\n",
      "      - 106.0\n",
      "      - 106.0\n",
      "      - 113.0\n",
      "      - 107.0\n",
      "      - 106.0\n",
      "      - 107.0\n",
      "      - 109.0\n",
      "      - 115.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11723188414351424\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11834666566140213\n",
      "      mean_inference_ms: 1.6570980572513458\n",
      "      mean_raw_obs_processing_ms: 0.12841243099165117\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 25696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 43.50128173828125\n",
      "          mean_q: 36.95145034790039\n",
      "          mean_td_error: 2.331296920776367\n",
      "          min_q: 18.01629066467285\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.3821601867675781\n",
      "        - 0.7158203125\n",
      "        - -0.5336723327636719\n",
      "        - 0.1832866668701172\n",
      "        - 0.058872222900390625\n",
      "        - -1.9710502624511719\n",
      "        - 0.3671417236328125\n",
      "        - -0.8501358032226562\n",
      "        - 4.15286922454834\n",
      "        - -0.132232666015625\n",
      "        - -0.09940719604492188\n",
      "        - 28.294424057006836\n",
      "        - -0.3096351623535156\n",
      "        - 0.22979736328125\n",
      "        - 0.23268890380859375\n",
      "        - 0.18223190307617188\n",
      "        - 0.5959205627441406\n",
      "        - 0.08181381225585938\n",
      "        - -0.266357421875\n",
      "        - -0.058925628662109375\n",
      "        - 0.1535491943359375\n",
      "        - 22.847864151000977\n",
      "        - -0.193603515625\n",
      "        - 0.15105819702148438\n",
      "        - -0.11526107788085938\n",
      "        - 20.324140548706055\n",
      "        - 0.018177032470703125\n",
      "        - -0.4226531982421875\n",
      "        - 0.3296470642089844\n",
      "        - -0.3489036560058594\n",
      "        - 0.6663169860839844\n",
      "        - -0.0644378662109375\n",
      "    num_agent_steps_sampled: 26000\n",
      "    num_agent_steps_trained: 200032\n",
      "    num_steps_sampled: 26000\n",
      "    num_steps_trained: 200032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 50\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.52857142857143\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11466574194812956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11688456289075502\n",
      "    mean_inference_ms: 1.6600589880775587\n",
      "    mean_raw_obs_processing_ms: 0.24302051260786342\n",
      "  time_since_restore: 201.56881499290466\n",
      "  time_this_iter_s: 9.375470161437988\n",
      "  time_total_s: 201.56881499290466\n",
      "  timers:\n",
      "    learn_throughput: 9407.961\n",
      "    learn_time_ms: 3.401\n",
      "    load_throughput: 155129.135\n",
      "    load_time_ms: 0.206\n",
      "  timestamp: 1641219085\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 26000\n",
      "  training_iteration: 26\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:30 (running for 00:03:32.16)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         201.569</td><td style=\"text-align: right;\">26000</td><td style=\"text-align: right;\">  135.72</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            135.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 27000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-30\n",
      "  done: false\n",
      "  episode_len_mean: 134.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 134.88\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 339\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 26704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 44.176116943359375\n",
      "          mean_q: 36.32344436645508\n",
      "          mean_td_error: 1.6983642578125\n",
      "          min_q: 6.016007423400879\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.6635704040527344\n",
      "        - 0.32772064208984375\n",
      "        - 0.19774436950683594\n",
      "        - 0.7230224609375\n",
      "        - 1.0729942321777344\n",
      "        - 0.2630043029785156\n",
      "        - 0.09472274780273438\n",
      "        - 0.13047027587890625\n",
      "        - 0.23093414306640625\n",
      "        - 0.2507820129394531\n",
      "        - 0.196136474609375\n",
      "        - 0.04013824462890625\n",
      "        - 5.016007423400879\n",
      "        - 0.2677764892578125\n",
      "        - 0.08546257019042969\n",
      "        - 0.26885986328125\n",
      "        - -0.3794746398925781\n",
      "        - 0.016834259033203125\n",
      "        - -0.09505844116210938\n",
      "        - 0.3625946044921875\n",
      "        - -0.02880859375\n",
      "        - 24.992610931396484\n",
      "        - 16.050762176513672\n",
      "        - 0.4693412780761719\n",
      "        - 0.7756423950195312\n",
      "        - 0.2713813781738281\n",
      "        - -0.2536163330078125\n",
      "        - -0.1283721923828125\n",
      "        - -0.014171600341796875\n",
      "        - 0.3885498046875\n",
      "        - 0.19522857666015625\n",
      "        - 0.894866943359375\n",
      "    num_agent_steps_sampled: 27000\n",
      "    num_agent_steps_trained: 208032\n",
      "    num_steps_sampled: 27000\n",
      "    num_steps_trained: 208032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 52\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.228571428571428\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11471236276988091\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11690029245453273\n",
      "    mean_inference_ms: 1.660363178447486\n",
      "    mean_raw_obs_processing_ms: 0.24275859446488032\n",
      "  time_since_restore: 206.65689611434937\n",
      "  time_this_iter_s: 5.088081121444702\n",
      "  time_total_s: 206.65689611434937\n",
      "  timers:\n",
      "    learn_throughput: 8164.94\n",
      "    learn_time_ms: 3.919\n",
      "    load_throughput: 101052.348\n",
      "    load_time_ms: 0.317\n",
      "  timestamp: 1641219090\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 27\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:35 (running for 00:03:37.29)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         206.657</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">  134.88</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            134.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-39\n",
      "  done: false\n",
      "  episode_len_mean: 131.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 131.12\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 348\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 98.4\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 102.0\n",
      "    episode_reward_mean: 98.4\n",
      "    episode_reward_min: 94.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 96\n",
      "      - 94\n",
      "      - 96\n",
      "      - 100\n",
      "      - 95\n",
      "      - 98\n",
      "      - 99\n",
      "      - 101\n",
      "      - 101\n",
      "      - 101\n",
      "      - 101\n",
      "      - 102\n",
      "      - 98\n",
      "      - 98\n",
      "      - 102\n",
      "      - 95\n",
      "      - 95\n",
      "      - 100\n",
      "      - 96\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 96.0\n",
      "      - 94.0\n",
      "      - 96.0\n",
      "      - 100.0\n",
      "      - 95.0\n",
      "      - 98.0\n",
      "      - 99.0\n",
      "      - 101.0\n",
      "      - 101.0\n",
      "      - 101.0\n",
      "      - 101.0\n",
      "      - 102.0\n",
      "      - 98.0\n",
      "      - 98.0\n",
      "      - 102.0\n",
      "      - 95.0\n",
      "      - 95.0\n",
      "      - 100.0\n",
      "      - 96.0\n",
      "      - 100.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11725758230842358\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11828583400842925\n",
      "      mean_inference_ms: 1.6568685593042833\n",
      "      mean_raw_obs_processing_ms: 0.12859922048826927\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 27712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 45.02077102661133\n",
      "          mean_q: 33.11648941040039\n",
      "          mean_td_error: 2.8749682903289795\n",
      "          min_q: 0.0005220025777816772\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.5081987380981445\n",
      "        - 0.8819580078125\n",
      "        - -0.24718475341796875\n",
      "        - -0.6797218322753906\n",
      "        - -0.73162841796875\n",
      "        - -0.27610015869140625\n",
      "        - 36.497032165527344\n",
      "        - 1.6834415197372437\n",
      "        - 1.3889350891113281\n",
      "        - -0.3653068542480469\n",
      "        - -0.4320182800292969\n",
      "        - -0.6662788391113281\n",
      "        - -0.3724937438964844\n",
      "        - -0.688140869140625\n",
      "        - -0.06586456298828125\n",
      "        - -0.7097263336181641\n",
      "        - 23.322673797607422\n",
      "        - -0.5054340362548828\n",
      "        - 0.14369964599609375\n",
      "        - 0.7404518127441406\n",
      "        - -0.3474311828613281\n",
      "        - 1.79803466796875\n",
      "        - -1.0557222366333008\n",
      "        - 0.17821216583251953\n",
      "        - 0.66253662109375\n",
      "        - 0.3893623352050781\n",
      "        - 0.7703285217285156\n",
      "        - 28.7894287109375\n",
      "        - -0.38336181640625\n",
      "        - -0.5038719177246094\n",
      "        - 0.321014404296875\n",
      "        - 0.9539623260498047\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 216032\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 216032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 54\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.723076923076924\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11471263442622945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11688309267716501\n",
      "    mean_inference_ms: 1.6602349381644919\n",
      "    mean_raw_obs_processing_ms: 0.24248397128209184\n",
      "  time_since_restore: 215.53247690200806\n",
      "  time_this_iter_s: 8.875580787658691\n",
      "  time_total_s: 215.53247690200806\n",
      "  timers:\n",
      "    learn_throughput: 7666.824\n",
      "    learn_time_ms: 4.174\n",
      "    load_throughput: 86832.974\n",
      "    load_time_ms: 0.369\n",
      "  timestamp: 1641219099\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 28\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:41 (running for 00:03:43.21)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         215.532</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">  131.12</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            131.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 29000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-45\n",
      "  done: false\n",
      "  episode_len_mean: 128.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 128.17\n",
      "  episode_reward_min: 11.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 358\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 28720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 48.45393753051758\n",
      "          mean_q: 37.35730743408203\n",
      "          mean_td_error: 1.7911548614501953\n",
      "          min_q: 8.768638610839844\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.4965629577636719\n",
      "        - -0.03350830078125\n",
      "        - -0.3031272888183594\n",
      "        - 0.11463546752929688\n",
      "        - 0.1494598388671875\n",
      "        - -0.2573509216308594\n",
      "        - 0.0013885498046875\n",
      "        - -0.3288688659667969\n",
      "        - 0.12874603271484375\n",
      "        - 0.2558135986328125\n",
      "        - -0.101776123046875\n",
      "        - -0.23098373413085938\n",
      "        - -0.00466156005859375\n",
      "        - 2.0264720916748047\n",
      "        - 25.480852127075195\n",
      "        - -0.6077651977539062\n",
      "        - 0.16843795776367188\n",
      "        - 0.06725692749023438\n",
      "        - 4.047372817993164\n",
      "        - -0.8145980834960938\n",
      "        - -1.3036603927612305\n",
      "        - 0.08143997192382812\n",
      "        - 0.19512939453125\n",
      "        - 0.3619232177734375\n",
      "        - 0.013561248779296875\n",
      "        - 0.41892051696777344\n",
      "        - 0.379241943359375\n",
      "        - -0.6845130920410156\n",
      "        - -3.9713478088378906\n",
      "        - 32.168922424316406\n",
      "        - 0.2931060791015625\n",
      "        - 0.10300064086914062\n",
      "    num_agent_steps_sampled: 29000\n",
      "    num_agent_steps_trained: 224032\n",
      "    num_steps_sampled: 29000\n",
      "    num_steps_trained: 224032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 56\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.525\n",
      "    ram_util_percent: 16.4\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11469397372499757\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11684636886822053\n",
      "    mean_inference_ms: 1.6598990537677134\n",
      "    mean_raw_obs_processing_ms: 0.2421978607338039\n",
      "  time_since_restore: 220.874835729599\n",
      "  time_this_iter_s: 5.342358827590942\n",
      "  time_total_s: 220.874835729599\n",
      "  timers:\n",
      "    learn_throughput: 7694.779\n",
      "    learn_time_ms: 4.159\n",
      "    load_throughput: 80742.181\n",
      "    load_time_ms: 0.396\n",
      "  timestamp: 1641219105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 29000\n",
      "  training_iteration: 29\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:47 (running for 00:03:48.60)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         220.875</td><td style=\"text-align: right;\">29000</td><td style=\"text-align: right;\">  128.17</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            128.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:52 (running for 00:03:53.61)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         220.875</td><td style=\"text-align: right;\">29000</td><td style=\"text-align: right;\">  128.17</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">            128.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-54\n",
      "  done: false\n",
      "  episode_len_mean: 127.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 391.0\n",
      "  episode_reward_mean: 127.58\n",
      "  episode_reward_min: 60.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 368\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 118.65\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 124.0\n",
      "    episode_reward_mean: 118.65\n",
      "    episode_reward_min: 114.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 117\n",
      "      - 121\n",
      "      - 114\n",
      "      - 116\n",
      "      - 121\n",
      "      - 118\n",
      "      - 114\n",
      "      - 120\n",
      "      - 119\n",
      "      - 115\n",
      "      - 121\n",
      "      - 118\n",
      "      - 117\n",
      "      - 120\n",
      "      - 121\n",
      "      - 124\n",
      "      - 122\n",
      "      - 117\n",
      "      - 119\n",
      "      - 119\n",
      "      episode_reward:\n",
      "      - 117.0\n",
      "      - 121.0\n",
      "      - 114.0\n",
      "      - 116.0\n",
      "      - 121.0\n",
      "      - 118.0\n",
      "      - 114.0\n",
      "      - 120.0\n",
      "      - 119.0\n",
      "      - 115.0\n",
      "      - 121.0\n",
      "      - 118.0\n",
      "      - 117.0\n",
      "      - 120.0\n",
      "      - 121.0\n",
      "      - 124.0\n",
      "      - 122.0\n",
      "      - 117.0\n",
      "      - 119.0\n",
      "      - 119.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11710260995663395\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11820844853113492\n",
      "      mean_inference_ms: 1.654443850114052\n",
      "      mean_raw_obs_processing_ms: 0.1285200627719822\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 29728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 48.818214416503906\n",
      "          mean_q: 36.7585334777832\n",
      "          mean_td_error: 3.395566701889038\n",
      "          min_q: 1.1336965560913086\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.8111724853515625\n",
      "        - -0.3776817321777344\n",
      "        - 37.157833099365234\n",
      "        - -0.5525703430175781\n",
      "        - -0.29454803466796875\n",
      "        - -2.180194854736328\n",
      "        - 0.1322021484375\n",
      "        - 0.21954345703125\n",
      "        - 0.09775543212890625\n",
      "        - -0.6104507446289062\n",
      "        - 25.179201126098633\n",
      "        - -0.17479324340820312\n",
      "        - 2.1697940826416016\n",
      "        - 0.06731796264648438\n",
      "        - -0.2712745666503906\n",
      "        - -0.4687767028808594\n",
      "        - 24.117889404296875\n",
      "        - 0.16016769409179688\n",
      "        - -0.12080001831054688\n",
      "        - 0.3760032653808594\n",
      "        - -0.5943603515625\n",
      "        - 0.10120201110839844\n",
      "        - 0.1062774658203125\n",
      "        - -4.533750534057617\n",
      "        - -0.7743339538574219\n",
      "        - 0.3952789306640625\n",
      "        - -0.055278778076171875\n",
      "        - 0.5370893478393555\n",
      "        - -0.14122772216796875\n",
      "        - 3.200843572616577\n",
      "        - 25.065025329589844\n",
      "        - -0.08642959594726562\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 232032\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 232032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 58\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.838461538461537\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11460973196741028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1167350859450398\n",
      "    mean_inference_ms: 1.658769930620159\n",
      "    mean_raw_obs_processing_ms: 0.24184102536422764\n",
      "  time_since_restore: 230.54733967781067\n",
      "  time_this_iter_s: 9.67250394821167\n",
      "  time_total_s: 230.54733967781067\n",
      "  timers:\n",
      "    learn_throughput: 7226.108\n",
      "    learn_time_ms: 4.428\n",
      "    load_throughput: 76823.152\n",
      "    load_time_ms: 0.417\n",
      "  timestamp: 1641219114\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 30\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:11:57 (running for 00:03:59.32)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         230.547</td><td style=\"text-align: right;\">30000</td><td style=\"text-align: right;\">  127.58</td><td style=\"text-align: right;\">                 391</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            127.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 31000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-11-59\n",
      "  done: false\n",
      "  episode_len_mean: 126.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 126.0\n",
      "  episode_reward_min: 60.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 372\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 30736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 50.70576095581055\n",
      "          mean_q: 41.564422607421875\n",
      "          mean_td_error: 4.377071380615234\n",
      "          min_q: 5.573333263397217\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.11088943481445312\n",
      "        - 0.5280876159667969\n",
      "        - -0.21857643127441406\n",
      "        - -0.2285747528076172\n",
      "        - 0.67926025390625\n",
      "        - 29.464599609375\n",
      "        - 0.3893470764160156\n",
      "        - -0.1104278564453125\n",
      "        - 34.85247802734375\n",
      "        - -0.07234954833984375\n",
      "        - -3.597301483154297\n",
      "        - 37.68191909790039\n",
      "        - 0.2823524475097656\n",
      "        - 0.3425865173339844\n",
      "        - 0.19340896606445312\n",
      "        - 0.908843994140625\n",
      "        - 4.968584060668945\n",
      "        - 0.7574615478515625\n",
      "        - 0.6354866027832031\n",
      "        - 0.08979415893554688\n",
      "        - 0.33457183837890625\n",
      "        - 0.819000244140625\n",
      "        - 0.23958587646484375\n",
      "        - 28.271160125732422\n",
      "        - 0.3443794250488281\n",
      "        - 0.379547119140625\n",
      "        - -0.2326202392578125\n",
      "        - 1.3471641540527344\n",
      "        - 0.223907470703125\n",
      "        - -0.22587966918945312\n",
      "        - 0.5890846252441406\n",
      "        - 0.3184967041015625\n",
      "    num_agent_steps_sampled: 31000\n",
      "    num_agent_steps_trained: 240032\n",
      "    num_steps_sampled: 31000\n",
      "    num_steps_trained: 240032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 60\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.8125\n",
      "    ram_util_percent: 16.4\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11457106568765596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11668796069675047\n",
      "    mean_inference_ms: 1.658279728346755\n",
      "    mean_raw_obs_processing_ms: 0.24169897061952084\n",
      "  time_since_restore: 235.6577663421631\n",
      "  time_this_iter_s: 5.110426664352417\n",
      "  time_total_s: 235.6577663421631\n",
      "  timers:\n",
      "    learn_throughput: 8771.311\n",
      "    learn_time_ms: 3.648\n",
      "    load_throughput: 111458.004\n",
      "    load_time_ms: 0.287\n",
      "  timestamp: 1641219119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 31000\n",
      "  training_iteration: 31\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:03 (running for 00:04:04.46)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         235.658</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">     126</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">               126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:08 (running for 00:04:09.47)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         235.658</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">     126</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">               126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:13 (running for 00:04:14.48)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         235.658</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">     126</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">               126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:18 (running for 00:04:19.49)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         235.658</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">     126</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">               126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:23 (running for 00:04:24.50)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         235.658</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">     126</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">               126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-12-25\n",
      "  done: false\n",
      "  episode_len_mean: 126.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 126.91\n",
      "  episode_reward_min: 60.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 376\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11767261266110056\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11868830801036631\n",
      "      mean_inference_ms: 1.6608599304235951\n",
      "      mean_raw_obs_processing_ms: 0.12807601584856604\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 31744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 51.02528762817383\n",
      "          mean_q: 42.002113342285156\n",
      "          mean_td_error: 4.766757011413574\n",
      "          min_q: 7.832283020019531\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 24.871641159057617\n",
      "        - -0.1290283203125\n",
      "        - -0.3152122497558594\n",
      "        - 0.44766998291015625\n",
      "        - -0.39406585693359375\n",
      "        - -0.4330482482910156\n",
      "        - -0.6355056762695312\n",
      "        - -0.48227691650390625\n",
      "        - -0.05002593994140625\n",
      "        - -1.0694389343261719\n",
      "        - -0.15557861328125\n",
      "        - -0.24630355834960938\n",
      "        - 0.29740142822265625\n",
      "        - -0.2586860656738281\n",
      "        - -0.11658477783203125\n",
      "        - 2.820718288421631\n",
      "        - -0.6451148986816406\n",
      "        - -3.0097084045410156\n",
      "        - 25.028736114501953\n",
      "        - -0.8906707763671875\n",
      "        - -0.17465972900390625\n",
      "        - 0.4689483642578125\n",
      "        - 0.6164779663085938\n",
      "        - 1.5977287292480469\n",
      "        - 36.8331413269043\n",
      "        - 32.889434814453125\n",
      "        - 0.08614349365234375\n",
      "        - -4.7729644775390625\n",
      "        - -0.16736602783203125\n",
      "        - 41.23582458496094\n",
      "        - -0.06821823120117188\n",
      "        - -0.6431808471679688\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 248032\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 248032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 62\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.508333333333336\n",
      "    ram_util_percent: 16.419444444444437\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11451999725714018\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.116628695829978\n",
      "    mean_inference_ms: 1.657643406461122\n",
      "    mean_raw_obs_processing_ms: 0.24153157114234497\n",
      "  time_since_restore: 261.1259183883667\n",
      "  time_this_iter_s: 25.468152046203613\n",
      "  time_total_s: 261.1259183883667\n",
      "  timers:\n",
      "    learn_throughput: 8508.147\n",
      "    learn_time_ms: 3.761\n",
      "    load_throughput: 123158.128\n",
      "    load_time_ms: 0.26\n",
      "  timestamp: 1641219145\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 32\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:28 (running for 00:04:29.98)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         261.126</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">  126.91</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            126.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 33000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-12-30\n",
      "  done: false\n",
      "  episode_len_mean: 131.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 131.67\n",
      "  episode_reward_min: 60.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 380\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 32752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 52.0106086730957\n",
      "          mean_q: 39.037513732910156\n",
      "          mean_td_error: 3.2949302196502686\n",
      "          min_q: 6.298738479614258\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2213306427001953\n",
      "        - 0.5878982543945312\n",
      "        - -0.24311447143554688\n",
      "        - 6.728670120239258\n",
      "        - -1.0464210510253906\n",
      "        - 3.117168426513672\n",
      "        - 36.74207305908203\n",
      "        - -0.2409229278564453\n",
      "        - -1.1187973022460938\n",
      "        - 1.1334381103515625\n",
      "        - -0.2147064208984375\n",
      "        - 35.70606994628906\n",
      "        - 0.263580322265625\n",
      "        - -0.3936614990234375\n",
      "        - 1.0120429992675781\n",
      "        - -0.7321891784667969\n",
      "        - -0.29924774169921875\n",
      "        - 0.7729339599609375\n",
      "        - -0.20986557006835938\n",
      "        - -0.493011474609375\n",
      "        - -0.2122039794921875\n",
      "        - 2.943920850753784\n",
      "        - 24.361286163330078\n",
      "        - 0.17919921875\n",
      "        - -1.7178115844726562\n",
      "        - -0.1447601318359375\n",
      "        - 0.06610870361328125\n",
      "        - 0.10929489135742188\n",
      "        - -0.4510345458984375\n",
      "        - 0.0013637542724609375\n",
      "        - 0.4008979797363281\n",
      "        - -1.3917655944824219\n",
      "    num_agent_steps_sampled: 33000\n",
      "    num_agent_steps_trained: 256032\n",
      "    num_steps_sampled: 33000\n",
      "    num_steps_trained: 256032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 64\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.04285714285714\n",
      "    ram_util_percent: 16.400000000000002\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1144625915234345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11656303657477818\n",
      "    mean_inference_ms: 1.6569300566191645\n",
      "    mean_raw_obs_processing_ms: 0.2413460269721304\n",
      "  time_since_restore: 266.0938401222229\n",
      "  time_this_iter_s: 4.967921733856201\n",
      "  time_total_s: 266.0938401222229\n",
      "  timers:\n",
      "    learn_throughput: 7217.714\n",
      "    learn_time_ms: 4.434\n",
      "    load_throughput: 82443.322\n",
      "    load_time_ms: 0.388\n",
      "  timestamp: 1641219150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 33000\n",
      "  training_iteration: 33\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:33 (running for 00:04:34.99)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         266.094</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  131.67</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            131.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:38 (running for 00:04:40.00)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         266.094</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  131.67</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            131.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:43 (running for 00:04:45.01)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         266.094</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  131.67</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            131.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:48 (running for 00:04:50.01)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         266.094</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  131.67</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            131.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:53 (running for 00:04:55.02)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         266.094</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  131.67</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  60</td><td style=\"text-align: right;\">            131.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 34000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 140.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 140.72\n",
      "  episode_reward_min: 62.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 383\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11811583576205949\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11877666727624256\n",
      "      mean_inference_ms: 1.6622903388911248\n",
      "      mean_raw_obs_processing_ms: 0.1276158220719938\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 33760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 53.223384857177734\n",
      "          mean_q: 44.00257110595703\n",
      "          mean_td_error: 3.588672637939453\n",
      "          min_q: 14.244988441467285\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.0300140380859375\n",
      "        - 0.24681854248046875\n",
      "        - 0.16379928588867188\n",
      "        - 0.5348587036132812\n",
      "        - -0.17053604125976562\n",
      "        - 13.244988441467285\n",
      "        - 0.47658538818359375\n",
      "        - 0.7560806274414062\n",
      "        - -0.6888465881347656\n",
      "        - 0.241607666015625\n",
      "        - 30.83228874206543\n",
      "        - -0.10048675537109375\n",
      "        - 23.06293487548828\n",
      "        - -0.18114089965820312\n",
      "        - 0.4061012268066406\n",
      "        - 0.4621391296386719\n",
      "        - -0.5437850952148438\n",
      "        - 0.13393020629882812\n",
      "        - 8.126211166381836\n",
      "        - 0.13443374633789062\n",
      "        - 0.13499832153320312\n",
      "        - -1.2861213684082031\n",
      "        - -0.023799896240234375\n",
      "        - 0.24358749389648438\n",
      "        - 1.1095199584960938\n",
      "        - -0.026569366455078125\n",
      "        - 0.4149360656738281\n",
      "        - 37.55667495727539\n",
      "        - 0.33292388916015625\n",
      "        - -0.30591583251953125\n",
      "        - -0.6349029541015625\n",
      "        - 0.15419769287109375\n",
      "    num_agent_steps_sampled: 34000\n",
      "    num_agent_steps_trained: 264032\n",
      "    num_steps_sampled: 34000\n",
      "    num_steps_trained: 264032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 66\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.702777777777776\n",
      "    ram_util_percent: 16.399999999999995\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11441686207435355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11651115461118822\n",
      "    mean_inference_ms: 1.6563609043726106\n",
      "    mean_raw_obs_processing_ms: 0.24119741726412805\n",
      "  time_since_restore: 291.55087637901306\n",
      "  time_this_iter_s: 25.45703625679016\n",
      "  time_total_s: 291.55087637901306\n",
      "  timers:\n",
      "    learn_throughput: 7880.373\n",
      "    learn_time_ms: 4.061\n",
      "    load_throughput: 92672.601\n",
      "    load_time_ms: 0.345\n",
      "  timestamp: 1641219175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 34000\n",
      "  training_iteration: 34\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:12:59 (running for 00:05:00.50)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         291.551</td><td style=\"text-align: right;\">34000</td><td style=\"text-align: right;\">  140.72</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  62</td><td style=\"text-align: right;\">            140.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 35000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-13-01\n",
      "  done: false\n",
      "  episode_len_mean: 147.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 147.58\n",
      "  episode_reward_min: 71.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 385\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 34768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 53.69955062866211\n",
      "          mean_q: 46.140907287597656\n",
      "          mean_td_error: 0.4654074013233185\n",
      "          min_q: -6.056939125061035\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.5699462890625\n",
      "        - -0.5588493347167969\n",
      "        - 2.409515380859375\n",
      "        - 23.722307205200195\n",
      "        - -0.19234466552734375\n",
      "        - 0.5704498291015625\n",
      "        - 0.47850799560546875\n",
      "        - -7.056939125061035\n",
      "        - 1.2125358581542969\n",
      "        - -0.4197235107421875\n",
      "        - 0.3746452331542969\n",
      "        - -0.3026161193847656\n",
      "        - 0.2867279052734375\n",
      "        - 0.19870758056640625\n",
      "        - -0.009723663330078125\n",
      "        - -0.12969589233398438\n",
      "        - -0.40512847900390625\n",
      "        - -0.27991485595703125\n",
      "        - -0.4453849792480469\n",
      "        - -1.75396728515625\n",
      "        - -0.7037620544433594\n",
      "        - -0.2993965148925781\n",
      "        - -0.261962890625\n",
      "        - -0.2869224548339844\n",
      "        - -1.3454017639160156\n",
      "        - -0.2582855224609375\n",
      "        - -0.08589935302734375\n",
      "        - 0.12070846557617188\n",
      "        - -0.3309059143066406\n",
      "        - -0.2941474914550781\n",
      "        - -0.28240966796875\n",
      "        - -0.34763336181640625\n",
      "    num_agent_steps_sampled: 35000\n",
      "    num_agent_steps_trained: 272032\n",
      "    num_steps_sampled: 35000\n",
      "    num_steps_trained: 272032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 68\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.8375\n",
      "    ram_util_percent: 16.424999999999997\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11438666793877861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1164756236521232\n",
      "    mean_inference_ms: 1.6559765344150765\n",
      "    mean_raw_obs_processing_ms: 0.2410952153603974\n",
      "  time_since_restore: 296.57561230659485\n",
      "  time_this_iter_s: 5.024735927581787\n",
      "  time_total_s: 296.57561230659485\n",
      "  timers:\n",
      "    learn_throughput: 7335.304\n",
      "    learn_time_ms: 4.362\n",
      "    load_throughput: 77497.389\n",
      "    load_time_ms: 0.413\n",
      "  timestamp: 1641219181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 35000\n",
      "  training_iteration: 35\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:04 (running for 00:05:05.56)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         296.576</td><td style=\"text-align: right;\">35000</td><td style=\"text-align: right;\">  147.58</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            147.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:09 (running for 00:05:10.57)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         296.576</td><td style=\"text-align: right;\">35000</td><td style=\"text-align: right;\">  147.58</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  71</td><td style=\"text-align: right;\">            147.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-13-11\n",
      "  done: false\n",
      "  episode_len_mean: 152.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 152.91\n",
      "  episode_reward_min: 76.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 390\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 134.05\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 138.0\n",
      "    episode_reward_mean: 134.05\n",
      "    episode_reward_min: 127.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 138\n",
      "      - 127\n",
      "      - 136\n",
      "      - 136\n",
      "      - 133\n",
      "      - 137\n",
      "      - 138\n",
      "      - 133\n",
      "      - 128\n",
      "      - 138\n",
      "      - 138\n",
      "      - 136\n",
      "      - 131\n",
      "      - 137\n",
      "      - 131\n",
      "      - 135\n",
      "      - 134\n",
      "      - 133\n",
      "      - 130\n",
      "      - 132\n",
      "      episode_reward:\n",
      "      - 138.0\n",
      "      - 127.0\n",
      "      - 136.0\n",
      "      - 136.0\n",
      "      - 133.0\n",
      "      - 137.0\n",
      "      - 138.0\n",
      "      - 133.0\n",
      "      - 128.0\n",
      "      - 138.0\n",
      "      - 138.0\n",
      "      - 136.0\n",
      "      - 131.0\n",
      "      - 137.0\n",
      "      - 131.0\n",
      "      - 135.0\n",
      "      - 134.0\n",
      "      - 133.0\n",
      "      - 130.0\n",
      "      - 132.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11799168686435943\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11867991018423588\n",
      "      mean_inference_ms: 1.660578999909048\n",
      "      mean_raw_obs_processing_ms: 0.12760963548766696\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 35776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 55.565696716308594\n",
      "          mean_q: 44.04975891113281\n",
      "          mean_td_error: 1.1101131439208984\n",
      "          min_q: -1.6574007272720337\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.0923423767089844\n",
      "        - -2.657400608062744\n",
      "        - 0.912750244140625\n",
      "        - 0.3084678649902344\n",
      "        - 0.9687652587890625\n",
      "        - 0.09400177001953125\n",
      "        - 0.6274757385253906\n",
      "        - -1.0102310180664062\n",
      "        - -0.5219268798828125\n",
      "        - 1.6322708129882812\n",
      "        - 0.62896728515625\n",
      "        - 0.3975677490234375\n",
      "        - 0.7231864929199219\n",
      "        - 16.0511417388916\n",
      "        - 0.6968612670898438\n",
      "        - 0.943084716796875\n",
      "        - 0.8261756896972656\n",
      "        - 0.3478813171386719\n",
      "        - 1.0816421508789062\n",
      "        - 0.7969512939453125\n",
      "        - 1.4299860000610352\n",
      "        - 1.6698646545410156\n",
      "        - 0.9871177673339844\n",
      "        - 3.1880359649658203\n",
      "        - 0.142852783203125\n",
      "        - 0.5021247863769531\n",
      "        - 1.1056060791015625\n",
      "        - 1.3884086608886719\n",
      "        - 1.0148391723632812\n",
      "        - -1.1451454162597656\n",
      "        - 0.4195976257324219\n",
      "        - 0.8803558349609375\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 280032\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 280032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 70\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.228571428571428\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11430844456177205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11638156534883713\n",
      "    mean_inference_ms: 1.6549680904715423\n",
      "    mean_raw_obs_processing_ms: 0.2408271754558554\n",
      "  time_since_restore: 306.84306836128235\n",
      "  time_this_iter_s: 10.2674560546875\n",
      "  time_total_s: 306.84306836128235\n",
      "  timers:\n",
      "    learn_throughput: 8138.502\n",
      "    learn_time_ms: 3.932\n",
      "    load_throughput: 99017.136\n",
      "    load_time_ms: 0.323\n",
      "  timestamp: 1641219191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 36\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:14 (running for 00:05:15.88)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         306.843</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">  152.91</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  76</td><td style=\"text-align: right;\">            152.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 37000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-13-17\n",
      "  done: false\n",
      "  episode_len_mean: 157.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 157.81\n",
      "  episode_reward_min: 82.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 397\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 36784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 57.7547607421875\n",
      "          mean_q: 42.90449523925781\n",
      "          mean_td_error: 1.5674850940704346\n",
      "          min_q: 3.656644821166992\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 4.322236061096191\n",
      "        - -3.1929283142089844\n",
      "        - -0.00710296630859375\n",
      "        - 0.176727294921875\n",
      "        - 33.723785400390625\n",
      "        - -0.5264511108398438\n",
      "        - -0.492706298828125\n",
      "        - -0.7818756103515625\n",
      "        - 0.0386199951171875\n",
      "        - 0.6685714721679688\n",
      "        - -0.7341957092285156\n",
      "        - 0.5047035217285156\n",
      "        - 0.42212677001953125\n",
      "        - -3.811948776245117\n",
      "        - -0.09375953674316406\n",
      "        - 9.364667892456055\n",
      "        - 0.29998016357421875\n",
      "        - -2.5939369201660156\n",
      "        - 0.48996734619140625\n",
      "        - 0.7462329864501953\n",
      "        - 15.994258880615234\n",
      "        - 0.3490638732910156\n",
      "        - 0.4394874572753906\n",
      "        - -1.0649375915527344\n",
      "        - -0.1137542724609375\n",
      "        - 0.4632530212402344\n",
      "        - -3.868968963623047\n",
      "        - 0.4981803894042969\n",
      "        - -1.2908172607421875\n",
      "        - -0.13804244995117188\n",
      "        - 0.19980239868164062\n",
      "        - 0.16928482055664062\n",
      "    num_agent_steps_sampled: 37000\n",
      "    num_agent_steps_trained: 288032\n",
      "    num_steps_sampled: 37000\n",
      "    num_steps_trained: 288032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 72\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.4875\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1142180441591028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11627205074278521\n",
      "    mean_inference_ms: 1.6537607243058068\n",
      "    mean_raw_obs_processing_ms: 0.240488798618737\n",
      "  time_since_restore: 312.44041776657104\n",
      "  time_this_iter_s: 5.597349405288696\n",
      "  time_total_s: 312.44041776657104\n",
      "  timers:\n",
      "    learn_throughput: 8831.566\n",
      "    learn_time_ms: 3.623\n",
      "    load_throughput: 131097.605\n",
      "    load_time_ms: 0.244\n",
      "  timestamp: 1641219197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 37000\n",
      "  training_iteration: 37\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:20 (running for 00:05:21.52)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">          312.44</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  157.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            157.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:25 (running for 00:05:26.52)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">          312.44</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  157.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            157.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:30 (running for 00:05:31.53)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">          312.44</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  157.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            157.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:35 (running for 00:05:36.54)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">          312.44</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  157.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            157.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:40 (running for 00:05:41.55)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">          312.44</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  157.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  82</td><td style=\"text-align: right;\">            157.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 38000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-13-42\n",
      "  done: false\n",
      "  episode_len_mean: 158.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 158.68\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 404\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11764050368055937\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11838089024055871\n",
      "      mean_inference_ms: 1.6568555497230606\n",
      "      mean_raw_obs_processing_ms: 0.12691144275210356\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 37792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 58.436378479003906\n",
      "          mean_q: 40.804298400878906\n",
      "          mean_td_error: 2.3174962997436523\n",
      "          min_q: -0.7338389158248901\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.2279510498046875\n",
      "        - 0.4327278137207031\n",
      "        - -0.29792022705078125\n",
      "        - 24.005252838134766\n",
      "        - 26.184587478637695\n",
      "        - -1.4616584777832031\n",
      "        - 1.8198966979980469\n",
      "        - 0.24520111083984375\n",
      "        - 0.22521591186523438\n",
      "        - -0.3621330261230469\n",
      "        - 22.259565353393555\n",
      "        - -0.06761932373046875\n",
      "        - 0.23713302612304688\n",
      "        - 0.5086898803710938\n",
      "        - 0.30511474609375\n",
      "        - 9.054840087890625\n",
      "        - 1.7865982055664062\n",
      "        - -0.8939943313598633\n",
      "        - 0.6478118896484375\n",
      "        - -5.129875183105469\n",
      "        - 0.13770294189453125\n",
      "        - -1.7251434326171875\n",
      "        - 0.0851287841796875\n",
      "        - 0.3206634521484375\n",
      "        - 0.0602264404296875\n",
      "        - 0.2564277648925781\n",
      "        - -1.7338389158248901\n",
      "        - 1.5453300476074219\n",
      "        - -2.080413818359375\n",
      "        - 0.2522010803222656\n",
      "        - -0.3525352478027344\n",
      "        - -1.877349853515625\n",
      "    num_agent_steps_sampled: 38000\n",
      "    num_agent_steps_trained: 296032\n",
      "    num_steps_sampled: 38000\n",
      "    num_steps_trained: 296032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 74\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.78108108108108\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11416648454165727\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11620575359901344\n",
      "    mean_inference_ms: 1.6530451456088786\n",
      "    mean_raw_obs_processing_ms: 0.2402281164534788\n",
      "  time_since_restore: 337.8876566886902\n",
      "  time_this_iter_s: 25.44723892211914\n",
      "  time_total_s: 337.8876566886902\n",
      "  timers:\n",
      "    learn_throughput: 7514.738\n",
      "    learn_time_ms: 4.258\n",
      "    load_throughput: 94639.492\n",
      "    load_time_ms: 0.338\n",
      "  timestamp: 1641219222\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 38000\n",
      "  training_iteration: 38\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:45 (running for 00:05:47.01)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         337.888</td><td style=\"text-align: right;\">38000</td><td style=\"text-align: right;\">  158.68</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            158.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:51 (running for 00:05:53.01)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         342.852</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  163.42</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            163.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:13:56 (running for 00:05:58.02)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         342.852</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  163.42</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            163.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:01 (running for 00:06:03.03)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         342.852</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  163.42</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            163.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:06 (running for 00:06:08.03)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         342.852</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  163.42</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            163.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-09\n",
      "  done: false\n",
      "  episode_len_mean: 169.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 169.7\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 411\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 416.05\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 416.05\n",
      "    episode_reward_min: 147.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 191\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 492\n",
      "      - 500\n",
      "      - 500\n",
      "      - 466\n",
      "      - 500\n",
      "      - 157\n",
      "      - 500\n",
      "      - 500\n",
      "      - 179\n",
      "      - 189\n",
      "      - 500\n",
      "      - 147\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 191.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 492.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 466.0\n",
      "      - 500.0\n",
      "      - 157.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 179.0\n",
      "      - 189.0\n",
      "      - 500.0\n",
      "      - 147.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11769922973140808\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11841175310806744\n",
      "      mean_inference_ms: 1.6576589855977626\n",
      "      mean_raw_obs_processing_ms: 0.12690214814897222\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 39808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 60.35881042480469\n",
      "          mean_q: 48.8358268737793\n",
      "          mean_td_error: -0.8597903847694397\n",
      "          min_q: -6.442785739898682\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.0103607177734375\n",
      "        - 0.1202239990234375\n",
      "        - -0.23309326171875\n",
      "        - -1.3099217414855957\n",
      "        - -0.20491790771484375\n",
      "        - -0.5802459716796875\n",
      "        - -5.983051300048828\n",
      "        - 0.6201324462890625\n",
      "        - 0.4205894470214844\n",
      "        - -0.02584075927734375\n",
      "        - -4.483972549438477\n",
      "        - -0.2535552978515625\n",
      "        - 0.27460479736328125\n",
      "        - -8.186372756958008\n",
      "        - 0.9570655822753906\n",
      "        - -0.264801025390625\n",
      "        - -5.14703369140625\n",
      "        - 0.335693359375\n",
      "        - -0.06877517700195312\n",
      "        - 0.168975830078125\n",
      "        - -3.2530956268310547\n",
      "        - -0.36447906494140625\n",
      "        - 0.02489471435546875\n",
      "        - -0.14276123046875\n",
      "        - -0.14476394653320312\n",
      "        - 0.2534523010253906\n",
      "        - -0.13242721557617188\n",
      "        - 0.3895835876464844\n",
      "        - 0.5024147033691406\n",
      "        - 0.5328750610351562\n",
      "        - 0.23796844482421875\n",
      "        - -1.5830192565917969\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 312032\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 312032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 78\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.6875\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11413178420031014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11615734511946257\n",
      "    mean_inference_ms: 1.6525381957516998\n",
      "    mean_raw_obs_processing_ms: 0.24000452284056661\n",
      "  time_since_restore: 365.1165888309479\n",
      "  time_this_iter_s: 22.26449418067932\n",
      "  time_total_s: 365.1165888309479\n",
      "  timers:\n",
      "    learn_throughput: 7195.426\n",
      "    learn_time_ms: 4.447\n",
      "    load_throughput: 75074.241\n",
      "    load_time_ms: 0.426\n",
      "  timestamp: 1641219249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 40\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:11 (running for 00:06:13.32)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         365.117</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">   169.7</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">             169.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 41000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-14\n",
      "  done: false\n",
      "  episode_len_mean: 169.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 169.86\n",
      "  episode_reward_min: 92.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 417\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 40816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 60.50190734863281\n",
      "          mean_q: 48.9627685546875\n",
      "          mean_td_error: 1.3020035028457642\n",
      "          min_q: 4.149369239807129\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.5264625549316406\n",
      "        - -0.4585609436035156\n",
      "        - -0.41059112548828125\n",
      "        - -0.08672714233398438\n",
      "        - -0.8461380004882812\n",
      "        - 0.8368339538574219\n",
      "        - 1.2378959655761719\n",
      "        - -0.2448272705078125\n",
      "        - -0.000423431396484375\n",
      "        - -0.3906745910644531\n",
      "        - -0.804107666015625\n",
      "        - -0.37131500244140625\n",
      "        - -0.48760986328125\n",
      "        - -1.7890625\n",
      "        - -0.8929939270019531\n",
      "        - 5.800599098205566\n",
      "        - -0.2991600036621094\n",
      "        - 20.35341453552246\n",
      "        - 0.2394561767578125\n",
      "        - -0.0391693115234375\n",
      "        - -4.296161651611328\n",
      "        - 0.04419708251953125\n",
      "        - -0.12971878051757812\n",
      "        - -0.6772880554199219\n",
      "        - 0.15454483032226562\n",
      "        - -0.5240020751953125\n",
      "        - -0.3974571228027344\n",
      "        - -0.43132781982421875\n",
      "        - 26.86312484741211\n",
      "        - 0.07870864868164062\n",
      "        - 0.7749786376953125\n",
      "        - -0.6158638000488281\n",
      "    num_agent_steps_sampled: 41000\n",
      "    num_agent_steps_trained: 320032\n",
      "    num_steps_sampled: 41000\n",
      "    num_steps_trained: 320032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 80\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.97142857142857\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1140799414924354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1160930020866439\n",
      "    mean_inference_ms: 1.651821404424722\n",
      "    mean_raw_obs_processing_ms: 0.23978568382531004\n",
      "  time_since_restore: 370.1634786128998\n",
      "  time_this_iter_s: 5.046889781951904\n",
      "  time_total_s: 370.1634786128998\n",
      "  timers:\n",
      "    learn_throughput: 7619.211\n",
      "    learn_time_ms: 4.2\n",
      "    load_throughput: 84440.219\n",
      "    load_time_ms: 0.379\n",
      "  timestamp: 1641219254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 41000\n",
      "  training_iteration: 41\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:16 (running for 00:06:18.40)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         370.163</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">  169.86</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            169.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:21 (running for 00:06:23.42)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         370.163</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">  169.86</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  92</td><td style=\"text-align: right;\">            169.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 42000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-23\n",
      "  done: false\n",
      "  episode_len_mean: 170.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 170.64\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 423\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 92.9\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 103.0\n",
      "    episode_reward_mean: 92.9\n",
      "    episode_reward_min: 87.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 93\n",
      "      - 89\n",
      "      - 89\n",
      "      - 98\n",
      "      - 99\n",
      "      - 90\n",
      "      - 91\n",
      "      - 92\n",
      "      - 95\n",
      "      - 95\n",
      "      - 95\n",
      "      - 90\n",
      "      - 97\n",
      "      - 103\n",
      "      - 90\n",
      "      - 91\n",
      "      - 87\n",
      "      - 91\n",
      "      - 92\n",
      "      - 91\n",
      "      episode_reward:\n",
      "      - 93.0\n",
      "      - 89.0\n",
      "      - 89.0\n",
      "      - 98.0\n",
      "      - 99.0\n",
      "      - 90.0\n",
      "      - 91.0\n",
      "      - 92.0\n",
      "      - 95.0\n",
      "      - 95.0\n",
      "      - 95.0\n",
      "      - 90.0\n",
      "      - 97.0\n",
      "      - 103.0\n",
      "      - 90.0\n",
      "      - 91.0\n",
      "      - 87.0\n",
      "      - 91.0\n",
      "      - 92.0\n",
      "      - 91.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11763363257963262\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11837422609687402\n",
      "      mean_inference_ms: 1.656837680501636\n",
      "      mean_raw_obs_processing_ms: 0.12696857915292642\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 41824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 61.99522399902344\n",
      "          mean_q: 49.99223327636719\n",
      "          mean_td_error: 2.6710453033447266\n",
      "          min_q: 4.583530902862549\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.15801620483398438\n",
      "        - -0.17583847045898438\n",
      "        - 1.2339324951171875\n",
      "        - -1.0585441589355469\n",
      "        - -1.1725578308105469\n",
      "        - -0.569580078125\n",
      "        - 0.2001953125\n",
      "        - 27.414121627807617\n",
      "        - -0.20928192138671875\n",
      "        - 1.6357135772705078\n",
      "        - 23.728425979614258\n",
      "        - -0.04164886474609375\n",
      "        - -0.3768348693847656\n",
      "        - -0.5056991577148438\n",
      "        - 3.583530902862549\n",
      "        - -1.1323699951171875\n",
      "        - 0.20103073120117188\n",
      "        - -0.23382949829101562\n",
      "        - -0.5568008422851562\n",
      "        - -0.5606346130371094\n",
      "        - -0.030853271484375\n",
      "        - -0.4813270568847656\n",
      "        - 0.04555511474609375\n",
      "        - -0.7110633850097656\n",
      "        - -0.3603553771972656\n",
      "        - -2.09600830078125\n",
      "        - 5.880222320556641\n",
      "        - 33.464046478271484\n",
      "        - 0.6190032958984375\n",
      "        - -0.06171417236328125\n",
      "        - -1.8192253112792969\n",
      "        - -0.22014236450195312\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 328032\n",
      "    num_steps_sampled: 42000\n",
      "    num_steps_trained: 328032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 82\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.746153846153845\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11404391744356443\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11604744201124034\n",
      "    mean_inference_ms: 1.6513394781967627\n",
      "    mean_raw_obs_processing_ms: 0.23960511327964973\n",
      "  time_since_restore: 379.1706805229187\n",
      "  time_this_iter_s: 9.007201910018921\n",
      "  time_total_s: 379.1706805229187\n",
      "  timers:\n",
      "    learn_throughput: 7138.292\n",
      "    learn_time_ms: 4.483\n",
      "    load_throughput: 76669.558\n",
      "    load_time_ms: 0.417\n",
      "  timestamp: 1641219263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 42000\n",
      "  training_iteration: 42\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:27 (running for 00:06:28.47)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         379.171</td><td style=\"text-align: right;\">42000</td><td style=\"text-align: right;\">  170.64</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            170.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 43000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-29\n",
      "  done: false\n",
      "  episode_len_mean: 169.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 169.91\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 428\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 42832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 62.63013458251953\n",
      "          mean_q: 51.07343292236328\n",
      "          mean_td_error: 2.8395581245422363\n",
      "          min_q: -3.807802200317383\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.13470458984375\n",
      "        - -0.05173492431640625\n",
      "        - -0.8017578125\n",
      "        - -0.26395416259765625\n",
      "        - 58.183746337890625\n",
      "        - -0.1107940673828125\n",
      "        - 0.6428298950195312\n",
      "        - 31.23736572265625\n",
      "        - 0.038021087646484375\n",
      "        - 1.5222187042236328\n",
      "        - -0.08509445190429688\n",
      "        - 0.152191162109375\n",
      "        - 0.001667022705078125\n",
      "        - 0.2857933044433594\n",
      "        - 0.4558372497558594\n",
      "        - 0.33521270751953125\n",
      "        - 0.355804443359375\n",
      "        - -1.3745765686035156\n",
      "        - 0.26536083221435547\n",
      "        - 0.10226821899414062\n",
      "        - 1.9812273979187012\n",
      "        - -0.4732246398925781\n",
      "        - -2.0321474075317383\n",
      "        - 0.15514373779296875\n",
      "        - 0.14433670043945312\n",
      "        - 0.053722381591796875\n",
      "        - 0.190338134765625\n",
      "        - -0.208038330078125\n",
      "        - 0.15764236450195312\n",
      "        - -0.0971527099609375\n",
      "        - -0.011993408203125\n",
      "        - -0.019100189208984375\n",
      "    num_agent_steps_sampled: 43000\n",
      "    num_agent_steps_trained: 336032\n",
      "    num_steps_sampled: 43000\n",
      "    num_steps_trained: 336032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 84\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.12857142857143\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11402654114800471\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11602659934314097\n",
      "    mean_inference_ms: 1.6511091633228705\n",
      "    mean_raw_obs_processing_ms: 0.23948596235253788\n",
      "  time_since_restore: 384.5756850242615\n",
      "  time_this_iter_s: 5.405004501342773\n",
      "  time_total_s: 384.5756850242615\n",
      "  timers:\n",
      "    learn_throughput: 7769.568\n",
      "    learn_time_ms: 4.119\n",
      "    load_throughput: 79886.75\n",
      "    load_time_ms: 0.401\n",
      "  timestamp: 1641219269\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 43000\n",
      "  training_iteration: 43\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:32 (running for 00:06:33.91)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         384.576</td><td style=\"text-align: right;\">43000</td><td style=\"text-align: right;\">  169.91</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            169.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:37 (running for 00:06:38.92)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         384.576</td><td style=\"text-align: right;\">43000</td><td style=\"text-align: right;\">  169.91</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            169.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-39\n",
      "  done: false\n",
      "  episode_len_mean: 168.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 168.45\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 440\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 129.35\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 147.0\n",
      "    episode_reward_mean: 129.35\n",
      "    episode_reward_min: 118.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 126\n",
      "      - 132\n",
      "      - 147\n",
      "      - 125\n",
      "      - 126\n",
      "      - 142\n",
      "      - 125\n",
      "      - 121\n",
      "      - 129\n",
      "      - 140\n",
      "      - 124\n",
      "      - 126\n",
      "      - 125\n",
      "      - 130\n",
      "      - 121\n",
      "      - 139\n",
      "      - 118\n",
      "      - 124\n",
      "      - 140\n",
      "      - 127\n",
      "      episode_reward:\n",
      "      - 126.0\n",
      "      - 132.0\n",
      "      - 147.0\n",
      "      - 125.0\n",
      "      - 126.0\n",
      "      - 142.0\n",
      "      - 125.0\n",
      "      - 121.0\n",
      "      - 129.0\n",
      "      - 140.0\n",
      "      - 124.0\n",
      "      - 126.0\n",
      "      - 125.0\n",
      "      - 130.0\n",
      "      - 121.0\n",
      "      - 139.0\n",
      "      - 118.0\n",
      "      - 124.0\n",
      "      - 140.0\n",
      "      - 127.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11759788087270792\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11832214434960428\n",
      "      mean_inference_ms: 1.6560775985826168\n",
      "      mean_raw_obs_processing_ms: 0.1269734783701047\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 43840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 63.28428268432617\n",
      "          mean_q: 51.746803283691406\n",
      "          mean_td_error: 0.2585909366607666\n",
      "          min_q: 9.763935089111328\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.131195068359375\n",
      "        - 0.7714653015136719\n",
      "        - 0.7427253723144531\n",
      "        - -0.1854400634765625\n",
      "        - 1.1703109741210938\n",
      "        - -0.052066802978515625\n",
      "        - -0.3895721435546875\n",
      "        - 0.1395721435546875\n",
      "        - -0.3661766052246094\n",
      "        - 0.14544677734375\n",
      "        - -0.12261199951171875\n",
      "        - 0.37673187255859375\n",
      "        - -0.15110397338867188\n",
      "        - -0.030635833740234375\n",
      "        - -0.5834465026855469\n",
      "        - -0.12689208984375\n",
      "        - 0.5314445495605469\n",
      "        - -0.15980148315429688\n",
      "        - -0.23799896240234375\n",
      "        - 0.4397430419921875\n",
      "        - -0.1513824462890625\n",
      "        - -0.029804229736328125\n",
      "        - 0.01302337646484375\n",
      "        - 0.3068885803222656\n",
      "        - -1.5071868896484375\n",
      "        - -0.7301750183105469\n",
      "        - 0.006175994873046875\n",
      "        - 0.6280021667480469\n",
      "        - 8.763935089111328\n",
      "        - -0.8354721069335938\n",
      "        - -0.17650604248046875\n",
      "        - 0.20691299438476562\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 344032\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 344032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 86\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.64666666666667\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11399149659159778\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11598361097439631\n",
      "    mean_inference_ms: 1.6506095032037609\n",
      "    mean_raw_obs_processing_ms: 0.23920310268282996\n",
      "  time_since_restore: 394.81668305397034\n",
      "  time_this_iter_s: 10.240998029708862\n",
      "  time_total_s: 394.81668305397034\n",
      "  timers:\n",
      "    learn_throughput: 7947.097\n",
      "    learn_time_ms: 4.027\n",
      "    load_throughput: 93252.086\n",
      "    load_time_ms: 0.343\n",
      "  timestamp: 1641219279\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 44\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:42 (running for 00:06:44.20)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         394.817</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">  168.45</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            168.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 168.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 168.64\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 450\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 44848\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 64.79225158691406\n",
      "          mean_q: 50.952571868896484\n",
      "          mean_td_error: 1.8211590051651\n",
      "          min_q: 5.840732097625732\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.8513641357421875\n",
      "        - -0.1414947509765625\n",
      "        - 12.603954315185547\n",
      "        - -1.2953681945800781\n",
      "        - 1.0448722839355469\n",
      "        - -0.3058624267578125\n",
      "        - 0.18584060668945312\n",
      "        - 0.1710968017578125\n",
      "        - 0.12449264526367188\n",
      "        - -0.37523651123046875\n",
      "        - 0.20108413696289062\n",
      "        - 5.615629196166992\n",
      "        - 6.322169303894043\n",
      "        - 27.20197868347168\n",
      "        - -0.43425750732421875\n",
      "        - -0.07321929931640625\n",
      "        - -0.2111358642578125\n",
      "        - 0.06421661376953125\n",
      "        - 0.1108856201171875\n",
      "        - 0.35034942626953125\n",
      "        - -0.21990966796875\n",
      "        - 0.6650581359863281\n",
      "        - 0.05132293701171875\n",
      "        - 0.17889785766601562\n",
      "        - 0.9902610778808594\n",
      "        - -2.9500274658203125\n",
      "        - 0.17436981201171875\n",
      "        - 8.239983558654785\n",
      "        - -0.0414276123046875\n",
      "        - -0.14173126220703125\n",
      "        - -0.3667564392089844\n",
      "        - -0.3143119812011719\n",
      "    num_agent_steps_sampled: 45000\n",
      "    num_agent_steps_trained: 352032\n",
      "    num_steps_sampled: 45000\n",
      "    num_steps_trained: 352032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 88\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.285714285714285\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11398523421715699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11596175180212319\n",
      "    mean_inference_ms: 1.6503691755747518\n",
      "    mean_raw_obs_processing_ms: 0.2390080787074446\n",
      "  time_since_restore: 399.8854022026062\n",
      "  time_this_iter_s: 5.068719148635864\n",
      "  time_total_s: 399.8854022026062\n",
      "  timers:\n",
      "    learn_throughput: 8182.511\n",
      "    learn_time_ms: 3.911\n",
      "    load_throughput: 98421.741\n",
      "    load_time_ms: 0.325\n",
      "  timestamp: 1641219284\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 45\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:47 (running for 00:06:49.31)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         399.885</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">  168.64</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            168.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:52 (running for 00:06:54.32)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         399.885</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">  168.64</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            168.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 46000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-14-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 170.82\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 457\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 193.2\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 193.2\n",
      "    episode_reward_min: 149.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 149\n",
      "      - 162\n",
      "      - 168\n",
      "      - 149\n",
      "      - 159\n",
      "      - 150\n",
      "      - 161\n",
      "      - 162\n",
      "      - 500\n",
      "      - 152\n",
      "      - 154\n",
      "      - 167\n",
      "      - 159\n",
      "      - 172\n",
      "      - 165\n",
      "      - 500\n",
      "      - 158\n",
      "      - 152\n",
      "      - 163\n",
      "      - 162\n",
      "      episode_reward:\n",
      "      - 149.0\n",
      "      - 162.0\n",
      "      - 168.0\n",
      "      - 149.0\n",
      "      - 159.0\n",
      "      - 150.0\n",
      "      - 161.0\n",
      "      - 162.0\n",
      "      - 500.0\n",
      "      - 152.0\n",
      "      - 154.0\n",
      "      - 167.0\n",
      "      - 159.0\n",
      "      - 172.0\n",
      "      - 165.0\n",
      "      - 500.0\n",
      "      - 158.0\n",
      "      - 152.0\n",
      "      - 163.0\n",
      "      - 162.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11772162985215395\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11842944344437259\n",
      "      mean_inference_ms: 1.6579525198961729\n",
      "      mean_raw_obs_processing_ms: 0.12708415609787932\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 45856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 66.55477142333984\n",
      "          mean_q: 53.098907470703125\n",
      "          mean_td_error: 0.1754491627216339\n",
      "          min_q: 4.569713115692139\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.020511627197265625\n",
      "        - 1.5213305950164795\n",
      "        - 0.11228179931640625\n",
      "        - -0.12676239013671875\n",
      "        - 0.25281524658203125\n",
      "        - -0.23584747314453125\n",
      "        - -0.046993255615234375\n",
      "        - -0.36252593994140625\n",
      "        - -0.057605743408203125\n",
      "        - -0.1797943115234375\n",
      "        - -0.4291419982910156\n",
      "        - -0.10463714599609375\n",
      "        - -0.12786483764648438\n",
      "        - -0.7400741577148438\n",
      "        - -1.5459327697753906\n",
      "        - -0.4379463195800781\n",
      "        - 10.212026596069336\n",
      "        - -0.3509407043457031\n",
      "        - -0.37306976318359375\n",
      "        - -0.8080558776855469\n",
      "        - -0.43776702880859375\n",
      "        - 3.2653961181640625\n",
      "        - -0.5258407592773438\n",
      "        - -0.5691757202148438\n",
      "        - -0.26172637939453125\n",
      "        - -0.11371994018554688\n",
      "        - -0.19420623779296875\n",
      "        - -0.6880226135253906\n",
      "        - 0.6256828308105469\n",
      "        - -0.9630050659179688\n",
      "        - -0.2577056884765625\n",
      "        - -0.4162864685058594\n",
      "    num_agent_steps_sampled: 46000\n",
      "    num_agent_steps_trained: 360032\n",
      "    num_steps_sampled: 46000\n",
      "    num_steps_trained: 360032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 90\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.926315789473687\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11396236980330553\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11592585649844002\n",
      "    mean_inference_ms: 1.6499626878580944\n",
      "    mean_raw_obs_processing_ms: 0.2388346206810748\n",
      "  time_since_restore: 412.8744943141937\n",
      "  time_this_iter_s: 12.989092111587524\n",
      "  time_total_s: 412.8744943141937\n",
      "  timers:\n",
      "    learn_throughput: 8429.915\n",
      "    learn_time_ms: 3.796\n",
      "    load_throughput: 101757.186\n",
      "    load_time_ms: 0.314\n",
      "  timestamp: 1641219297\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 46000\n",
      "  training_iteration: 46\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:14:57 (running for 00:06:59.35)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         412.874</td><td style=\"text-align: right;\">46000</td><td style=\"text-align: right;\">  170.82</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            170.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:02 (running for 00:07:04.37)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         412.874</td><td style=\"text-align: right;\">46000</td><td style=\"text-align: right;\">  170.82</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            170.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 47000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-15-03\n",
      "  done: false\n",
      "  episode_len_mean: 175.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 175.49\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 460\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 46864\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 67.6890869140625\n",
      "          mean_q: 48.96868896484375\n",
      "          mean_td_error: 3.20308518409729\n",
      "          min_q: -13.33405590057373\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.12540435791015625\n",
      "        - -0.0103302001953125\n",
      "        - 0.12351226806640625\n",
      "        - -0.023715972900390625\n",
      "        - 2.079059600830078\n",
      "        - -0.5576629638671875\n",
      "        - -1.1400260925292969\n",
      "        - 29.953441619873047\n",
      "        - -0.0521240234375\n",
      "        - 27.08698844909668\n",
      "        - -0.097625732421875\n",
      "        - -0.5874688625335693\n",
      "        - -14.33405590057373\n",
      "        - 0.206817626953125\n",
      "        - 0.09566497802734375\n",
      "        - 2.0894546508789062\n",
      "        - -2.8085098266601562\n",
      "        - 35.033348083496094\n",
      "        - 0.77630615234375\n",
      "        - 0.47930145263671875\n",
      "        - -0.038665771484375\n",
      "        - -0.0075531005859375\n",
      "        - -0.0981597900390625\n",
      "        - -0.6890029907226562\n",
      "        - -1.70745849609375\n",
      "        - -0.19437408447265625\n",
      "        - 0.0466461181640625\n",
      "        - 0.00592041015625\n",
      "        - -1.3746070861816406\n",
      "        - 1.3201980590820312\n",
      "        - 26.963088989257812\n",
      "        - 0.085723876953125\n",
      "    num_agent_steps_sampled: 47000\n",
      "    num_agent_steps_trained: 368032\n",
      "    num_steps_sampled: 47000\n",
      "    num_steps_trained: 368032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 92\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.025\n",
      "    ram_util_percent: 16.5\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11396122890913202\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11592007309346762\n",
      "    mean_inference_ms: 1.6498893974193267\n",
      "    mean_raw_obs_processing_ms: 0.23877579485823386\n",
      "  time_since_restore: 418.2387011051178\n",
      "  time_this_iter_s: 5.364206790924072\n",
      "  time_total_s: 418.2387011051178\n",
      "  timers:\n",
      "    learn_throughput: 7580.267\n",
      "    learn_time_ms: 4.221\n",
      "    load_throughput: 87256.357\n",
      "    load_time_ms: 0.367\n",
      "  timestamp: 1641219303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 47000\n",
      "  training_iteration: 47\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:08 (running for 00:07:09.75)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         418.239</td><td style=\"text-align: right;\">47000</td><td style=\"text-align: right;\">  175.49</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            175.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:13 (running for 00:07:14.76)<br>Memory usage on this node: 10.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         418.239</td><td style=\"text-align: right;\">47000</td><td style=\"text-align: right;\">  175.49</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            175.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-15-14\n",
      "  done: false\n",
      "  episode_len_mean: 185.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 185.38\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 463\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 145.4\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 155.0\n",
      "    episode_reward_mean: 145.4\n",
      "    episode_reward_min: 131.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 149\n",
      "      - 138\n",
      "      - 150\n",
      "      - 155\n",
      "      - 131\n",
      "      - 141\n",
      "      - 149\n",
      "      - 151\n",
      "      - 141\n",
      "      - 151\n",
      "      - 153\n",
      "      - 153\n",
      "      - 132\n",
      "      - 139\n",
      "      - 142\n",
      "      - 135\n",
      "      - 147\n",
      "      - 141\n",
      "      - 155\n",
      "      - 155\n",
      "      episode_reward:\n",
      "      - 149.0\n",
      "      - 138.0\n",
      "      - 150.0\n",
      "      - 155.0\n",
      "      - 131.0\n",
      "      - 141.0\n",
      "      - 149.0\n",
      "      - 151.0\n",
      "      - 141.0\n",
      "      - 151.0\n",
      "      - 153.0\n",
      "      - 153.0\n",
      "      - 132.0\n",
      "      - 139.0\n",
      "      - 142.0\n",
      "      - 135.0\n",
      "      - 147.0\n",
      "      - 141.0\n",
      "      - 155.0\n",
      "      - 155.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1177025291845281\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.1184416654569063\n",
      "      mean_inference_ms: 1.6579652869546677\n",
      "      mean_raw_obs_processing_ms: 0.1271311984234465\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 47872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 68.78758239746094\n",
      "          mean_q: 55.406089782714844\n",
      "          mean_td_error: 5.568657875061035\n",
      "          min_q: 20.03516960144043\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 44.565711975097656\n",
      "        - 54.15273666381836\n",
      "        - -0.045475006103515625\n",
      "        - -0.9210968017578125\n",
      "        - 0.10520172119140625\n",
      "        - -0.06924819946289062\n",
      "        - -0.728790283203125\n",
      "        - 0.4112052917480469\n",
      "        - -0.14300537109375\n",
      "        - -12.490215301513672\n",
      "        - -0.20352935791015625\n",
      "        - -0.7520599365234375\n",
      "        - 0.5132942199707031\n",
      "        - 0.1455230712890625\n",
      "        - 0.13072967529296875\n",
      "        - -0.0789031982421875\n",
      "        - 0.906280517578125\n",
      "        - -1.1304359436035156\n",
      "        - -1.2528305053710938\n",
      "        - -0.5418624877929688\n",
      "        - -0.11549758911132812\n",
      "        - -0.22293853759765625\n",
      "        - 0.7370986938476562\n",
      "        - 29.18018913269043\n",
      "        - 43.446144104003906\n",
      "        - 0.3102455139160156\n",
      "        - -0.6925010681152344\n",
      "        - -0.40830230712890625\n",
      "        - -0.11292648315429688\n",
      "        - -3.416013717651367\n",
      "        - 26.834646224975586\n",
      "        - 0.08367919921875\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 376032\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 376032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 94\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.839999999999996\n",
      "    ram_util_percent: 16.486666666666668\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11395738964699131\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11591169207113755\n",
      "    mean_inference_ms: 1.6497856646933124\n",
      "    mean_raw_obs_processing_ms: 0.23870903950238007\n",
      "  time_since_restore: 429.01958084106445\n",
      "  time_this_iter_s: 10.780879735946655\n",
      "  time_total_s: 429.01958084106445\n",
      "  timers:\n",
      "    learn_throughput: 8191.65\n",
      "    learn_time_ms: 3.906\n",
      "    load_throughput: 101919.453\n",
      "    load_time_ms: 0.314\n",
      "  timestamp: 1641219314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 48\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:19 (running for 00:07:20.57)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         433.981</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  189.76</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:24 (running for 00:07:25.59)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         433.981</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  189.76</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:29 (running for 00:07:30.59)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         433.981</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  189.76</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 50000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-15-30\n",
      "  done: false\n",
      "  episode_len_mean: 198.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 198.43\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 469\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 149.1\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 162.0\n",
      "    episode_reward_mean: 149.1\n",
      "    episode_reward_min: 138.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 139\n",
      "      - 148\n",
      "      - 141\n",
      "      - 147\n",
      "      - 151\n",
      "      - 150\n",
      "      - 153\n",
      "      - 140\n",
      "      - 162\n",
      "      - 154\n",
      "      - 152\n",
      "      - 138\n",
      "      - 149\n",
      "      - 156\n",
      "      - 154\n",
      "      - 148\n",
      "      - 156\n",
      "      - 149\n",
      "      - 153\n",
      "      - 142\n",
      "      episode_reward:\n",
      "      - 139.0\n",
      "      - 148.0\n",
      "      - 141.0\n",
      "      - 147.0\n",
      "      - 151.0\n",
      "      - 150.0\n",
      "      - 153.0\n",
      "      - 140.0\n",
      "      - 162.0\n",
      "      - 154.0\n",
      "      - 152.0\n",
      "      - 138.0\n",
      "      - 149.0\n",
      "      - 156.0\n",
      "      - 154.0\n",
      "      - 148.0\n",
      "      - 156.0\n",
      "      - 149.0\n",
      "      - 153.0\n",
      "      - 142.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11781859970311417\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11855895399761344\n",
      "      mean_inference_ms: 1.6594365662071016\n",
      "      mean_raw_obs_processing_ms: 0.12727046884925483\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 49888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 69.50862884521484\n",
      "          mean_q: 53.31780242919922\n",
      "          mean_td_error: 2.581427812576294\n",
      "          min_q: 4.127772331237793\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.04676055908203125\n",
      "        - 0.0001373291015625\n",
      "        - 0.20215225219726562\n",
      "        - 4.727573394775391\n",
      "        - -1.5716056823730469\n",
      "        - 0.34770965576171875\n",
      "        - 0.2354736328125\n",
      "        - 3.064075469970703\n",
      "        - 1.1342735290527344\n",
      "        - 0.5994110107421875\n",
      "        - 3.329784393310547\n",
      "        - -0.39833831787109375\n",
      "        - -0.9214668273925781\n",
      "        - -0.5079803466796875\n",
      "        - 33.61530685424805\n",
      "        - -1.3634796142578125\n",
      "        - -0.0686492919921875\n",
      "        - -1.1351165771484375\n",
      "        - -5.573720932006836\n",
      "        - -1.325347900390625\n",
      "        - -0.085662841796875\n",
      "        - 4.473121166229248\n",
      "        - 0.2777252197265625\n",
      "        - 0.4948616027832031\n",
      "        - 2.21783447265625\n",
      "        - -0.23697280883789062\n",
      "        - 34.92132568359375\n",
      "        - 0.5368118286132812\n",
      "        - 1.1802749633789062\n",
      "        - 0.15523529052734375\n",
      "        - 0.8820724487304688\n",
      "        - 3.4456233978271484\n",
      "    num_agent_steps_sampled: 50000\n",
      "    num_agent_steps_trained: 392032\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 392032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 98\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.7875\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11394180035059154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11588543965412679\n",
      "    mean_inference_ms: 1.6494686797172124\n",
      "    mean_raw_obs_processing_ms: 0.23855349774798187\n",
      "  time_since_restore: 445.2310552597046\n",
      "  time_this_iter_s: 11.249923467636108\n",
      "  time_total_s: 445.2310552597046\n",
      "  timers:\n",
      "    learn_throughput: 7139.583\n",
      "    learn_time_ms: 4.482\n",
      "    load_throughput: 80815.106\n",
      "    load_time_ms: 0.396\n",
      "  timestamp: 1641219330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 50\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:34 (running for 00:07:35.88)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         445.231</td><td style=\"text-align: right;\">50000</td><td style=\"text-align: right;\">  198.43</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            198.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 51000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-15-35\n",
      "  done: false\n",
      "  episode_len_mean: 191.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 191.98\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 476\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 50896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 69.98592376708984\n",
      "          mean_q: 57.78348922729492\n",
      "          mean_td_error: 4.055697917938232\n",
      "          min_q: 27.353172302246094\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.0577392578125\n",
      "        - -0.39366912841796875\n",
      "        - -0.9701805114746094\n",
      "        - -0.4151763916015625\n",
      "        - -0.36461639404296875\n",
      "        - 42.092430114746094\n",
      "        - -0.39618682861328125\n",
      "        - 0.0342559814453125\n",
      "        - 0.9769554138183594\n",
      "        - -0.402252197265625\n",
      "        - -0.07158660888671875\n",
      "        - 0.24493408203125\n",
      "        - 0.08172225952148438\n",
      "        - -0.13398361206054688\n",
      "        - -0.32543182373046875\n",
      "        - 26.353172302246094\n",
      "        - -0.19656753540039062\n",
      "        - -0.16219329833984375\n",
      "        - -5.257282257080078\n",
      "        - -3.111713409423828\n",
      "        - -0.1332244873046875\n",
      "        - -0.39577484130859375\n",
      "        - 26.353172302246094\n",
      "        - 0.09990692138671875\n",
      "        - 42.44679641723633\n",
      "        - -0.1209564208984375\n",
      "        - 1.1750679016113281\n",
      "        - 2.7702255249023438\n",
      "        - -0.3100433349609375\n",
      "        - 0.13207244873046875\n",
      "        - -0.31890106201171875\n",
      "        - 0.4436187744140625\n",
      "    num_agent_steps_sampled: 51000\n",
      "    num_agent_steps_trained: 400032\n",
      "    num_steps_sampled: 51000\n",
      "    num_steps_trained: 400032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 100\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.225\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1139431259065043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1158738821624707\n",
      "    mean_inference_ms: 1.6493531119463327\n",
      "    mean_raw_obs_processing_ms: 0.23842003493709193\n",
      "  time_since_restore: 450.57649755477905\n",
      "  time_this_iter_s: 5.345442295074463\n",
      "  time_total_s: 450.57649755477905\n",
      "  timers:\n",
      "    learn_throughput: 7619.946\n",
      "    learn_time_ms: 4.2\n",
      "    load_throughput: 91025.926\n",
      "    load_time_ms: 0.352\n",
      "  timestamp: 1641219335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 51000\n",
      "  training_iteration: 51\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:39 (running for 00:07:41.26)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         450.576</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">  191.98</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            191.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:44 (running for 00:07:46.27)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         450.576</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">  191.98</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            191.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:49 (running for 00:07:51.28)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         450.576</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">  191.98</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            191.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:15:54 (running for 00:07:56.29)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         450.576</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">  191.98</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            191.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-15-56\n",
      "  done: false\n",
      "  episode_len_mean: 185.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 185.1\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 481\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 390.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 390.5\n",
      "    episode_reward_min: 284.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 375\n",
      "      - 416\n",
      "      - 500\n",
      "      - 415\n",
      "      - 416\n",
      "      - 457\n",
      "      - 327\n",
      "      - 312\n",
      "      - 370\n",
      "      - 355\n",
      "      - 385\n",
      "      - 284\n",
      "      - 397\n",
      "      - 410\n",
      "      - 314\n",
      "      - 464\n",
      "      - 329\n",
      "      - 383\n",
      "      - 401\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 375.0\n",
      "      - 416.0\n",
      "      - 500.0\n",
      "      - 415.0\n",
      "      - 416.0\n",
      "      - 457.0\n",
      "      - 327.0\n",
      "      - 312.0\n",
      "      - 370.0\n",
      "      - 355.0\n",
      "      - 385.0\n",
      "      - 284.0\n",
      "      - 397.0\n",
      "      - 410.0\n",
      "      - 314.0\n",
      "      - 464.0\n",
      "      - 329.0\n",
      "      - 383.0\n",
      "      - 401.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11760350686283212\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11832064846810253\n",
      "      mean_inference_ms: 1.6567118119456896\n",
      "      mean_raw_obs_processing_ms: 0.12702596222177484\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 51904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 69.94829559326172\n",
      "          mean_q: 58.377864837646484\n",
      "          mean_td_error: 3.351808547973633\n",
      "          min_q: 15.544485092163086\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.16558837890625\n",
      "        - -0.11700439453125\n",
      "        - -0.281646728515625\n",
      "        - 0.097625732421875\n",
      "        - -0.13382720947265625\n",
      "        - 64.28205108642578\n",
      "        - -0.05271148681640625\n",
      "        - 0.3589630126953125\n",
      "        - -0.650299072265625\n",
      "        - -0.2938079833984375\n",
      "        - 14.544485092163086\n",
      "        - 0.2428741455078125\n",
      "        - 33.343902587890625\n",
      "        - 0.13938140869140625\n",
      "        - -0.3411903381347656\n",
      "        - -0.26851654052734375\n",
      "        - -0.18659591674804688\n",
      "        - -0.2588348388671875\n",
      "        - 0.6218719482421875\n",
      "        - -0.60833740234375\n",
      "        - 0.11177444458007812\n",
      "        - -0.30654144287109375\n",
      "        - -0.10387420654296875\n",
      "        - 0.4260101318359375\n",
      "        - -0.35321807861328125\n",
      "        - -1.1826438903808594\n",
      "        - -0.04082489013671875\n",
      "        - -0.21544647216796875\n",
      "        - -0.14813995361328125\n",
      "        - -1.2310409545898438\n",
      "        - -0.15738677978515625\n",
      "        - -0.1447601318359375\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 408032\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 408032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 102\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.2448275862069\n",
      "    ram_util_percent: 16.300000000000004\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1139504313153396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11587305048438752\n",
      "    mean_inference_ms: 1.6493765123909008\n",
      "    mean_raw_obs_processing_ms: 0.23835158796240263\n",
      "  time_since_restore: 471.1312837600708\n",
      "  time_this_iter_s: 20.554786205291748\n",
      "  time_total_s: 471.1312837600708\n",
      "  timers:\n",
      "    learn_throughput: 8288.217\n",
      "    learn_time_ms: 3.861\n",
      "    load_throughput: 104392.726\n",
      "    load_time_ms: 0.307\n",
      "  timestamp: 1641219356\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 52\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:00 (running for 00:08:01.87)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         471.131</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">   185.1</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">             185.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 53000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 184.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 184.78\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 484\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 52912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 70.81880950927734\n",
      "          mean_q: 55.911712646484375\n",
      "          mean_td_error: 1.0280462503433228\n",
      "          min_q: -1.503367304801941\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -3.0314903259277344\n",
      "        - 0.1345062255859375\n",
      "        - 0.3050994873046875\n",
      "        - 0.027492523193359375\n",
      "        - 6.48457145690918\n",
      "        - -1.8671798706054688\n",
      "        - 0.1188507080078125\n",
      "        - -0.21756744384765625\n",
      "        - 33.334503173828125\n",
      "        - -0.068817138671875\n",
      "        - -0.7023468017578125\n",
      "        - 1.5382614135742188\n",
      "        - -6.814403533935547\n",
      "        - -0.8574752807617188\n",
      "        - 0.14167022705078125\n",
      "        - 0.27886962890625\n",
      "        - 0.1532745361328125\n",
      "        - -0.3480224609375\n",
      "        - 0.08319091796875\n",
      "        - 0.17902374267578125\n",
      "        - 0.23169708251953125\n",
      "        - 0.03240966796875\n",
      "        - 0.028636932373046875\n",
      "        - 0.13330078125\n",
      "        - 8.239927291870117\n",
      "        - -4.068007469177246\n",
      "        - 0.19876480102539062\n",
      "        - -0.8499603271484375\n",
      "        - -0.20249176025390625\n",
      "        - 0.17816925048828125\n",
      "        - -0.0673980712890625\n",
      "        - 0.17041778564453125\n",
      "    num_agent_steps_sampled: 53000\n",
      "    num_agent_steps_trained: 416032\n",
      "    num_steps_sampled: 53000\n",
      "    num_steps_trained: 416032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 104\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.75\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11395963258418731\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11587769511431208\n",
      "    mean_inference_ms: 1.6494565891633783\n",
      "    mean_raw_obs_processing_ms: 0.23832375453610993\n",
      "  time_since_restore: 476.4005358219147\n",
      "  time_this_iter_s: 5.269252061843872\n",
      "  time_total_s: 476.4005358219147\n",
      "  timers:\n",
      "    learn_throughput: 7987.677\n",
      "    learn_time_ms: 4.006\n",
      "    load_throughput: 96020.695\n",
      "    load_time_ms: 0.333\n",
      "  timestamp: 1641219361\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 53000\n",
      "  training_iteration: 53\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:05 (running for 00:08:07.18)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         476.401</td><td style=\"text-align: right;\">53000</td><td style=\"text-align: right;\">  184.78</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            184.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:10 (running for 00:08:12.19)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         476.401</td><td style=\"text-align: right;\">53000</td><td style=\"text-align: right;\">  184.78</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            184.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 54000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-13\n",
      "  done: false\n",
      "  episode_len_mean: 189.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 189.26\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 486\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 171.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 261.0\n",
      "    episode_reward_mean: 171.0\n",
      "    episode_reward_min: 142.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 162\n",
      "      - 241\n",
      "      - 163\n",
      "      - 159\n",
      "      - 164\n",
      "      - 173\n",
      "      - 175\n",
      "      - 177\n",
      "      - 151\n",
      "      - 185\n",
      "      - 162\n",
      "      - 147\n",
      "      - 166\n",
      "      - 162\n",
      "      - 154\n",
      "      - 152\n",
      "      - 261\n",
      "      - 165\n",
      "      - 142\n",
      "      - 159\n",
      "      episode_reward:\n",
      "      - 162.0\n",
      "      - 241.0\n",
      "      - 163.0\n",
      "      - 159.0\n",
      "      - 164.0\n",
      "      - 173.0\n",
      "      - 175.0\n",
      "      - 177.0\n",
      "      - 151.0\n",
      "      - 185.0\n",
      "      - 162.0\n",
      "      - 147.0\n",
      "      - 166.0\n",
      "      - 162.0\n",
      "      - 154.0\n",
      "      - 152.0\n",
      "      - 261.0\n",
      "      - 165.0\n",
      "      - 142.0\n",
      "      - 159.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11752872165682679\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11826517287002862\n",
      "      mean_inference_ms: 1.655830813215759\n",
      "      mean_raw_obs_processing_ms: 0.12703688914088207\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 53920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 71.80310821533203\n",
      "          mean_q: 55.84362030029297\n",
      "          mean_td_error: 4.320730209350586\n",
      "          min_q: 19.929580688476562\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.3651580810546875\n",
      "        - -0.03057861328125\n",
      "        - -0.26532745361328125\n",
      "        - -2.4630775451660156\n",
      "        - 0.8216171264648438\n",
      "        - -0.25992584228515625\n",
      "        - -0.7370185852050781\n",
      "        - 1.8412742614746094\n",
      "        - -0.19417572021484375\n",
      "        - 4.5812530517578125\n",
      "        - -0.101806640625\n",
      "        - 55.81910705566406\n",
      "        - 0.003448486328125\n",
      "        - 6.413312911987305\n",
      "        - 2.095905303955078\n",
      "        - -0.12624359130859375\n",
      "        - 19.724504470825195\n",
      "        - 0.00717926025390625\n",
      "        - 18.929580688476562\n",
      "        - 0.09759521484375\n",
      "        - 34.0621337890625\n",
      "        - 0.146820068359375\n",
      "        - -0.49176788330078125\n",
      "        - 0.7432022094726562\n",
      "        - 0.5370712280273438\n",
      "        - 4.642118453979492\n",
      "        - 0.090118408203125\n",
      "        - -0.1693115234375\n",
      "        - -7.280727386474609\n",
      "        - -0.21166229248046875\n",
      "        - 0.39252471923828125\n",
      "        - 0.01139068603515625\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 424032\n",
      "    num_steps_sampled: 54000\n",
      "    num_steps_trained: 424032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 106\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.682352941176468\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11396988905771334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11588667576031873\n",
      "    mean_inference_ms: 1.6495723268127112\n",
      "    mean_raw_obs_processing_ms: 0.23831645341623223\n",
      "  time_since_restore: 488.59897541999817\n",
      "  time_this_iter_s: 12.198439598083496\n",
      "  time_total_s: 488.59897541999817\n",
      "  timers:\n",
      "    learn_throughput: 8725.636\n",
      "    learn_time_ms: 3.667\n",
      "    load_throughput: 120797.163\n",
      "    load_time_ms: 0.265\n",
      "  timestamp: 1641219373\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 54000\n",
      "  training_iteration: 54\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:15 (running for 00:08:17.42)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         488.599</td><td style=\"text-align: right;\">54000</td><td style=\"text-align: right;\">  189.26</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 55000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 192.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 192.77\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 489\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 54928\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 72.85979461669922\n",
      "          mean_q: 55.447364807128906\n",
      "          mean_td_error: -0.11758032441139221\n",
      "          min_q: 5.2955827713012695\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.8501739501953125\n",
      "        - -0.009796142578125\n",
      "        - -0.63543701171875\n",
      "        - -0.4761505126953125\n",
      "        - -0.03227710723876953\n",
      "        - 0.1416778564453125\n",
      "        - 0.7636032104492188\n",
      "        - -1.1397552490234375\n",
      "        - -1.119232177734375\n",
      "        - -0.4138336181640625\n",
      "        - -1.148284912109375\n",
      "        - 0.44574737548828125\n",
      "        - 0.09505462646484375\n",
      "        - -0.35942840576171875\n",
      "        - 0.8037071228027344\n",
      "        - 0.19782638549804688\n",
      "        - 0.6506500244140625\n",
      "        - -1.5496578216552734\n",
      "        - 0.6569976806640625\n",
      "        - -0.3777503967285156\n",
      "        - -0.19083786010742188\n",
      "        - 1.2414016723632812\n",
      "        - -1.0537967681884766\n",
      "        - -0.2676544189453125\n",
      "        - -1.0450782775878906\n",
      "        - -0.1130523681640625\n",
      "        - -0.42928314208984375\n",
      "        - -0.689910888671875\n",
      "        - -0.5187225341796875\n",
      "        - 0.7478523254394531\n",
      "        - 0.9229660034179688\n",
      "        - -0.7102890014648438\n",
      "    num_agent_steps_sampled: 55000\n",
      "    num_agent_steps_trained: 432032\n",
      "    num_steps_sampled: 55000\n",
      "    num_steps_trained: 432032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 108\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.314285714285717\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11398562837018837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11590148188592966\n",
      "    mean_inference_ms: 1.649758393129637\n",
      "    mean_raw_obs_processing_ms: 0.2383104587358872\n",
      "  time_since_restore: 493.6843957901001\n",
      "  time_this_iter_s: 5.085420370101929\n",
      "  time_total_s: 493.6843957901001\n",
      "  timers:\n",
      "    learn_throughput: 8340.649\n",
      "    learn_time_ms: 3.837\n",
      "    load_throughput: 110014.531\n",
      "    load_time_ms: 0.291\n",
      "  timestamp: 1641219379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 55000\n",
      "  training_iteration: 55\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:21 (running for 00:08:22.54)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         493.684</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  192.77</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            192.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:26 (running for 00:08:27.55)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         493.684</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  192.77</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            192.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:31 (running for 00:08:32.56)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         493.684</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  192.77</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            192.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-35\n",
      "  done: false\n",
      "  episode_len_mean: 189.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 189.52\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 498\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 273.35\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 282.0\n",
      "    episode_reward_mean: 273.35\n",
      "    episode_reward_min: 265.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 278\n",
      "      - 282\n",
      "      - 271\n",
      "      - 279\n",
      "      - 275\n",
      "      - 273\n",
      "      - 265\n",
      "      - 277\n",
      "      - 273\n",
      "      - 273\n",
      "      - 275\n",
      "      - 275\n",
      "      - 278\n",
      "      - 275\n",
      "      - 266\n",
      "      - 272\n",
      "      - 268\n",
      "      - 266\n",
      "      - 272\n",
      "      - 274\n",
      "      episode_reward:\n",
      "      - 278.0\n",
      "      - 282.0\n",
      "      - 271.0\n",
      "      - 279.0\n",
      "      - 275.0\n",
      "      - 273.0\n",
      "      - 265.0\n",
      "      - 277.0\n",
      "      - 273.0\n",
      "      - 273.0\n",
      "      - 275.0\n",
      "      - 275.0\n",
      "      - 278.0\n",
      "      - 275.0\n",
      "      - 266.0\n",
      "      - 272.0\n",
      "      - 268.0\n",
      "      - 266.0\n",
      "      - 272.0\n",
      "      - 274.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1174897548521692\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11823729816291662\n",
      "      mean_inference_ms: 1.6556106944893763\n",
      "      mean_raw_obs_processing_ms: 0.12703846290529838\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 55936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 73.2376708984375\n",
      "          mean_q: 55.21161651611328\n",
      "          mean_td_error: 0.9327175617218018\n",
      "          min_q: 2.4427151679992676\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.9081325531005859\n",
      "        - 0.1568603515625\n",
      "        - 1.2651214599609375\n",
      "        - 0.8023643493652344\n",
      "        - 1.945896863937378\n",
      "        - 2.812103271484375\n",
      "        - -0.9410514831542969\n",
      "        - 0.095947265625\n",
      "        - -0.8402442932128906\n",
      "        - -0.08069610595703125\n",
      "        - -0.2854423522949219\n",
      "        - 23.924606323242188\n",
      "        - -0.4644737243652344\n",
      "        - -0.6280288696289062\n",
      "        - -0.28823089599609375\n",
      "        - -1.1848640441894531\n",
      "        - -0.2733001708984375\n",
      "        - 0.4494590759277344\n",
      "        - -1.0961189270019531\n",
      "        - -0.35439300537109375\n",
      "        - -0.40427398681640625\n",
      "        - -1.0823688507080078\n",
      "        - -0.34551239013671875\n",
      "        - -0.15830230712890625\n",
      "        - 2.8793487548828125\n",
      "        - -1.4319114685058594\n",
      "        - -0.00881195068359375\n",
      "        - 0.09903717041015625\n",
      "        - 1.4997367858886719\n",
      "        - -0.22887420654296875\n",
      "        - 2.0351123809814453\n",
      "        - 1.0701332092285156\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 440032\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 440032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 110\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.045833333333334\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11401567511314521\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1159256566027084\n",
      "    mean_inference_ms: 1.6501535382599064\n",
      "    mean_raw_obs_processing_ms: 0.2382612746404879\n",
      "  time_since_restore: 509.9729073047638\n",
      "  time_this_iter_s: 16.288511514663696\n",
      "  time_total_s: 509.9729073047638\n",
      "  timers:\n",
      "    learn_throughput: 7853.629\n",
      "    learn_time_ms: 4.075\n",
      "    load_throughput: 86247.094\n",
      "    load_time_ms: 0.371\n",
      "  timestamp: 1641219395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 56\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:36 (running for 00:08:37.89)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         509.973</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">  189.52</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 57000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 193.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 193.71\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 501\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 56944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 74.45823669433594\n",
      "          mean_q: 61.73200988769531\n",
      "          mean_td_error: 0.5509313941001892\n",
      "          min_q: 17.713563919067383\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.17041778564453125\n",
      "        - -0.324249267578125\n",
      "        - 0.46021270751953125\n",
      "        - 0.5845603942871094\n",
      "        - -0.07581710815429688\n",
      "        - -0.08541107177734375\n",
      "        - 0.0378570556640625\n",
      "        - -0.290283203125\n",
      "        - -0.3228759765625\n",
      "        - -0.12857437133789062\n",
      "        - 0.0925140380859375\n",
      "        - 0.35448455810546875\n",
      "        - -0.06641006469726562\n",
      "        - 0.7643089294433594\n",
      "        - 0.46196746826171875\n",
      "        - -3.5610809326171875\n",
      "        - -0.017604827880859375\n",
      "        - -0.1160430908203125\n",
      "        - 0.22210693359375\n",
      "        - 16.713563919067383\n",
      "        - 0.03389739990234375\n",
      "        - 0.5500564575195312\n",
      "        - 0.42928314208984375\n",
      "        - -0.2404022216796875\n",
      "        - 0.5165824890136719\n",
      "        - -0.13034820556640625\n",
      "        - 0.24636077880859375\n",
      "        - 0.6009979248046875\n",
      "        - 0.357269287109375\n",
      "        - 0.12554931640625\n",
      "        - -0.08138275146484375\n",
      "        - 0.348297119140625\n",
      "    num_agent_steps_sampled: 57000\n",
      "    num_agent_steps_trained: 448032\n",
      "    num_steps_sampled: 57000\n",
      "    num_steps_trained: 448032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 112\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.157142857142855\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11401960907465133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11592759605002105\n",
      "    mean_inference_ms: 1.6502147972139987\n",
      "    mean_raw_obs_processing_ms: 0.23823440392768502\n",
      "  time_since_restore: 515.1782898902893\n",
      "  time_this_iter_s: 5.205382585525513\n",
      "  time_total_s: 515.1782898902893\n",
      "  timers:\n",
      "    learn_throughput: 7793.388\n",
      "    learn_time_ms: 4.106\n",
      "    load_throughput: 91516.247\n",
      "    load_time_ms: 0.35\n",
      "  timestamp: 1641219400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 57000\n",
      "  training_iteration: 57\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:41 (running for 00:08:43.14)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         515.178</td><td style=\"text-align: right;\">57000</td><td style=\"text-align: right;\">  193.71</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            193.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:46 (running for 00:08:48.15)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         515.178</td><td style=\"text-align: right;\">57000</td><td style=\"text-align: right;\">  193.71</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            193.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 58000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-50\n",
      "  done: false\n",
      "  episode_len_mean: 198.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 198.25\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 505\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 120.7\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 125.0\n",
      "    episode_reward_mean: 120.7\n",
      "    episode_reward_min: 116.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 120\n",
      "      - 121\n",
      "      - 121\n",
      "      - 120\n",
      "      - 125\n",
      "      - 121\n",
      "      - 123\n",
      "      - 123\n",
      "      - 124\n",
      "      - 122\n",
      "      - 118\n",
      "      - 121\n",
      "      - 122\n",
      "      - 116\n",
      "      - 120\n",
      "      - 117\n",
      "      - 122\n",
      "      - 122\n",
      "      - 117\n",
      "      - 119\n",
      "      episode_reward:\n",
      "      - 120.0\n",
      "      - 121.0\n",
      "      - 121.0\n",
      "      - 120.0\n",
      "      - 125.0\n",
      "      - 121.0\n",
      "      - 123.0\n",
      "      - 123.0\n",
      "      - 124.0\n",
      "      - 122.0\n",
      "      - 118.0\n",
      "      - 121.0\n",
      "      - 122.0\n",
      "      - 116.0\n",
      "      - 120.0\n",
      "      - 117.0\n",
      "      - 122.0\n",
      "      - 122.0\n",
      "      - 117.0\n",
      "      - 119.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1174691905255826\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11822846297157433\n",
      "      mean_inference_ms: 1.6552466534106063\n",
      "      mean_raw_obs_processing_ms: 0.12705507326830895\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 57952\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 75.83350372314453\n",
      "          mean_q: 60.49574279785156\n",
      "          mean_td_error: 2.8298258781433105\n",
      "          min_q: 6.2880473136901855\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.18007659912109375\n",
      "        - -0.32791900634765625\n",
      "        - -0.1900787353515625\n",
      "        - 0.00357818603515625\n",
      "        - -0.20975494384765625\n",
      "        - 0.42633819580078125\n",
      "        - -0.29647064208984375\n",
      "        - 0.483551025390625\n",
      "        - -0.0619354248046875\n",
      "        - 0.26265716552734375\n",
      "        - -0.08896636962890625\n",
      "        - -1.808929443359375\n",
      "        - -0.8187522888183594\n",
      "        - -1.1772880554199219\n",
      "        - 22.90993881225586\n",
      "        - 68.83012390136719\n",
      "        - -0.0166778564453125\n",
      "        - -0.047515869140625\n",
      "        - -0.04673004150390625\n",
      "        - 0.45885467529296875\n",
      "        - -1.507070541381836\n",
      "        - 0.2083740234375\n",
      "        - -0.27291107177734375\n",
      "        - 0.13205718994140625\n",
      "        - -1.5852508544921875\n",
      "        - 5.2880473136901855\n",
      "        - -0.1150054931640625\n",
      "        - 0.7789993286132812\n",
      "        - -0.068145751953125\n",
      "        - -0.1740264892578125\n",
      "        - -0.03000640869140625\n",
      "        - -0.2045745849609375\n",
      "    num_agent_steps_sampled: 58000\n",
      "    num_agent_steps_trained: 456032\n",
      "    num_steps_sampled: 58000\n",
      "    num_steps_trained: 456032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 114\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.607142857142858\n",
      "    ram_util_percent: 16.300000000000004\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11402150778684106\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11592703360570504\n",
      "    mean_inference_ms: 1.6502671597285308\n",
      "    mean_raw_obs_processing_ms: 0.23819318544422177\n",
      "  time_since_restore: 524.9886908531189\n",
      "  time_this_iter_s: 9.81040096282959\n",
      "  time_total_s: 524.9886908531189\n",
      "  timers:\n",
      "    learn_throughput: 7428.436\n",
      "    learn_time_ms: 4.308\n",
      "    load_throughput: 81616.131\n",
      "    load_time_ms: 0.392\n",
      "  timestamp: 1641219410\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 58000\n",
      "  training_iteration: 58\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:52 (running for 00:08:53.98)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         524.989</td><td style=\"text-align: right;\">58000</td><td style=\"text-align: right;\">  198.25</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            198.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 59000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-16-55\n",
      "  done: false\n",
      "  episode_len_mean: 189.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 189.29\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 511\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 58960\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 76.07567596435547\n",
      "          mean_q: 62.125465393066406\n",
      "          mean_td_error: 0.0750662088394165\n",
      "          min_q: 2.6260461807250977\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.0162200927734375\n",
      "        - -0.12673187255859375\n",
      "        - -0.1426544189453125\n",
      "        - -0.09236526489257812\n",
      "        - 0.07196044921875\n",
      "        - 2.76772403717041\n",
      "        - 0.08406829833984375\n",
      "        - -0.1457061767578125\n",
      "        - 0.03766632080078125\n",
      "        - 0.13082504272460938\n",
      "        - 0.7711639404296875\n",
      "        - -0.14918136596679688\n",
      "        - -0.07403564453125\n",
      "        - -0.27756500244140625\n",
      "        - -0.26209259033203125\n",
      "        - 0.1691741943359375\n",
      "        - -1.0158309936523438\n",
      "        - 0.385498046875\n",
      "        - 1.7737092971801758\n",
      "        - 0.10757827758789062\n",
      "        - -0.478118896484375\n",
      "        - 0.15316009521484375\n",
      "        - 0.4207305908203125\n",
      "        - -0.102630615234375\n",
      "        - -0.26296234130859375\n",
      "        - 0.05080413818359375\n",
      "        - -0.26998329162597656\n",
      "        - -0.8256301879882812\n",
      "        - 0.1336669921875\n",
      "        - -0.17861175537109375\n",
      "        - -0.1181182861328125\n",
      "        - -0.1496124267578125\n",
      "    num_agent_steps_sampled: 59000\n",
      "    num_agent_steps_trained: 464032\n",
      "    num_steps_sampled: 59000\n",
      "    num_steps_trained: 464032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 116\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.04285714285714\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11402113837824349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1159226157341094\n",
      "    mean_inference_ms: 1.6503063504931692\n",
      "    mean_raw_obs_processing_ms: 0.23813087103907093\n",
      "  time_since_restore: 530.0541172027588\n",
      "  time_this_iter_s: 5.065426349639893\n",
      "  time_total_s: 530.0541172027588\n",
      "  timers:\n",
      "    learn_throughput: 7515.117\n",
      "    learn_time_ms: 4.258\n",
      "    load_throughput: 82845.335\n",
      "    load_time_ms: 0.386\n",
      "  timestamp: 1641219415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 59000\n",
      "  training_iteration: 59\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:16:57 (running for 00:08:59.09)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         530.054</td><td style=\"text-align: right;\">59000</td><td style=\"text-align: right;\">  189.29</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:02 (running for 00:09:04.10)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         530.054</td><td style=\"text-align: right;\">59000</td><td style=\"text-align: right;\">  189.29</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:07 (running for 00:09:09.11)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         530.054</td><td style=\"text-align: right;\">59000</td><td style=\"text-align: right;\">  189.29</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            189.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-17-10\n",
      "  done: false\n",
      "  episode_len_mean: 192.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 192.99\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 513\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 232.55\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 245.0\n",
      "    episode_reward_mean: 232.55\n",
      "    episode_reward_min: 225.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 232\n",
      "      - 226\n",
      "      - 226\n",
      "      - 240\n",
      "      - 240\n",
      "      - 240\n",
      "      - 225\n",
      "      - 240\n",
      "      - 230\n",
      "      - 232\n",
      "      - 226\n",
      "      - 226\n",
      "      - 245\n",
      "      - 227\n",
      "      - 227\n",
      "      - 230\n",
      "      - 231\n",
      "      - 234\n",
      "      - 234\n",
      "      - 240\n",
      "      episode_reward:\n",
      "      - 232.0\n",
      "      - 226.0\n",
      "      - 226.0\n",
      "      - 240.0\n",
      "      - 240.0\n",
      "      - 240.0\n",
      "      - 225.0\n",
      "      - 240.0\n",
      "      - 230.0\n",
      "      - 232.0\n",
      "      - 226.0\n",
      "      - 226.0\n",
      "      - 245.0\n",
      "      - 227.0\n",
      "      - 227.0\n",
      "      - 230.0\n",
      "      - 231.0\n",
      "      - 234.0\n",
      "      - 234.0\n",
      "      - 240.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11772623650298701\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11849062858439789\n",
      "      mean_inference_ms: 1.6587726191325847\n",
      "      mean_raw_obs_processing_ms: 0.1272914421277878\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 59968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 77.51114654541016\n",
      "          mean_q: 62.99618911743164\n",
      "          mean_td_error: 2.429065227508545\n",
      "          min_q: 11.238271713256836\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.2145538330078125\n",
      "        - 0.088226318359375\n",
      "        - -0.34654998779296875\n",
      "        - -0.0682220458984375\n",
      "        - -0.5801010131835938\n",
      "        - -0.27611541748046875\n",
      "        - -0.20346832275390625\n",
      "        - -0.1340789794921875\n",
      "        - 0.4142913818359375\n",
      "        - -1.0702857971191406\n",
      "        - -2.028867721557617\n",
      "        - -0.6046905517578125\n",
      "        - -0.0690765380859375\n",
      "        - -0.373291015625\n",
      "        - 1.0008010864257812\n",
      "        - 0.0444183349609375\n",
      "        - 36.84209060668945\n",
      "        - -0.0011749267578125\n",
      "        - 0.36161041259765625\n",
      "        - -0.26555633544921875\n",
      "        - -0.34967803955078125\n",
      "        - -0.734832763671875\n",
      "        - -0.3512115478515625\n",
      "        - -1.3133506774902344\n",
      "        - -0.6024169921875\n",
      "        - 0.888641357421875\n",
      "        - 0.25643157958984375\n",
      "        - 0.09952735900878906\n",
      "        - 0.0466156005859375\n",
      "        - 0.02020263671875\n",
      "        - -1.9998893737792969\n",
      "        - 48.82553482055664\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 472032\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 472032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 118\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.49090909090909\n",
      "    ram_util_percent: 16.300000000000004\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11402081645848966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1159212240861621\n",
      "    mean_inference_ms: 1.6503207012124832\n",
      "    mean_raw_obs_processing_ms: 0.23811113358875372\n",
      "  time_since_restore: 545.0300097465515\n",
      "  time_this_iter_s: 14.975892543792725\n",
      "  time_total_s: 545.0300097465515\n",
      "  timers:\n",
      "    learn_throughput: 7407.037\n",
      "    learn_time_ms: 4.32\n",
      "    load_throughput: 82010.099\n",
      "    load_time_ms: 0.39\n",
      "  timestamp: 1641219430\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 60\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:12 (running for 00:09:14.12)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">          545.03</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  192.99</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            192.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 61000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-17-15\n",
      "  done: false\n",
      "  episode_len_mean: 191.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 191.8\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 522\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 60976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 78.9620132446289\n",
      "          mean_q: 64.53556060791016\n",
      "          mean_td_error: 5.155134201049805\n",
      "          min_q: 5.952127456665039\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.31151580810546875\n",
      "        - -0.7920303344726562\n",
      "        - -8.778949737548828\n",
      "        - 0.18183135986328125\n",
      "        - -0.227020263671875\n",
      "        - 0.680023193359375\n",
      "        - -0.045963287353515625\n",
      "        - 0.1847991943359375\n",
      "        - 0.894073486328125\n",
      "        - 0.11444854736328125\n",
      "        - 0.6962203979492188\n",
      "        - -0.653167724609375\n",
      "        - -0.32526397705078125\n",
      "        - -0.10552978515625\n",
      "        - 0.09112548828125\n",
      "        - 57.111637115478516\n",
      "        - 0.10772705078125\n",
      "        - -0.5568790435791016\n",
      "        - -0.045501708984375\n",
      "        - -0.21572113037109375\n",
      "        - -0.5951995849609375\n",
      "        - 0.5583419799804688\n",
      "        - 53.4013786315918\n",
      "        - -0.19276762008666992\n",
      "        - 0.4018878936767578\n",
      "        - 2.2922897338867188\n",
      "        - 0.1848297119140625\n",
      "        - 0.31835174560546875\n",
      "        - 0.4976806640625\n",
      "        - 60.28038787841797\n",
      "        - -0.23264312744140625\n",
      "        - 0.04541778564453125\n",
      "    num_agent_steps_sampled: 61000\n",
      "    num_agent_steps_trained: 480032\n",
      "    num_steps_sampled: 61000\n",
      "    num_steps_trained: 480032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 120\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.442857142857143\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11400753511857759\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1159036741699781\n",
      "    mean_inference_ms: 1.650253650439555\n",
      "    mean_raw_obs_processing_ms: 0.238001543029874\n",
      "  time_since_restore: 550.0220994949341\n",
      "  time_this_iter_s: 4.992089748382568\n",
      "  time_total_s: 550.0220994949341\n",
      "  timers:\n",
      "    learn_throughput: 8754.491\n",
      "    learn_time_ms: 3.655\n",
      "    load_throughput: 117869.261\n",
      "    load_time_ms: 0.271\n",
      "  timestamp: 1641219435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 61000\n",
      "  training_iteration: 61\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:17 (running for 00:09:19.14)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         550.022</td><td style=\"text-align: right;\">61000</td><td style=\"text-align: right;\">   191.8</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">             191.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:22 (running for 00:09:24.15)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         550.022</td><td style=\"text-align: right;\">61000</td><td style=\"text-align: right;\">   191.8</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">             191.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 62000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-17-27\n",
      "  done: false\n",
      "  episode_len_mean: 188.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 188.87\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 529\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 166.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 177.0\n",
      "    episode_reward_mean: 166.5\n",
      "    episode_reward_min: 157.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 174\n",
      "      - 176\n",
      "      - 162\n",
      "      - 170\n",
      "      - 167\n",
      "      - 160\n",
      "      - 177\n",
      "      - 173\n",
      "      - 160\n",
      "      - 157\n",
      "      - 159\n",
      "      - 172\n",
      "      - 164\n",
      "      - 172\n",
      "      - 158\n",
      "      - 164\n",
      "      - 173\n",
      "      - 159\n",
      "      - 158\n",
      "      - 175\n",
      "      episode_reward:\n",
      "      - 174.0\n",
      "      - 176.0\n",
      "      - 162.0\n",
      "      - 170.0\n",
      "      - 167.0\n",
      "      - 160.0\n",
      "      - 177.0\n",
      "      - 173.0\n",
      "      - 160.0\n",
      "      - 157.0\n",
      "      - 159.0\n",
      "      - 172.0\n",
      "      - 164.0\n",
      "      - 172.0\n",
      "      - 158.0\n",
      "      - 164.0\n",
      "      - 173.0\n",
      "      - 159.0\n",
      "      - 158.0\n",
      "      - 175.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11761189332561121\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.1183867409323894\n",
      "      mean_inference_ms: 1.6573603708698883\n",
      "      mean_raw_obs_processing_ms: 0.12721310066272326\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 61984\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 79.99483489990234\n",
      "          mean_q: 65.46089935302734\n",
      "          mean_td_error: 2.6252856254577637\n",
      "          min_q: 3.927096128463745\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.115142822265625\n",
      "        - 75.2597885131836\n",
      "        - 0.19097137451171875\n",
      "        - -0.06878662109375\n",
      "        - 0.24359130859375\n",
      "        - -0.00475311279296875\n",
      "        - 0.34581756591796875\n",
      "        - 0.10528564453125\n",
      "        - -0.2805023193359375\n",
      "        - 0.1701812744140625\n",
      "        - -0.32318115234375\n",
      "        - -0.83837890625\n",
      "        - 0.33057403564453125\n",
      "        - 0.17523956298828125\n",
      "        - 0.9764137268066406\n",
      "        - 0.4391632080078125\n",
      "        - 0.1345367431640625\n",
      "        - -0.01293182373046875\n",
      "        - -0.7695388793945312\n",
      "        - 0.2435302734375\n",
      "        - 0.417877197265625\n",
      "        - 2.927096128463745\n",
      "        - 2.301982879638672\n",
      "        - 0.2842140197753906\n",
      "        - 0.211517333984375\n",
      "        - 0.2929840087890625\n",
      "        - 0.14153671264648438\n",
      "        - -0.35601139068603516\n",
      "        - 0.07552337646484375\n",
      "        - 0.6171188354492188\n",
      "        - 0.6312179565429688\n",
      "        - 0.26221466064453125\n",
      "    num_agent_steps_sampled: 62000\n",
      "    num_agent_steps_trained: 488032\n",
      "    num_steps_sampled: 62000\n",
      "    num_steps_trained: 488032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 122\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.547058823529415\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11398699350143965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.115878145904552\n",
      "    mean_inference_ms: 1.6500742779235582\n",
      "    mean_raw_obs_processing_ms: 0.23790268906829304\n",
      "  time_since_restore: 561.875128030777\n",
      "  time_this_iter_s: 11.853028535842896\n",
      "  time_total_s: 561.875128030777\n",
      "  timers:\n",
      "    learn_throughput: 7878.8\n",
      "    learn_time_ms: 4.062\n",
      "    load_throughput: 91143.371\n",
      "    load_time_ms: 0.351\n",
      "  timestamp: 1641219447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 62000\n",
      "  training_iteration: 62\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:28 (running for 00:09:30.05)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         561.875</td><td style=\"text-align: right;\">62000</td><td style=\"text-align: right;\">  188.87</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            188.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:34 (running for 00:09:35.93)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         566.729</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">  196.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            196.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:39 (running for 00:09:40.94)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         566.729</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">  196.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            196.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:44 (running for 00:09:45.95)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         566.729</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">  196.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            196.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:49 (running for 00:09:50.96)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         566.729</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">  196.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            196.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:17:54 (running for 00:09:55.97)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         566.729</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">  196.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            196.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 64000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 205.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 205.26\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 533\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11752593156514382\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11839563844082406\n",
      "      mean_inference_ms: 1.6565008388459614\n",
      "      mean_raw_obs_processing_ms: 0.12696406328256693\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 64000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 80.06248474121094\n",
      "          mean_q: 57.35490417480469\n",
      "          mean_td_error: 1.2971380949020386\n",
      "          min_q: 14.942583084106445\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.09561920166015625\n",
      "        - -0.23904037475585938\n",
      "        - 0.8811836242675781\n",
      "        - -0.13179779052734375\n",
      "        - 0.6588554382324219\n",
      "        - 1.4247016906738281\n",
      "        - -0.1474151611328125\n",
      "        - 0.33943939208984375\n",
      "        - 0.818943977355957\n",
      "        - 0.049346923828125\n",
      "        - 0.5724563598632812\n",
      "        - 0.006500244140625\n",
      "        - 0.18572235107421875\n",
      "        - 28.9488582611084\n",
      "        - 1.3107490539550781\n",
      "        - 0.28641510009765625\n",
      "        - -0.1547393798828125\n",
      "        - -0.15642547607421875\n",
      "        - 2.8438549041748047\n",
      "        - 0.1097564697265625\n",
      "        - -0.09210205078125\n",
      "        - 0.009723663330078125\n",
      "        - 0.5609169006347656\n",
      "        - 0.0327301025390625\n",
      "        - 0.78424072265625\n",
      "        - 0.08267974853515625\n",
      "        - 0.37125396728515625\n",
      "        - 1.0541667938232422\n",
      "        - 0.6268463134765625\n",
      "        - 0.4015350341796875\n",
      "        - -0.13348388671875\n",
      "        - 0.29816436767578125\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 504032\n",
      "    num_steps_sampled: 64000\n",
      "    num_steps_trained: 504032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 126\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.175675675675677\n",
      "    ram_util_percent: 16.3054054054054\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11397564589692415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1158644442949158\n",
      "    mean_inference_ms: 1.64997907615469\n",
      "    mean_raw_obs_processing_ms: 0.23784413816121494\n",
      "  time_since_restore: 592.4223039150238\n",
      "  time_this_iter_s: 25.69314670562744\n",
      "  time_total_s: 592.4223039150238\n",
      "  timers:\n",
      "    learn_throughput: 8281.824\n",
      "    learn_time_ms: 3.864\n",
      "    load_throughput: 92195.17\n",
      "    load_time_ms: 0.347\n",
      "  timestamp: 1641219478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 64\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:00 (running for 00:10:01.68)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         592.422</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">  205.26</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            205.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 65000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 213.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 213.25\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 535\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 64504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 81.26753234863281\n",
      "          mean_q: 68.29806518554688\n",
      "          mean_td_error: 1.7789790630340576\n",
      "          min_q: 27.640716552734375\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.24729156494140625\n",
      "        - -0.9698371887207031\n",
      "        - 1.2769889831542969\n",
      "        - 0.28783416748046875\n",
      "        - -0.9588680267333984\n",
      "        - 0.170654296875\n",
      "        - 0.36053466796875\n",
      "        - -0.031261444091796875\n",
      "        - 0.06673431396484375\n",
      "        - 55.96065902709961\n",
      "        - -1.1537628173828125\n",
      "        - 0.31641387939453125\n",
      "        - 0.34825897216796875\n",
      "        - 0.48403167724609375\n",
      "        - -0.49481964111328125\n",
      "        - -0.2952117919921875\n",
      "        - -0.1314239501953125\n",
      "        - -1.1989860534667969\n",
      "        - 0.520233154296875\n",
      "        - 0.3892364501953125\n",
      "        - -0.19853973388671875\n",
      "        - 0.9190559387207031\n",
      "        - 0.8627090454101562\n",
      "        - -0.9198341369628906\n",
      "        - 0.457489013671875\n",
      "        - -0.20858001708984375\n",
      "        - -0.18894195556640625\n",
      "        - -0.16389846801757812\n",
      "        - 0.26421356201171875\n",
      "        - 0.16316986083984375\n",
      "        - 0.6914596557617188\n",
      "        - 0.05432891845703125\n",
      "    num_agent_steps_sampled: 65000\n",
      "    num_agent_steps_trained: 512032\n",
      "    num_steps_sampled: 65000\n",
      "    num_steps_trained: 512032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 127\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.014285714285716\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1139712802564738\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11585938061887933\n",
      "    mean_inference_ms: 1.649952977000691\n",
      "    mean_raw_obs_processing_ms: 0.23781533863845833\n",
      "  time_since_restore: 597.4985599517822\n",
      "  time_this_iter_s: 5.076256036758423\n",
      "  time_total_s: 597.4985599517822\n",
      "  timers:\n",
      "    learn_throughput: 8118.81\n",
      "    learn_time_ms: 3.941\n",
      "    load_throughput: 109547.607\n",
      "    load_time_ms: 0.292\n",
      "  timestamp: 1641219483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 65000\n",
      "  training_iteration: 65\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:05 (running for 00:10:06.79)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         597.499</td><td style=\"text-align: right;\">65000</td><td style=\"text-align: right;\">  213.25</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            213.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:10 (running for 00:10:11.80)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         597.499</td><td style=\"text-align: right;\">65000</td><td style=\"text-align: right;\">  213.25</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            213.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:15 (running for 00:10:16.81)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         597.499</td><td style=\"text-align: right;\">65000</td><td style=\"text-align: right;\">  213.25</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            213.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 66000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-18-16\n",
      "  done: false\n",
      "  episode_len_mean: 218.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 218.56\n",
      "  episode_reward_min: 13.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 539\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 179.6\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 187.0\n",
      "    episode_reward_mean: 179.6\n",
      "    episode_reward_min: 172.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 178\n",
      "      - 183\n",
      "      - 176\n",
      "      - 187\n",
      "      - 183\n",
      "      - 172\n",
      "      - 186\n",
      "      - 179\n",
      "      - 175\n",
      "      - 185\n",
      "      - 175\n",
      "      - 176\n",
      "      - 184\n",
      "      - 176\n",
      "      - 181\n",
      "      - 179\n",
      "      - 172\n",
      "      - 179\n",
      "      - 182\n",
      "      - 184\n",
      "      episode_reward:\n",
      "      - 178.0\n",
      "      - 183.0\n",
      "      - 176.0\n",
      "      - 187.0\n",
      "      - 183.0\n",
      "      - 172.0\n",
      "      - 186.0\n",
      "      - 179.0\n",
      "      - 175.0\n",
      "      - 185.0\n",
      "      - 175.0\n",
      "      - 176.0\n",
      "      - 184.0\n",
      "      - 176.0\n",
      "      - 181.0\n",
      "      - 179.0\n",
      "      - 172.0\n",
      "      - 179.0\n",
      "      - 182.0\n",
      "      - 184.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11763843423037197\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11851008709783939\n",
      "      mean_inference_ms: 1.6578950299281936\n",
      "      mean_raw_obs_processing_ms: 0.12712293661724666\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 65512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 81.39521789550781\n",
      "          mean_q: 67.88121795654297\n",
      "          mean_td_error: 4.16941499710083\n",
      "          min_q: 3.031308650970459\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.4002532958984375\n",
      "        - 0.19216156005859375\n",
      "        - -0.6217269897460938\n",
      "        - -0.41934680938720703\n",
      "        - 51.559757232666016\n",
      "        - 0.47180938720703125\n",
      "        - -0.44547271728515625\n",
      "        - 0.8997650146484375\n",
      "        - -0.6765289306640625\n",
      "        - 0.18952178955078125\n",
      "        - 0.07427978515625\n",
      "        - -0.04549407958984375\n",
      "        - -0.00940704345703125\n",
      "        - -1.0343923568725586\n",
      "        - 0.2325897216796875\n",
      "        - -0.7877883911132812\n",
      "        - -2.559986114501953\n",
      "        - 74.49388122558594\n",
      "        - 0.1919708251953125\n",
      "        - 0.12598419189453125\n",
      "        - -0.39240264892578125\n",
      "        - 13.303857803344727\n",
      "        - -0.05222320556640625\n",
      "        - -0.512847900390625\n",
      "        - -0.2479248046875\n",
      "        - 0.15185546875\n",
      "        - 0.2472381591796875\n",
      "        - -0.770751953125\n",
      "        - -0.17568206787109375\n",
      "        - -0.2690582275390625\n",
      "        - -0.15848541259765625\n",
      "        - 0.06587982177734375\n",
      "    num_agent_steps_sampled: 66000\n",
      "    num_agent_steps_trained: 520032\n",
      "    num_steps_sampled: 66000\n",
      "    num_steps_trained: 520032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 129\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.07222222222222\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11396817281840459\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11585390602622636\n",
      "    mean_inference_ms: 1.6499550239282845\n",
      "    mean_raw_obs_processing_ms: 0.23776315761443548\n",
      "  time_since_restore: 610.4224925041199\n",
      "  time_this_iter_s: 12.923932552337646\n",
      "  time_total_s: 610.4224925041199\n",
      "  timers:\n",
      "    learn_throughput: 9010.018\n",
      "    learn_time_ms: 3.552\n",
      "    load_throughput: 133126.094\n",
      "    load_time_ms: 0.24\n",
      "  timestamp: 1641219496\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 66000\n",
      "  training_iteration: 66\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:21 (running for 00:10:22.77)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         610.422</td><td style=\"text-align: right;\">66000</td><td style=\"text-align: right;\">  218.56</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">            218.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 67000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-18-21\n",
      "  done: false\n",
      "  episode_len_mean: 226.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 226.24\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 543\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 66520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 82.6741943359375\n",
      "          mean_q: 68.23177337646484\n",
      "          mean_td_error: 5.176796913146973\n",
      "          min_q: 22.377748489379883\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 47.44973373413086\n",
      "        - 0.1116485595703125\n",
      "        - -0.90911865234375\n",
      "        - -0.5243988037109375\n",
      "        - 0.8309249877929688\n",
      "        - -1.6411781311035156\n",
      "        - 0.222320556640625\n",
      "        - 0.299102783203125\n",
      "        - -1.9945144653320312\n",
      "        - 0.59735107421875\n",
      "        - 0.8992996215820312\n",
      "        - -0.5576705932617188\n",
      "        - -0.41884613037109375\n",
      "        - 2.1262664794921875\n",
      "        - 34.72789764404297\n",
      "        - 21.377748489379883\n",
      "        - 0.4615936279296875\n",
      "        - 61.603485107421875\n",
      "        - 0.0806427001953125\n",
      "        - 0.03745269775390625\n",
      "        - 0.5363845825195312\n",
      "        - -0.0459136962890625\n",
      "        - 1.13690185546875\n",
      "        - -1.0583000183105469\n",
      "        - 0.714202880859375\n",
      "        - 0.23642730712890625\n",
      "        - 0.48018646240234375\n",
      "        - 0.13661956787109375\n",
      "        - -2.2276077270507812\n",
      "        - 0.31797027587890625\n",
      "        - 0.28174591064453125\n",
      "        - 0.369140625\n",
      "    num_agent_steps_sampled: 67000\n",
      "    num_agent_steps_trained: 528032\n",
      "    num_steps_sampled: 67000\n",
      "    num_steps_trained: 528032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 131\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.7375\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11396524345167387\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11584957635951593\n",
      "    mean_inference_ms: 1.649967212049942\n",
      "    mean_raw_obs_processing_ms: 0.23771227348110086\n",
      "  time_since_restore: 615.5333070755005\n",
      "  time_this_iter_s: 5.110814571380615\n",
      "  time_total_s: 615.5333070755005\n",
      "  timers:\n",
      "    learn_throughput: 9190.288\n",
      "    learn_time_ms: 3.482\n",
      "    load_throughput: 160566.728\n",
      "    load_time_ms: 0.199\n",
      "  timestamp: 1641219501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 67000\n",
      "  training_iteration: 67\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:26 (running for 00:10:27.91)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         615.533</td><td style=\"text-align: right;\">67000</td><td style=\"text-align: right;\">  226.24</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            226.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:31 (running for 00:10:32.92)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         615.533</td><td style=\"text-align: right;\">67000</td><td style=\"text-align: right;\">  226.24</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            226.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-18-31\n",
      "  done: false\n",
      "  episode_len_mean: 229.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 229.57\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 550\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 134.55\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 144.0\n",
      "    episode_reward_mean: 134.55\n",
      "    episode_reward_min: 125.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 139\n",
      "      - 131\n",
      "      - 131\n",
      "      - 136\n",
      "      - 131\n",
      "      - 138\n",
      "      - 140\n",
      "      - 133\n",
      "      - 131\n",
      "      - 138\n",
      "      - 141\n",
      "      - 144\n",
      "      - 134\n",
      "      - 125\n",
      "      - 133\n",
      "      - 130\n",
      "      - 131\n",
      "      - 129\n",
      "      - 142\n",
      "      - 134\n",
      "      episode_reward:\n",
      "      - 139.0\n",
      "      - 131.0\n",
      "      - 131.0\n",
      "      - 136.0\n",
      "      - 131.0\n",
      "      - 138.0\n",
      "      - 140.0\n",
      "      - 133.0\n",
      "      - 131.0\n",
      "      - 138.0\n",
      "      - 141.0\n",
      "      - 144.0\n",
      "      - 134.0\n",
      "      - 125.0\n",
      "      - 133.0\n",
      "      - 130.0\n",
      "      - 131.0\n",
      "      - 129.0\n",
      "      - 142.0\n",
      "      - 134.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1175801661066039\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11846931670228089\n",
      "      mean_inference_ms: 1.6571145034492933\n",
      "      mean_raw_obs_processing_ms: 0.1271179125802137\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 67528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 82.71674346923828\n",
      "          mean_q: 70.07846069335938\n",
      "          mean_td_error: 7.32863187789917\n",
      "          min_q: 18.998733520507812\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.3462371826171875\n",
      "        - -0.00080108642578125\n",
      "        - -0.49506378173828125\n",
      "        - 3.5175323486328125\n",
      "        - 1.782196044921875\n",
      "        - 0.115203857421875\n",
      "        - 68.49295806884766\n",
      "        - 0.1739654541015625\n",
      "        - -0.3880157470703125\n",
      "        - -0.48604583740234375\n",
      "        - -1.3166694641113281\n",
      "        - -1.2142410278320312\n",
      "        - 39.21612548828125\n",
      "        - 0.1910247802734375\n",
      "        - -0.747467041015625\n",
      "        - 49.4556770324707\n",
      "        - 78.46431732177734\n",
      "        - -0.12984466552734375\n",
      "        - 0.37884521484375\n",
      "        - 1.1465072631835938\n",
      "        - -0.1006622314453125\n",
      "        - -0.680419921875\n",
      "        - -0.7069320678710938\n",
      "        - -1.136190414428711\n",
      "        - -0.24664306640625\n",
      "        - -0.07054901123046875\n",
      "        - -0.31879425048828125\n",
      "        - 0.27997589111328125\n",
      "        - 0.2834625244140625\n",
      "        - -0.5215530395507812\n",
      "        - 0.3891754150390625\n",
      "        - -0.464630126953125\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 536032\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 536032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 133\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.34285714285714\n",
      "    ram_util_percent: 16.300000000000004\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11395648383535444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11583930183808774\n",
      "    mean_inference_ms: 1.649956543341301\n",
      "    mean_raw_obs_processing_ms: 0.23761633624491446\n",
      "  time_since_restore: 625.8516535758972\n",
      "  time_this_iter_s: 10.318346500396729\n",
      "  time_total_s: 625.8516535758972\n",
      "  timers:\n",
      "    learn_throughput: 7829.028\n",
      "    learn_time_ms: 4.087\n",
      "    load_throughput: 95733.044\n",
      "    load_time_ms: 0.334\n",
      "  timestamp: 1641219511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 68\n",
      "  trial_id: 8cc99_00000\n",
      "  \n",
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 69000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-18-36\n",
      "  done: false\n",
      "  episode_len_mean: 232.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 232.22\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 556\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 68536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 82.8670654296875\n",
      "          mean_q: 70.88026428222656\n",
      "          mean_td_error: 2.7545056343078613\n",
      "          min_q: 18.75147819519043\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.5687789916992188\n",
      "        - -0.431182861328125\n",
      "        - -0.3060035705566406\n",
      "        - -0.6578521728515625\n",
      "        - -1.2669754028320312\n",
      "        - -0.9313125610351562\n",
      "        - -0.36810302734375\n",
      "        - -0.52685546875\n",
      "        - -0.30507659912109375\n",
      "        - -0.49514007568359375\n",
      "        - 18.353256225585938\n",
      "        - -0.31362152099609375\n",
      "        - -0.6982269287109375\n",
      "        - -0.45680999755859375\n",
      "        - -15.862003326416016\n",
      "        - -0.44638824462890625\n",
      "        - -0.341583251953125\n",
      "        - -0.540863037109375\n",
      "        - -0.1644439697265625\n",
      "        - -1.9127273559570312\n",
      "        - -0.5906982421875\n",
      "        - -0.33985137939453125\n",
      "        - -0.3536834716796875\n",
      "        - 43.270660400390625\n",
      "        - -0.0321044921875\n",
      "        - -0.4492950439453125\n",
      "        - -0.32108306884765625\n",
      "        - -0.42641448974609375\n",
      "        - -0.5454025268554688\n",
      "        - -0.4655914306640625\n",
      "        - 59.774044036865234\n",
      "        - -3.1357040405273438\n",
      "    num_agent_steps_sampled: 69000\n",
      "    num_agent_steps_trained: 544032\n",
      "    num_steps_sampled: 69000\n",
      "    num_steps_trained: 544032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 135\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.542857142857144\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11395114531960644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11583431938500878\n",
      "    mean_inference_ms: 1.6500009653764791\n",
      "    mean_raw_obs_processing_ms: 0.2375419398863492\n",
      "  time_since_restore: 630.8357465267181\n",
      "  time_this_iter_s: 4.984092950820923\n",
      "  time_total_s: 630.8357465267181\n",
      "  timers:\n",
      "    learn_throughput: 7888.247\n",
      "    learn_time_ms: 4.057\n",
      "    load_throughput: 98105.203\n",
      "    load_time_ms: 0.326\n",
      "  timestamp: 1641219516\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 69000\n",
      "  training_iteration: 69\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:36 (running for 00:10:38.30)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         630.836</td><td style=\"text-align: right;\">69000</td><td style=\"text-align: right;\">  232.22</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            232.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:41 (running for 00:10:43.32)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         630.836</td><td style=\"text-align: right;\">69000</td><td style=\"text-align: right;\">  232.22</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            232.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:46 (running for 00:10:48.32)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         630.836</td><td style=\"text-align: right;\">69000</td><td style=\"text-align: right;\">  232.22</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            232.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:51 (running for 00:10:53.33)<br>Memory usage on this node: 10.2/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         630.836</td><td style=\"text-align: right;\">69000</td><td style=\"text-align: right;\">  232.22</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            232.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 70000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-18-54\n",
      "  done: false\n",
      "  episode_len_mean: 236.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 236.03\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 559\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 304.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 304.0\n",
      "    episode_reward_min: 179.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 229\n",
      "      - 500\n",
      "      - 198\n",
      "      - 187\n",
      "      - 500\n",
      "      - 191\n",
      "      - 500\n",
      "      - 500\n",
      "      - 209\n",
      "      - 201\n",
      "      - 195\n",
      "      - 203\n",
      "      - 220\n",
      "      - 500\n",
      "      - 185\n",
      "      - 449\n",
      "      - 500\n",
      "      - 208\n",
      "      - 226\n",
      "      - 179\n",
      "      episode_reward:\n",
      "      - 229.0\n",
      "      - 500.0\n",
      "      - 198.0\n",
      "      - 187.0\n",
      "      - 500.0\n",
      "      - 191.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 209.0\n",
      "      - 201.0\n",
      "      - 195.0\n",
      "      - 203.0\n",
      "      - 220.0\n",
      "      - 500.0\n",
      "      - 185.0\n",
      "      - 449.0\n",
      "      - 500.0\n",
      "      - 208.0\n",
      "      - 226.0\n",
      "      - 179.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11754709540399925\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11844362154920281\n",
      "      mean_inference_ms: 1.6568832766400778\n",
      "      mean_raw_obs_processing_ms: 0.12702778566627837\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 69544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 84.70296478271484\n",
      "          mean_q: 67.17474365234375\n",
      "          mean_td_error: 5.730910301208496\n",
      "          min_q: 12.42687702178955\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.2502288818359375\n",
      "        - 0.10120391845703125\n",
      "        - -0.5272216796875\n",
      "        - -0.42847442626953125\n",
      "        - -0.18022918701171875\n",
      "        - 1.0425758361816406\n",
      "        - 0.3126068115234375\n",
      "        - 0.3911285400390625\n",
      "        - 0.36263275146484375\n",
      "        - 1.4301605224609375\n",
      "        - 0.7040176391601562\n",
      "        - 0.4179534912109375\n",
      "        - 0.0142364501953125\n",
      "        - 11.42687702178955\n",
      "        - 3.1089553833007812\n",
      "        - 0.22711944580078125\n",
      "        - 0.29796600341796875\n",
      "        - -0.44640350341796875\n",
      "        - 0.03166961669921875\n",
      "        - 0.726715087890625\n",
      "        - 82.94073486328125\n",
      "        - 0.35308074951171875\n",
      "        - -0.5148162841796875\n",
      "        - 0.952728271484375\n",
      "        - 1.57025146484375\n",
      "        - 3.0181217193603516\n",
      "        - 70.2537841796875\n",
      "        - 0.3742218017578125\n",
      "        - 4.984102249145508\n",
      "        - 0.3348236083984375\n",
      "        - 1.03826904296875\n",
      "        - -0.6794357299804688\n",
      "    num_agent_steps_sampled: 70000\n",
      "    num_agent_steps_trained: 552032\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 552032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 137\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.523076923076925\n",
      "    ram_util_percent: 16.29615384615385\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11394803861558345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11583210484648117\n",
      "    mean_inference_ms: 1.65002204053438\n",
      "    mean_raw_obs_processing_ms: 0.23750393590319527\n",
      "  time_since_restore: 648.5076580047607\n",
      "  time_this_iter_s: 17.671911478042603\n",
      "  time_total_s: 648.5076580047607\n",
      "  timers:\n",
      "    learn_throughput: 8222.161\n",
      "    learn_time_ms: 3.892\n",
      "    load_throughput: 89015.604\n",
      "    load_time_ms: 0.359\n",
      "  timestamp: 1641219534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 70\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:18:57 (running for 00:10:59.03)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         648.508</td><td style=\"text-align: right;\">70000</td><td style=\"text-align: right;\">  236.03</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            236.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:03 (running for 00:11:05.01)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         653.455</td><td style=\"text-align: right;\">71000</td><td style=\"text-align: right;\">  229.69</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            229.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:08 (running for 00:11:10.02)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         653.455</td><td style=\"text-align: right;\">71000</td><td style=\"text-align: right;\">  229.69</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            229.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 72000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-19-11\n",
      "  done: false\n",
      "  episode_len_mean: 219.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 219.11\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 569\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 168.25\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 188.0\n",
      "    episode_reward_mean: 168.25\n",
      "    episode_reward_min: 155.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 166\n",
      "      - 165\n",
      "      - 184\n",
      "      - 168\n",
      "      - 163\n",
      "      - 168\n",
      "      - 165\n",
      "      - 167\n",
      "      - 162\n",
      "      - 161\n",
      "      - 155\n",
      "      - 188\n",
      "      - 184\n",
      "      - 173\n",
      "      - 155\n",
      "      - 159\n",
      "      - 160\n",
      "      - 183\n",
      "      - 168\n",
      "      - 171\n",
      "      episode_reward:\n",
      "      - 166.0\n",
      "      - 165.0\n",
      "      - 184.0\n",
      "      - 168.0\n",
      "      - 163.0\n",
      "      - 168.0\n",
      "      - 165.0\n",
      "      - 167.0\n",
      "      - 162.0\n",
      "      - 161.0\n",
      "      - 155.0\n",
      "      - 188.0\n",
      "      - 184.0\n",
      "      - 173.0\n",
      "      - 155.0\n",
      "      - 159.0\n",
      "      - 160.0\n",
      "      - 183.0\n",
      "      - 168.0\n",
      "      - 171.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11757064462705306\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11847888070860486\n",
      "      mean_inference_ms: 1.657049171436546\n",
      "      mean_raw_obs_processing_ms: 0.1270531609175875\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 71560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 87.85771942138672\n",
      "          mean_q: 65.25773620605469\n",
      "          mean_td_error: 2.637014389038086\n",
      "          min_q: 0.6193603277206421\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -3.498973846435547\n",
      "        - -1.9143314361572266\n",
      "        - 0.482391357421875\n",
      "        - 0.6261672973632812\n",
      "        - 0.8658218383789062\n",
      "        - 0.435760498046875\n",
      "        - 1.1021842956542969\n",
      "        - 0.33086395263671875\n",
      "        - -0.09595489501953125\n",
      "        - 0.03464317321777344\n",
      "        - -1.1440067291259766\n",
      "        - -1.3903465270996094\n",
      "        - -2.1771774291992188\n",
      "        - 0.28423309326171875\n",
      "        - -0.147491455078125\n",
      "        - 0.7141647338867188\n",
      "        - 0.2122039794921875\n",
      "        - 0.1921539306640625\n",
      "        - 0.593170166015625\n",
      "        - 42.74065399169922\n",
      "        - 0.6181793212890625\n",
      "        - 45.618751525878906\n",
      "        - -0.002197265625\n",
      "        - 0.4272308349609375\n",
      "        - -0.21838927268981934\n",
      "        - 0.26038360595703125\n",
      "        - 0.30382537841796875\n",
      "        - 0.33855438232421875\n",
      "        - -2.2370262145996094\n",
      "        - 0.5720826983451843\n",
      "        - 0.27014923095703125\n",
      "        - 0.18679046630859375\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 568032\n",
      "    num_steps_sampled: 72000\n",
      "    num_steps_trained: 568032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 141\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.9\n",
      "    ram_util_percent: 16.1\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11394409609996695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11583343092796827\n",
      "    mean_inference_ms: 1.650208331931899\n",
      "    mean_raw_obs_processing_ms: 0.2374041511340061\n",
      "  time_since_restore: 665.3437294960022\n",
      "  time_this_iter_s: 11.888824701309204\n",
      "  time_total_s: 665.3437294960022\n",
      "  timers:\n",
      "    learn_throughput: 7832.912\n",
      "    learn_time_ms: 4.085\n",
      "    load_throughput: 88921.246\n",
      "    load_time_ms: 0.36\n",
      "  timestamp: 1641219551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 72\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:14 (running for 00:11:15.95)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         665.344</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">  219.11</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            219.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 73000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-19-16\n",
      "  done: false\n",
      "  episode_len_mean: 223.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 223.44\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 573\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 72568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 87.8394546508789\n",
      "          mean_q: 66.51815795898438\n",
      "          mean_td_error: 3.1134607791900635\n",
      "          min_q: -5.235586166381836\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.3931884765625\n",
      "        - 21.474910736083984\n",
      "        - 0.01064300537109375\n",
      "        - -0.36431121826171875\n",
      "        - -0.1806640625\n",
      "        - -0.38677215576171875\n",
      "        - -0.5388031005859375\n",
      "        - -0.40045928955078125\n",
      "        - 0.15280914306640625\n",
      "        - 0.27342987060546875\n",
      "        - -4.006263732910156\n",
      "        - 0.16220855712890625\n",
      "        - -6.235586166381836\n",
      "        - 0.13411712646484375\n",
      "        - 0.1608428955078125\n",
      "        - -0.01757049560546875\n",
      "        - 0.25881195068359375\n",
      "        - -2.2672386169433594\n",
      "        - -0.2595672607421875\n",
      "        - 4.01751708984375\n",
      "        - 0.27219390869140625\n",
      "        - 0.2586517333984375\n",
      "        - 0.04140472412109375\n",
      "        - -0.2674407958984375\n",
      "        - 13.27334976196289\n",
      "        - -0.5166091918945312\n",
      "        - -0.21501922607421875\n",
      "        - 9.608316421508789\n",
      "        - 64.00115203857422\n",
      "        - 0.8694953918457031\n",
      "        - -0.08690643310546875\n",
      "        - 0.0109100341796875\n",
      "    num_agent_steps_sampled: 73000\n",
      "    num_agent_steps_trained: 576032\n",
      "    num_steps_sampled: 73000\n",
      "    num_steps_trained: 576032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 143\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.571428571428573\n",
      "    ram_util_percent: 16.099999999999998\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11394348908867664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11583588981542318\n",
      "    mean_inference_ms: 1.6502906008641423\n",
      "    mean_raw_obs_processing_ms: 0.2373716033920127\n",
      "  time_since_restore: 670.6562321186066\n",
      "  time_this_iter_s: 5.31250262260437\n",
      "  time_total_s: 670.6562321186066\n",
      "  timers:\n",
      "    learn_throughput: 8166.828\n",
      "    learn_time_ms: 3.918\n",
      "    load_throughput: 99427.904\n",
      "    load_time_ms: 0.322\n",
      "  timestamp: 1641219556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 73000\n",
      "  training_iteration: 73\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:19 (running for 00:11:21.30)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         670.656</td><td style=\"text-align: right;\">73000</td><td style=\"text-align: right;\">  223.44</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            223.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:24 (running for 00:11:26.31)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         670.656</td><td style=\"text-align: right;\">73000</td><td style=\"text-align: right;\">  223.44</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            223.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:29 (running for 00:11:31.32)<br>Memory usage on this node: 10.0/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         670.656</td><td style=\"text-align: right;\">73000</td><td style=\"text-align: right;\">  223.44</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            223.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 74000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-19-30\n",
      "  done: false\n",
      "  episode_len_mean: 226.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 226.89\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 578\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 212.05\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 289.0\n",
      "    episode_reward_mean: 212.05\n",
      "    episode_reward_min: 170.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 276\n",
      "      - 189\n",
      "      - 206\n",
      "      - 199\n",
      "      - 209\n",
      "      - 242\n",
      "      - 210\n",
      "      - 195\n",
      "      - 289\n",
      "      - 249\n",
      "      - 190\n",
      "      - 230\n",
      "      - 185\n",
      "      - 212\n",
      "      - 188\n",
      "      - 189\n",
      "      - 188\n",
      "      - 171\n",
      "      - 170\n",
      "      - 254\n",
      "      episode_reward:\n",
      "      - 276.0\n",
      "      - 189.0\n",
      "      - 206.0\n",
      "      - 199.0\n",
      "      - 209.0\n",
      "      - 242.0\n",
      "      - 210.0\n",
      "      - 195.0\n",
      "      - 289.0\n",
      "      - 249.0\n",
      "      - 190.0\n",
      "      - 230.0\n",
      "      - 185.0\n",
      "      - 212.0\n",
      "      - 188.0\n",
      "      - 189.0\n",
      "      - 188.0\n",
      "      - 171.0\n",
      "      - 170.0\n",
      "      - 254.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1174766724611231\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11838425488299406\n",
      "      mean_inference_ms: 1.6557300207024273\n",
      "      mean_raw_obs_processing_ms: 0.12697579190467453\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 73576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 89.08174896240234\n",
      "          mean_q: 67.60799407958984\n",
      "          mean_td_error: 4.278687477111816\n",
      "          min_q: 6.900193214416504\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.292388916015625\n",
      "        - 0.9483261108398438\n",
      "        - 0.37458038330078125\n",
      "        - 80.40205383300781\n",
      "        - 1.0248184204101562\n",
      "        - 0.10173797607421875\n",
      "        - 11.113821029663086\n",
      "        - 0.37761688232421875\n",
      "        - -0.5223007202148438\n",
      "        - -0.041015625\n",
      "        - -0.3025970458984375\n",
      "        - 0.9781603813171387\n",
      "        - 0.058624267578125\n",
      "        - -0.18396759033203125\n",
      "        - 46.022212982177734\n",
      "        - -0.45891571044921875\n",
      "        - -0.0598907470703125\n",
      "        - -0.5374984741210938\n",
      "        - -0.09282684326171875\n",
      "        - -0.0388336181640625\n",
      "        - 0.5915336608886719\n",
      "        - -0.0531463623046875\n",
      "        - 0.21678924560546875\n",
      "        - -0.26654815673828125\n",
      "        - -0.188812255859375\n",
      "        - -0.8899459838867188\n",
      "        - -0.18857574462890625\n",
      "        - -1.298593521118164\n",
      "        - -1.53912353515625\n",
      "        - 0.1632232666015625\n",
      "        - -0.14734649658203125\n",
      "        - 1.6468238830566406\n",
      "    num_agent_steps_sampled: 74000\n",
      "    num_agent_steps_trained: 584032\n",
      "    num_steps_sampled: 74000\n",
      "    num_steps_trained: 584032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 145\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.75\n",
      "    ram_util_percent: 16.100000000000005\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11394656282933557\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11584336381811493\n",
      "    mean_inference_ms: 1.650446908836036\n",
      "    mean_raw_obs_processing_ms: 0.2373368589758101\n",
      "  time_since_restore: 684.3005473613739\n",
      "  time_this_iter_s: 13.644315242767334\n",
      "  time_total_s: 684.3005473613739\n",
      "  timers:\n",
      "    learn_throughput: 9067.601\n",
      "    learn_time_ms: 3.529\n",
      "    load_throughput: 125168.076\n",
      "    load_time_ms: 0.256\n",
      "  timestamp: 1641219570\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 74000\n",
      "  training_iteration: 74\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:35 (running for 00:11:36.99)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         684.301</td><td style=\"text-align: right;\">74000</td><td style=\"text-align: right;\">  226.89</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            226.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 75000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-19-35\n",
      "  done: false\n",
      "  episode_len_mean: 224.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 224.24\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 583\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 74584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 89.93463134765625\n",
      "          mean_q: 79.48158264160156\n",
      "          mean_td_error: 2.9194231033325195\n",
      "          min_q: 21.018327713012695\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 1.4013900756835938\n",
      "        - 1.0643463134765625\n",
      "        - 0.4265899658203125\n",
      "        - 0.63262939453125\n",
      "        - 0.186187744140625\n",
      "        - 0.22847747802734375\n",
      "        - 0.42771148681640625\n",
      "        - 1.4878463745117188\n",
      "        - 0.6538314819335938\n",
      "        - 0.689727783203125\n",
      "        - -2.7486190795898438\n",
      "        - 0.602935791015625\n",
      "        - 0.8556365966796875\n",
      "        - 82.73535919189453\n",
      "        - 0.3590545654296875\n",
      "        - 1.3912811279296875\n",
      "        - 0.225738525390625\n",
      "        - 0.8750228881835938\n",
      "        - 0.1350250244140625\n",
      "        - -0.6882553100585938\n",
      "        - 0.8681488037109375\n",
      "        - -0.2281341552734375\n",
      "        - 0.5550537109375\n",
      "        - 0.42539215087890625\n",
      "        - -3.1570892333984375\n",
      "        - 0.7413253784179688\n",
      "        - 1.7083969116210938\n",
      "        - 0.09136199951171875\n",
      "        - 0.358795166015625\n",
      "        - 0.7321243286132812\n",
      "        - 0.5786209106445312\n",
      "        - -0.19437408447265625\n",
      "    num_agent_steps_sampled: 75000\n",
      "    num_agent_steps_trained: 592032\n",
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 592032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 147\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.900000000000002\n",
      "    ram_util_percent: 16.099999999999998\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11395086408556965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1158522915615119\n",
      "    mean_inference_ms: 1.6506178478612599\n",
      "    mean_raw_obs_processing_ms: 0.23730458004058078\n",
      "  time_since_restore: 689.4553050994873\n",
      "  time_this_iter_s: 5.154757738113403\n",
      "  time_total_s: 689.4553050994873\n",
      "  timers:\n",
      "    learn_throughput: 8655.244\n",
      "    learn_time_ms: 3.697\n",
      "    load_throughput: 129741.641\n",
      "    load_time_ms: 0.247\n",
      "  timestamp: 1641219575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 75\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:40 (running for 00:11:42.18)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         689.455</td><td style=\"text-align: right;\">75000</td><td style=\"text-align: right;\">  224.24</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            224.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:45 (running for 00:11:47.19)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         689.455</td><td style=\"text-align: right;\">75000</td><td style=\"text-align: right;\">  224.24</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            224.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 213.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 213.67\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 588\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 174.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 207.0\n",
      "    episode_reward_mean: 174.5\n",
      "    episode_reward_min: 159.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 181\n",
      "      - 187\n",
      "      - 164\n",
      "      - 167\n",
      "      - 163\n",
      "      - 195\n",
      "      - 171\n",
      "      - 164\n",
      "      - 185\n",
      "      - 179\n",
      "      - 167\n",
      "      - 185\n",
      "      - 159\n",
      "      - 169\n",
      "      - 165\n",
      "      - 177\n",
      "      - 207\n",
      "      - 175\n",
      "      - 165\n",
      "      - 165\n",
      "      episode_reward:\n",
      "      - 181.0\n",
      "      - 187.0\n",
      "      - 164.0\n",
      "      - 167.0\n",
      "      - 163.0\n",
      "      - 195.0\n",
      "      - 171.0\n",
      "      - 164.0\n",
      "      - 185.0\n",
      "      - 179.0\n",
      "      - 167.0\n",
      "      - 185.0\n",
      "      - 159.0\n",
      "      - 169.0\n",
      "      - 165.0\n",
      "      - 177.0\n",
      "      - 207.0\n",
      "      - 175.0\n",
      "      - 165.0\n",
      "      - 165.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11755305184141959\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.11844517314036984\n",
      "      mean_inference_ms: 1.6567847819080748\n",
      "      mean_raw_obs_processing_ms: 0.12705556927245526\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 75592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 89.52237701416016\n",
      "          mean_q: 65.0225830078125\n",
      "          mean_td_error: 5.511879920959473\n",
      "          min_q: 5.3269267082214355\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.6682662963867188\n",
      "        - 0.7884635925292969\n",
      "        - -1.548257827758789\n",
      "        - -1.152050495147705\n",
      "        - 0.0323486328125\n",
      "        - 0.30261993408203125\n",
      "        - -0.33475494384765625\n",
      "        - -0.355377197265625\n",
      "        - 0.4850311279296875\n",
      "        - -0.0091705322265625\n",
      "        - 84.60895538330078\n",
      "        - -0.0731964111328125\n",
      "        - 0.91546630859375\n",
      "        - 0.25844573974609375\n",
      "        - 0.7187652587890625\n",
      "        - 76.75433349609375\n",
      "        - 0.6302490234375\n",
      "        - 0.17315673828125\n",
      "        - -0.46143341064453125\n",
      "        - 0.16194915771484375\n",
      "        - 0.1202392578125\n",
      "        - 0.234283447265625\n",
      "        - -0.16156768798828125\n",
      "        - -2.234638214111328\n",
      "        - -0.076904296875\n",
      "        - 0.4188222885131836\n",
      "        - 0.5046539306640625\n",
      "        - 0.3310394287109375\n",
      "        - 13.131330490112305\n",
      "        - -0.01850128173828125\n",
      "        - 0.8971767425537109\n",
      "        - 0.67041015625\n",
      "    num_agent_steps_sampled: 76000\n",
      "    num_agent_steps_trained: 600032\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 600032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 149\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.266666666666666\n",
      "    ram_util_percent: 16.18333333333333\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1139435013035622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11584936475148382\n",
      "    mean_inference_ms: 1.6506506341530889\n",
      "    mean_raw_obs_processing_ms: 0.2372529619566245\n",
      "  time_since_restore: 701.5717785358429\n",
      "  time_this_iter_s: 12.11647343635559\n",
      "  time_total_s: 701.5717785358429\n",
      "  timers:\n",
      "    learn_throughput: 8244.13\n",
      "    learn_time_ms: 3.882\n",
      "    load_throughput: 104465.853\n",
      "    load_time_ms: 0.306\n",
      "  timestamp: 1641219587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 76\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:50 (running for 00:11:52.34)<br>Memory usage on this node: 10.1/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         701.572</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">  213.67</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            213.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_8cc99_00000:\n",
      "  agent_timesteps_total: 77000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-03_15-19-53\n",
      "  done: false\n",
      "  episode_len_mean: 215.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 215.37\n",
      "  episode_reward_min: 36.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 591\n",
      "  experiment_id: f05281628db04c1780232c719894f195\n",
      "  hostname: devbox-x299\n",
      "  info:\n",
      "    last_target_update_ts: 76600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 91.07196807861328\n",
      "          mean_q: 74.22181701660156\n",
      "          mean_td_error: 5.496589660644531\n",
      "          min_q: 12.40656566619873\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -1.6041412353515625\n",
      "        - 0.10140228271484375\n",
      "        - 1.0999526977539062\n",
      "        - 1.4450302124023438\n",
      "        - 87.4588394165039\n",
      "        - 1.1749591827392578\n",
      "        - 0.5279617309570312\n",
      "        - 0.1306610107421875\n",
      "        - 0.2468109130859375\n",
      "        - 0.3487396240234375\n",
      "        - 0.02913665771484375\n",
      "        - 0.12059783935546875\n",
      "        - -0.37894439697265625\n",
      "        - 83.79547119140625\n",
      "        - 0.08705902099609375\n",
      "        - -0.0374603271484375\n",
      "        - 0.29001617431640625\n",
      "        - 0.37235260009765625\n",
      "        - 0.1993865966796875\n",
      "        - -0.4294624328613281\n",
      "        - 0.00722503662109375\n",
      "        - 0.3223724365234375\n",
      "        - -0.1133270263671875\n",
      "        - 0.29021453857421875\n",
      "        - 0.20076751708984375\n",
      "        - 0.36275482177734375\n",
      "        - 0.15350341796875\n",
      "        - -0.0924072265625\n",
      "        - -0.11003875732421875\n",
      "        - -0.41562652587890625\n",
      "        - 0.27432727813720703\n",
      "        - 0.032745361328125\n",
      "    num_agent_steps_sampled: 77000\n",
      "    num_agent_steps_trained: 608032\n",
      "    num_steps_sampled: 77000\n",
      "    num_steps_trained: 608032\n",
      "    num_steps_trained_this_iter: 0\n",
      "    num_target_updates: 151\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.0.90\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.47142857142857\n",
      "    ram_util_percent: 16.2\n",
      "  pid: 17212\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11394264149139068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.11585175236798322\n",
      "    mean_inference_ms: 1.650710626395104\n",
      "    mean_raw_obs_processing_ms: 0.23722780643903124\n",
      "  time_since_restore: 707.0883543491364\n",
      "  time_this_iter_s: 5.516575813293457\n",
      "  time_total_s: 707.0883543491364\n",
      "  timers:\n",
      "    learn_throughput: 7043.11\n",
      "    learn_time_ms: 4.543\n",
      "    load_throughput: 79184.5\n",
      "    load_time_ms: 0.404\n",
      "  timestamp: 1641219593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 77000\n",
      "  training_iteration: 77\n",
      "  trial_id: 8cc99_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:56 (running for 00:11:57.89)<br>Memory usage on this node: 9.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         707.088</td><td style=\"text-align: right;\">77000</td><td style=\"text-align: right;\">  215.37</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            215.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 15:19:57,451\tWARNING tune.py:582 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-03 15:19:57 (running for 00:11:58.90)<br>Memory usage on this node: 9.3/62.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/28 CPUs, 0/1 GPUs, 0.0/33.91 GiB heap, 0.0/16.96 GiB objects<br>Result logdir: /home/dibya/Dropbox/rl_course/deep_rl_get_started_fast/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_8cc99_00000</td><td>RUNNING </td><td>192.168.0.90:17212</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         707.088</td><td style=\"text-align: right;\">77000</td><td style=\"text-align: right;\">  215.37</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  36</td><td style=\"text-align: right;\">            215.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m 2022-01-03 15:19:57,466\tERROR worker.py:431 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"python/ray/_raylet.pyx\", line 759, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"python/ray/_raylet.pyx\", line 580, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"python/ray/_raylet.pyx\", line 618, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"python/ray/_raylet.pyx\", line 625, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"python/ray/_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"python/ray/_raylet.pyx\", line 578, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 609, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/tune/trainable.py\", line 255, in train_buffered\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/tune/trainable.py\", line 314, in train\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/agents/trainer.py\", line 867, in step\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     result = self.step_attempt()\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/agents/trainer.py\", line 925, in step_attempt\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     step_results = next(self.train_exec_impl)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return next(self.built_iterator)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 1075, in build_union\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     item = next(it)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return next(self.built_iterator)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     for item in it:\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py\", line 76, in sampler\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     yield workers.local_worker().sample()\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 757, in sample\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 265, in get_data\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 656, in _env_runner\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     eval_results = _do_policy_eval(\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 1070, in _do_policy_eval\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     policy.compute_actions_from_input_dict(\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/policy/tf_policy.py\", line 297, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     fetched = builder.get(to_fetch)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 42, in get\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     self._executed = run_timeline(\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/rllib/utils/tf_run_builder.py\", line 92, in run_timeline\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 970, in run\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1193, in _run\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1373, in _do_run\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1380, in _do_call\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return fn(*args)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1363, in _run_fn\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1456, in _call_tf_sessionrun\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m   File \"/home/dibya/miniconda3/envs/deep_rl_get_started_fast_python3.9/lib/python3.9/site-packages/ray/worker.py\", line 428, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(DQN pid=17212)\u001b[0m SystemExit: 1\n",
      "2022-01-03 15:19:57,662\tERROR tune.py:622 -- Trials did not complete: [DQN_CartPole-v1_8cc99_00000]\n",
      "2022-01-03 15:19:57,664\tINFO tune.py:626 -- Total run time: 721.24 seconds (718.90 seconds for the tuning loop).\n",
      "2022-01-03 15:19:57,664\tWARNING tune.py:630 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f4d3353c970>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "tune.run(\"DQN\",\n",
    "         config={\"env\": \"CartPole-v1\",\n",
    "                 \"evaluation_interval\": 2, \n",
    "                 \"evaluation_num_episodes\": 20,\n",
    "                 },\n",
    "         local_dir=\"cartpole_v1\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497cc95-37e1-4c5f-9c60-b43c31d6f2bf",
   "metadata": {},
   "source": [
    "## Tensorboard can autodetect different experiments stored under the same results dir\n",
    "\n",
    "- Use `tensorboard logdir=cartpole_v1`\n",
    "\n",
    "```\n",
    "cartpole_v1/\n",
    " DQN\n",
    "  basic-variant-state-2021-06-11_11-46-36.json\n",
    "  DQN_CartPole-v1_e97f1_00000_0_2021-06-11_11-46-36\n",
    "   events.out.tfevents.1623404796.devbox-x299\n",
    "   params.json\n",
    "   params.pkl\n",
    "   progress.csv\n",
    "   result.json\n",
    "  experiment_state-2021-06-11_11-46-36.json\n",
    " PPO\n",
    "     basic-variant-state-2021-06-11_11-46-26.json\n",
    "     experiment_state-2021-06-11_11-46-26.json\n",
    "     PPO_CartPole-v1_e3e63_00000_0_2021-06-11_11-46-26\n",
    "         events.out.tfevents.1623404786.devbox-x299\n",
    "         params.json\n",
    "         params.pkl\n",
    "         progress.csv\n",
    "         result.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
